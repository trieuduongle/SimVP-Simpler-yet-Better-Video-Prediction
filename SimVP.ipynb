{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trieuduongle/SimVP-Simpler-yet-Better-Video-Prediction/blob/generative-approach/SimVP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLrjGVvQWNxH",
        "outputId": "1515f3e9-ed0e-49ea-9b60-e8c2970d2e16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/trieuduongle/SimVP-Simpler-yet-Better-Video-Prediction.git '/content/drive/My Drive/Duong/SimVP/code'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ8IXIA9WeV0",
        "outputId": "c831b15f-e65d-48b6-9702-f27d98c49b2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path '/content/drive/My Drive/Duong/SimVP/code' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/My Drive/Duong/SimVP/code'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snonURDKWpwk",
        "outputId": "9aacf2ff-7205-4c01-c5ef-bdc41b6d06b9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Duong/SimVP/code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.device_count()\n",
        "torch.cuda.is_available()\n",
        "torch.cuda.current_device()\n",
        "torch.cuda.device(0)\n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "id": "7wh_1WQhfFu4",
        "outputId": "99f5348d-8836-4706-d8ea-cc8ae5101e04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git fetch origin && git checkout colab && git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyuC_ecGWmcU",
        "outputId": "063b976f-6040-46c7-8216-b9100259a3c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Branch 'colab' set up to track remote branch 'colab' from 'origin'.\n",
            "Switched to a new branch 'colab'\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash \"./data/moving_mnist/download_mmnist.sh\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SY1EmwzxWzGa",
        "outputId": "d143182a-f5da-4bea-a688-54c120b0a7a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-02 18:06:52--  http://www.cs.toronto.edu/~nitish/unsupervised_video/mnist_test_seq.npy\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 819200096 (781M)\n",
            "Saving to: ‘mnist_test_seq.npy’\n",
            "\n",
            "mnist_test_seq.npy  100%[===================>] 781.25M  9.28MB/s    in 41s     \n",
            "\n",
            "2022-12-02 18:07:33 (19.1 MB/s) - ‘mnist_test_seq.npy’ saved [819200096/819200096]\n",
            "\n",
            "--2022-12-02 18:07:33--  http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Resolving yann.lecun.com (yann.lecun.com)... 172.67.171.76, 104.21.29.36, 2606:4700:3034::6815:1d24, ...\n",
            "Connecting to yann.lecun.com (yann.lecun.com)|172.67.171.76|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9912422 (9.5M) [application/x-gzip]\n",
            "Saving to: ‘train-images-idx3-ubyte.gz’\n",
            "\n",
            "train-images-idx3-u 100%[===================>]   9.45M  61.6MB/s    in 0.2s    \n",
            "\n",
            "2022-12-02 18:07:34 (61.6 MB/s) - ‘train-images-idx3-ubyte.gz’ saved [9912422/9912422]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mXZl8SCBd2x",
        "outputId": "b06e79b3-4bd1-4078-9f03-18eb1625f09e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API\t\t main.py\t     readme_figures\t\t utils.py\n",
            "data\t\t mnist_test_seq.npy  README.md\n",
            "environment.yml  model.py\t     SimVP.ipynb\n",
            "exp.py\t\t modules.py\t     train-images-idx3-ubyte.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --batch_size 64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgflhFiSXuHA",
        "outputId": "9399cfd3-f815-456e-e2a3-4753331d5cbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use GPU: 0\n",
            "\n",
            "device: \tcuda\t\n",
            "res_dir: \t./results\t\n",
            "ex_name: \tDebug\t\n",
            "use_gpu: \tTrue\t\n",
            "gpu: \t0\t\n",
            "seed: \t1\t\n",
            "batch_size: \t64\t\n",
            "val_batch_size: \t16\t\n",
            "data_root: \t./data/\t\n",
            "dataname: \tmmnist\t\n",
            "num_workers: \t8\t\n",
            "in_shape: \t[10, 1, 64, 64]\t\n",
            "hid_S: \t64\t\n",
            "hid_T: \t256\t\n",
            "N_S: \t4\t\n",
            "N_T: \t8\t\n",
            "groups: \t4\t\n",
            "epochs: \t51\t\n",
            "log_step: \t1\t\n",
            "lr: \t0.01\t\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>  start <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "train loss: 0.0337: 100% 157/157 [00:44<00:00,  3.54it/s]\n",
            "vali loss: 0.0310:  10% 63/625 [00:03<00:27, 20.68it/s]\n",
            "vali mse:137.6444, mae:346.0001, ssim:0.4469, psnr:31.2841\n",
            "Epoch: 1 | Train Loss: 0.0460 Vali Loss: 0.0336\n",
            "\n",
            "Validation loss decreased (inf --> 0.033605).  Saving model ...\n",
            "train loss: 0.0313: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0286:  10% 63/625 [00:03<00:28, 19.47it/s]\n",
            "vali mse:126.3827, mae:296.9196, ssim:0.5107, psnr:32.2142\n",
            "Epoch: 2 | Train Loss: 0.0313 Vali Loss: 0.0309\n",
            "\n",
            "Validation loss decreased (0.033605 --> 0.030855).  Saving model ...\n",
            "train loss: 0.0283: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0269:  10% 63/625 [00:03<00:28, 19.89it/s]\n",
            "vali mse:118.7211, mae:278.7345, ssim:0.5592, psnr:32.8707\n",
            "Epoch: 3 | Train Loss: 0.0293 Vali Loss: 0.0290\n",
            "\n",
            "Validation loss decreased (0.030855 --> 0.028985).  Saving model ...\n",
            "train loss: 0.0287: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0264:  10% 63/625 [00:03<00:28, 19.55it/s]\n",
            "vali mse:117.5775, mae:265.8234, ssim:0.6161, psnr:33.4710\n",
            "Epoch: 4 | Train Loss: 0.0282 Vali Loss: 0.0287\n",
            "\n",
            "Validation loss decreased (0.028985 --> 0.028706).  Saving model ...\n",
            "train loss: 0.0263: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0261:  10% 63/625 [00:03<00:28, 19.55it/s]\n",
            "vali mse:113.0489, mae:255.9769, ssim:0.6222, psnr:33.6774\n",
            "Epoch: 5 | Train Loss: 0.0274 Vali Loss: 0.0276\n",
            "\n",
            "Validation loss decreased (0.028706 --> 0.027600).  Saving model ...\n",
            "train loss: 0.0278: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0254:  10% 63/625 [00:03<00:28, 19.75it/s]\n",
            "vali mse:108.6772, mae:268.7874, ssim:0.5823, psnr:33.3547\n",
            "Epoch: 6 | Train Loss: 0.0265 Vali Loss: 0.0265\n",
            "\n",
            "Validation loss decreased (0.027600 --> 0.026533).  Saving model ...\n",
            "train loss: 0.0257: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0237:  10% 63/625 [00:03<00:28, 19.47it/s]\n",
            "vali mse:103.5582, mae:250.0797, ssim:0.6322, psnr:33.7852\n",
            "Epoch: 7 | Train Loss: 0.0255 Vali Loss: 0.0253\n",
            "\n",
            "Validation loss decreased (0.026533 --> 0.025283).  Saving model ...\n",
            "train loss: 0.0232: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0229:  10% 63/625 [00:03<00:28, 19.39it/s]\n",
            "vali mse:99.2328, mae:234.3316, ssim:0.6954, psnr:34.5845\n",
            "Epoch: 8 | Train Loss: 0.0246 Vali Loss: 0.0242\n",
            "\n",
            "Validation loss decreased (0.025283 --> 0.024227).  Saving model ...\n",
            "train loss: 0.0225: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0222:  10% 63/625 [00:03<00:28, 19.58it/s]\n",
            "vali mse:94.9563, mae:249.7297, ssim:0.5827, psnr:33.6404\n",
            "Epoch: 9 | Train Loss: 0.0233 Vali Loss: 0.0232\n",
            "\n",
            "Validation loss decreased (0.024227 --> 0.023183).  Saving model ...\n",
            "train loss: 0.0225: 100% 157/157 [00:37<00:00,  4.24it/s]\n",
            "vali loss: 0.0218:  10% 63/625 [00:03<00:29, 19.19it/s]\n",
            "vali mse:93.5796, mae:220.0360, ssim:0.7582, psnr:35.3514\n",
            "Epoch: 10 | Train Loss: 0.0225 Vali Loss: 0.0228\n",
            "\n",
            "Validation loss decreased (0.023183 --> 0.022847).  Saving model ...\n",
            "train loss: 0.0222: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0221:  10% 63/625 [00:03<00:28, 19.44it/s]\n",
            "vali mse:92.0262, mae:232.9030, ssim:0.7741, psnr:35.7236\n",
            "Epoch: 11 | Train Loss: 0.0218 Vali Loss: 0.0225\n",
            "\n",
            "Validation loss decreased (0.022847 --> 0.022467).  Saving model ...\n",
            "train loss: 0.0215: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0207:  10% 63/625 [00:03<00:29, 19.34it/s]\n",
            "vali mse:86.8812, mae:218.1367, ssim:0.7721, psnr:35.5152\n",
            "Epoch: 12 | Train Loss: 0.0212 Vali Loss: 0.0212\n",
            "\n",
            "Validation loss decreased (0.022467 --> 0.021211).  Saving model ...\n",
            "train loss: 0.0220: 100% 157/157 [00:37<00:00,  4.22it/s]\n",
            "vali loss: 0.0198:  10% 63/625 [00:03<00:28, 19.52it/s]\n",
            "vali mse:84.9514, mae:198.9120, ssim:0.7663, psnr:35.3256\n",
            "Epoch: 13 | Train Loss: 0.0209 Vali Loss: 0.0207\n",
            "\n",
            "Validation loss decreased (0.021211 --> 0.020740).  Saving model ...\n",
            "train loss: 0.0203: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0192:  10% 63/625 [00:03<00:28, 19.60it/s]\n",
            "vali mse:83.2834, mae:202.5196, ssim:0.7973, psnr:35.9497\n",
            "Epoch: 14 | Train Loss: 0.0202 Vali Loss: 0.0203\n",
            "\n",
            "Validation loss decreased (0.020740 --> 0.020333).  Saving model ...\n",
            "train loss: 0.0191: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0185:  10% 63/625 [00:03<00:28, 19.47it/s]\n",
            "vali mse:80.9647, mae:205.6377, ssim:0.7397, psnr:35.0482\n",
            "Epoch: 15 | Train Loss: 0.0197 Vali Loss: 0.0198\n",
            "\n",
            "Validation loss decreased (0.020333 --> 0.019767).  Saving model ...\n",
            "train loss: 0.0190: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0180:  10% 63/625 [00:03<00:28, 19.65it/s]\n",
            "vali mse:79.4775, mae:203.9977, ssim:0.7803, psnr:35.3456\n",
            "Epoch: 16 | Train Loss: 0.0193 Vali Loss: 0.0194\n",
            "\n",
            "Validation loss decreased (0.019767 --> 0.019404).  Saving model ...\n",
            "train loss: 0.0203: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0188:  10% 63/625 [00:03<00:28, 19.69it/s]\n",
            "vali mse:78.8270, mae:224.6094, ssim:0.6146, psnr:33.9823\n",
            "Epoch: 17 | Train Loss: 0.0189 Vali Loss: 0.0192\n",
            "\n",
            "Validation loss decreased (0.019404 --> 0.019245).  Saving model ...\n",
            "train loss: 0.0183: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0175:  10% 63/625 [00:03<00:28, 19.74it/s]\n",
            "vali mse:76.8339, mae:188.6660, ssim:0.7742, psnr:35.5812\n",
            "Epoch: 18 | Train Loss: 0.0186 Vali Loss: 0.0188\n",
            "\n",
            "Validation loss decreased (0.019245 --> 0.018758).  Saving model ...\n",
            "train loss: 0.0182: 100% 157/157 [00:37<00:00,  4.22it/s]\n",
            "vali loss: 0.0179:  10% 63/625 [00:03<00:28, 19.46it/s]\n",
            "vali mse:75.0394, mae:185.8936, ssim:0.7845, psnr:35.5812\n",
            "Epoch: 19 | Train Loss: 0.0184 Vali Loss: 0.0183\n",
            "\n",
            "Validation loss decreased (0.018758 --> 0.018320).  Saving model ...\n",
            "train loss: 0.0166: 100% 157/157 [00:37<00:00,  4.24it/s]\n",
            "vali loss: 0.0170:  10% 63/625 [00:03<00:28, 19.45it/s]\n",
            "vali mse:74.4794, mae:179.7516, ssim:0.8058, psnr:35.8249\n",
            "Epoch: 20 | Train Loss: 0.0180 Vali Loss: 0.0182\n",
            "\n",
            "Validation loss decreased (0.018320 --> 0.018184).  Saving model ...\n",
            "train loss: 0.0174: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0167:  10% 63/625 [00:03<00:28, 19.51it/s]\n",
            "vali mse:72.6940, mae:182.0740, ssim:0.7873, psnr:35.7151\n",
            "Epoch: 21 | Train Loss: 0.0178 Vali Loss: 0.0177\n",
            "\n",
            "Validation loss decreased (0.018184 --> 0.017748).  Saving model ...\n",
            "train loss: 0.0189: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0165:  10% 63/625 [00:03<00:28, 19.50it/s]\n",
            "vali mse:71.9190, mae:178.7111, ssim:0.8263, psnr:36.3520\n",
            "Epoch: 22 | Train Loss: 0.0175 Vali Loss: 0.0176\n",
            "\n",
            "Validation loss decreased (0.017748 --> 0.017558).  Saving model ...\n",
            "train loss: 0.0168: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0165:  10% 63/625 [00:03<00:28, 19.55it/s]\n",
            "vali mse:70.7945, mae:171.0153, ssim:0.8150, psnr:35.9789\n",
            "Epoch: 23 | Train Loss: 0.0172 Vali Loss: 0.0173\n",
            "\n",
            "Validation loss decreased (0.017558 --> 0.017284).  Saving model ...\n",
            "train loss: 0.0156: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0161:  10% 63/625 [00:03<00:28, 19.67it/s]\n",
            "vali mse:69.4670, mae:169.0605, ssim:0.8081, psnr:36.1257\n",
            "Epoch: 24 | Train Loss: 0.0171 Vali Loss: 0.0170\n",
            "\n",
            "Validation loss decreased (0.017284 --> 0.016960).  Saving model ...\n",
            "train loss: 0.0155: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0155:  10% 63/625 [00:03<00:28, 19.72it/s]\n",
            "vali mse:69.3838, mae:168.5445, ssim:0.8148, psnr:36.0635\n",
            "Epoch: 25 | Train Loss: 0.0169 Vali Loss: 0.0169\n",
            "\n",
            "Validation loss decreased (0.016960 --> 0.016940).  Saving model ...\n",
            "train loss: 0.0157: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0158:  10% 63/625 [00:03<00:28, 19.45it/s]\n",
            "vali mse:68.5109, mae:177.7370, ssim:0.7696, psnr:35.8291\n",
            "Epoch: 26 | Train Loss: 0.0166 Vali Loss: 0.0167\n",
            "\n",
            "Validation loss decreased (0.016940 --> 0.016726).  Saving model ...\n",
            "train loss: 0.0161: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0156:  10% 63/625 [00:03<00:28, 19.82it/s]\n",
            "vali mse:69.3776, mae:167.9369, ssim:0.8221, psnr:36.2695\n",
            "Epoch: 27 | Train Loss: 0.0164 Vali Loss: 0.0169\n",
            "\n",
            "train loss: 0.0160: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0156:  10% 63/625 [00:03<00:28, 19.78it/s]\n",
            "vali mse:67.5283, mae:163.2062, ssim:0.8268, psnr:36.3430\n",
            "Epoch: 28 | Train Loss: 0.0164 Vali Loss: 0.0165\n",
            "\n",
            "Validation loss decreased (0.016726 --> 0.016487).  Saving model ...\n",
            "train loss: 0.0156: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0146:  10% 63/625 [00:03<00:28, 19.89it/s]\n",
            "vali mse:65.6572, mae:167.2080, ssim:0.8358, psnr:36.3493\n",
            "Epoch: 29 | Train Loss: 0.0161 Vali Loss: 0.0160\n",
            "\n",
            "Validation loss decreased (0.016487 --> 0.016030).  Saving model ...\n",
            "train loss: 0.0153: 100% 157/157 [00:37<00:00,  4.24it/s]\n",
            "vali loss: 0.0154:  10% 63/625 [00:03<00:28, 19.44it/s]\n",
            "vali mse:64.9698, mae:164.7351, ssim:0.8410, psnr:36.4464\n",
            "Epoch: 30 | Train Loss: 0.0158 Vali Loss: 0.0159\n",
            "\n",
            "Validation loss decreased (0.016030 --> 0.015862).  Saving model ...\n",
            "train loss: 0.0153:   6% 10/157 [00:03<00:45,  3.23it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 113, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 157, in step\n",
            "    adam(params_with_grad,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 213, in adam\n",
            "    func(params,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 262, in _single_tensor_adam\n",
            "    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 45, in <module>\n",
            "    exp.train(args)\n",
            "  File \"/SimVP/exp.py\", line 108, in train\n",
            "    self.optimizer.step()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 113, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/profiler.py\", line 451, in __exit__\n",
            "    torch.ops.profiler._record_function_exit(self.handle)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/_ops.py\", line 143, in __call__\n",
            "    return self._op(*args, **kwargs or {})\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull && python interpolate.py"
      ],
      "metadata": {
        "id": "gBO-hmCwu6vv",
        "outputId": "9dad3107-b7bc-4f66-b9ec-857d82aaf36d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n",
            "From https://github.com/trieuduongle/SimVP-Simpler-yet-Better-Video-Prediction\n",
            "   55ab4a7..8c50ab2  colab      -> origin/colab\n",
            "Updating 55ab4a7..8c50ab2\n",
            "Fast-forward\n",
            " exp.py | 4 \u001b[32m++\u001b[m\u001b[31m--\u001b[m\n",
            " 1 file changed, 2 insertions(+), 2 deletions(-)\n",
            "Use GPU: 0\n",
            "\n",
            "device: \tcuda\t\n",
            "res_dir: \t./results\t\n",
            "ex_name: \tDebug\t\n",
            "use_gpu: \tTrue\t\n",
            "gpu: \t0\t\n",
            "seed: \t1\t\n",
            "batch_size: \t16\t\n",
            "val_batch_size: \t16\t\n",
            "data_root: \t./data/\t\n",
            "dataname: \tmmnist\t\n",
            "num_workers: \t8\t\n",
            "in_shape: \t[10, 1, 64, 64]\t\n",
            "hid_S: \t64\t\n",
            "hid_T: \t256\t\n",
            "N_S: \t4\t\n",
            "N_T: \t8\t\n",
            "groups: \t4\t\n",
            "epochs: \t51\t\n",
            "log_step: \t1\t\n",
            "lr: \t0.01\t\n",
            "(16, 10, 1, 64, 64)\n",
            "[[ 76  51  42 ...  69  65  66]\n",
            " [ 74  31  70 ...  32  67  80]\n",
            " [253  29  83 ...  40  40  55]\n",
            " ...\n",
            " [ 82  31  74 ...  49  71  57]\n",
            " [ 49  27  32 ...  44  35  56]\n",
            " [ 69  38  73 ...  71  76  92]]\n",
            "(64, 64)\n",
            "[[99 22 42 ... 58 48 68]\n",
            " [45 42 94 ... 19 77 74]\n",
            " [65 67 12 ... 33 49 64]\n",
            " ...\n",
            " [75 55 59 ... 53 87 65]\n",
            " [62 55 98 ... 37 48 43]\n",
            " [90 57 83 ... 82 98 75]]\n",
            "(64, 64)\n",
            "[[ 72  55  23 ...  37  72  64]\n",
            " [ 52  26 118 ...  22  64  57]\n",
            " [ 36  88  10 ...  48  71  52]\n",
            " ...\n",
            " [ 67  34  59 ...  50 102  43]\n",
            " [ 43  60  51 ...  49  19  63]\n",
            " [ 91  79  89 ...  67  80  68]]\n",
            "(64, 64)\n",
            "[[ 98  86  59 ...  70  65  61]\n",
            " [ 69  28  97 ...  43  91  61]\n",
            " [ 39  83  40 ...  28  35  59]\n",
            " ...\n",
            " [ 61  42  49 ...  26 103  75]\n",
            " [ 41  67  50 ...  98  49  61]\n",
            " [ 85  62  82 ...  74  74  89]]\n",
            "(64, 64)\n",
            "[[ 89  55  34 ...  71  63  64]\n",
            " [ 81  25 122 ...  25  80  74]\n",
            " [ 41   9  45 ... 242  64  56]\n",
            " ...\n",
            " [ 60  46  82 ...  49  66  70]\n",
            " [ 55  32  85 ...  47  30  53]\n",
            " [ 81  79  79 ...  66  83  78]]\n",
            "(64, 64)\n",
            "[[ 65  43  31 ...  57  61  76]\n",
            " [ 72  21  95 ...  36  74  70]\n",
            " [ 34  20  74 ...  72  24  52]\n",
            " ...\n",
            " [100  44  71 ...  64  68  79]\n",
            " [ 60  51  57 ...  52  42  58]\n",
            " [ 77  56  77 ...  71  83  92]]\n",
            "(64, 64)\n",
            "[[ 72  50  50 ...  69  73  71]\n",
            " [ 45  37 102 ...  35  80  69]\n",
            " [ 55  58  10 ...  62  28  54]\n",
            " ...\n",
            " [106  34  74 ...  64  85  69]\n",
            " [ 39  68  49 ...  67  40  70]\n",
            " [ 78  75 100 ...  50  83  96]]\n",
            "(64, 64)\n",
            "[[ 74  50   4 ...  57  35  64]\n",
            " [ 62 247  93 ...  50  84  81]\n",
            " [ 35  75  46 ...  91  42  61]\n",
            " ...\n",
            " [ 68  25  58 ...  42  74  67]\n",
            " [ 55  61  52 ...  30  30  47]\n",
            " [ 90  56  70 ...  69  77  86]]\n",
            "(64, 64)\n",
            "[[ 79  37  13 ...  40  56  71]\n",
            " [ 74  32 145 ...  29  69  64]\n",
            " [ 65  72 247 ...  32  39  48]\n",
            " ...\n",
            " [ 83  39  47 ...  52 100  47]\n",
            " [ 58  76  52 ...  63  30  60]\n",
            " [ 89  51  78 ...  69  97  70]]\n",
            "(64, 64)\n",
            "[[ 73  38  55 ...  19  67  70]\n",
            " [ 82  21 103 ...  12  79  61]\n",
            " [ 37  51  14 ...  44  37  69]\n",
            " ...\n",
            " [ 84  55  46 ...  44  58  68]\n",
            " [ 48  66  66 ...  68  36  71]\n",
            " [ 75  60  98 ...  71  77  89]]\n",
            "(64, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Trainning with Moving MNIST dataset"
      ],
      "metadata": {
        "id": "pvsZ3mzo9BxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmpXMxrMC50q",
        "outputId": "df4d1b2a-60da-4386-d27e-d84acce32a53"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects:  33% (1/3)\u001b[K\rremote: Counting objects:  66% (2/3)\u001b[K\rremote: Counting objects: 100% (3/3)\u001b[K\rremote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects:  33% (1/3)   \rUnpacking objects:  66% (2/3)   \rUnpacking objects: 100% (3/3)   \rUnpacking objects: 100% (3/3), done.\n",
            "From https://github.com/trieuduongle/SimVP-Simpler-yet-Better-Video-Prediction\n",
            "   6a1f6ba..7d4084c  generative-approach -> origin/generative-approach\n",
            "Updating 6a1f6ba..7d4084c\n",
            "Fast-forward\n",
            " adversarial_loss.py | 3 \u001b[32m++\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 2 insertions(+), 1 deletion(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KqQEKFi0jG9",
        "outputId": "2919a179-2ab5-4844-dd07-ac75ffbe2d5c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hickle==5.0.2\n",
            "  Downloading hickle-5.0.2-py3-none-any.whl (107 kB)\n",
            "\u001b[K     |████████████████████████████████| 107 kB 14.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm==4.64.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (4.64.1)\n",
            "Collecting scikit-image==0.19.3\n",
            "  Downloading scikit_image-0.19.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.0 MB 60.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy!=1.20,>=1.8 in /usr/local/lib/python3.8/dist-packages (from hickle==5.0.2->-r requirements.txt (line 1)) (1.21.6)\n",
            "Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.8/dist-packages (from hickle==5.0.2->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3->-r requirements.txt (line 3)) (2021.11.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3->-r requirements.txt (line 3)) (21.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3->-r requirements.txt (line 3)) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3->-r requirements.txt (line 3)) (1.7.3)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3->-r requirements.txt (line 3)) (2.9.0)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3->-r requirements.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->scikit-image==0.19.3->-r requirements.txt (line 3)) (3.0.9)\n",
            "Installing collected packages: scikit-image, hickle\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.3\n",
            "    Uninstalling scikit-image-0.18.3:\n",
            "      Successfully uninstalled scikit-image-0.18.3\n",
            "Successfully installed hickle-5.0.2 scikit-image-0.19.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout generative-approach"
      ],
      "metadata": {
        "id": "3XJt_93CJGHW",
        "outputId": "3a38d6eb-0843-4fc1-982a-b9070174d8a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Branch 'generative-approach' set up to track remote branch 'generative-approach' from 'origin'.\n",
            "Switched to a new branch 'generative-approach'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py \\\n",
        "  --res_dir './results/mnist/20221203-lan-ba-generative' \\\n",
        "  --data_root '/content/drive/My Drive/Duong/datasets/' \\\n",
        "  --dataname 'mmnist' \\\n",
        "  --num_workers 8 \\\n",
        "  --batch_size 16 \\\n",
        "  --epochs 11 \\\n",
        "  --save_epoch_freq 10\\\n",
        "  --in_shape 10 1 64 64 \\\n",
        "  --pre_seq_length 10 \\\n",
        "  --aft_seq_length 10"
      ],
      "metadata": {
        "id": "EJ-upBDx71pO",
        "outputId": "d3b446b3-da40-4bb4-ba47-4fd648a55c61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use GPU: 0\n",
            "including adv loss\n",
            "\n",
            "device: \tcuda\t\n",
            "res_dir: \t./results/mnist/20221203-lan-ba-generative\t\n",
            "ex_name: \tDebug\t\n",
            "use_gpu: \tTrue\t\n",
            "gpu: \t0\t\n",
            "seed: \t1\t\n",
            "batch_size: \t16\t\n",
            "val_batch_size: \t16\t\n",
            "data_root: \t/content/drive/My Drive/Duong/datasets/\t\n",
            "dataname: \tmmnist\t\n",
            "num_workers: \t8\t\n",
            "in_shape: \t[10, 1, 64, 64]\t\n",
            "hid_S: \t64\t\n",
            "hid_T: \t256\t\n",
            "N_S: \t4\t\n",
            "N_T: \t8\t\n",
            "groups: \t4\t\n",
            "pre_seq_length: \t10\t\n",
            "aft_seq_length: \t10\t\n",
            "epochs: \t11\t\n",
            "log_step: \t1\t\n",
            "save_epoch_freq: \t10\t\n",
            "lr: \t0.01\t\n",
            "resume_path: \t\t\n",
            "lr_D: \t0.0001\t\n",
            "gan_type: \tWGAN_GP\t\n",
            "lambda_adv: \t0.005\t\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>  start <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "  0% 0/625 [00:00<?, ?it/s]adv traning\n",
            "torch.Size([16, 10, 1, 64, 64])\n",
            "  0% 0/625 [00:03<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 14, in <module>\n",
            "    exp.train(args)\n",
            "  File \"/content/drive/MyDrive/Duong/SimVP/code/exp.py\", line 139, in train\n",
            "    adv_loss, d_loss = self.criterion_adv(pred_y, batch_y)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/drive/MyDrive/Duong/SimVP/code/adversarial_loss.py\", line 172, in forward\n",
            "    d_fake = self.discriminator(fake).detach()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/drive/MyDrive/Duong/SimVP/code/adversarial_loss.py\", line 129, in forward\n",
            "    validity = self.model(img_flat)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\", line 139, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "RuntimeError: mat1 and mat2 shapes cannot be multiplied (1x655360 and 40960x512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull && python interpolate.py \\\n",
        "  --data_root '/content/drive/My Drive/Duong/datasets/' \\\n",
        "  --resume_path './results/mnist/20221203-lan-hai/Debug/checkpoints/51.pth'"
      ],
      "metadata": {
        "id": "pO2tW7f1LCum",
        "outputId": "c2dd308b-69c7-40dd-998e-c3729d8e3d0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n",
            "Use GPU: 0\n",
            "resuming\n",
            "\n",
            "device: \tcuda\t\n",
            "res_dir: \t./results\t\n",
            "ex_name: \tDebug\t\n",
            "use_gpu: \tTrue\t\n",
            "gpu: \t0\t\n",
            "seed: \t1\t\n",
            "batch_size: \t16\t\n",
            "val_batch_size: \t16\t\n",
            "data_root: \t/content/drive/My Drive/Duong/datasets/\t\n",
            "dataname: \tmmnist\t\n",
            "num_workers: \t8\t\n",
            "in_shape: \t[10, 1, 64, 64]\t\n",
            "hid_S: \t64\t\n",
            "hid_T: \t256\t\n",
            "N_S: \t4\t\n",
            "N_T: \t8\t\n",
            "groups: \t4\t\n",
            "epochs: \t51\t\n",
            "log_step: \t1\t\n",
            "save_epoch_freq: \t10\t\n",
            "lr: \t0.01\t\n",
            "resume_path: \t./results/mnist/20221203-lan-hai/Debug/checkpoints/51.pth\t\n",
            "(16, 10, 1, 64, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traning with KTH dataset"
      ],
      "metadata": {
        "id": "73U9z7Fazp94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/My Drive/Duong/datasets/kth.zip' -d '/content/drive/My Drive/Duong/datasets/kth'"
      ],
      "metadata": {
        "id": "xmo39p-uyn2h",
        "outputId": "7e5fb337-a81b-4f93-bdbb-f38ff0405419",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/My Drive/Duong/datasets/kth.zip\n",
            "warning:  stripped absolute path spec from /\n",
            "mapname:  conversion of  failed\n",
            " extracting: /content/drive/My Drive/Duong/datasets/kth/dataloader_kth.py  \n",
            " extracting: /content/drive/My Drive/Duong/datasets/kth/test_data_gzip.hkl  \n",
            " extracting: /content/drive/My Drive/Duong/datasets/kth/train_data_gzip.hkl  \n",
            " extracting: /content/drive/My Drive/Duong/datasets/kth/test_indices_gzip.hkl  \n",
            " extracting: /content/drive/My Drive/Duong/datasets/kth/train_indices_gzip.hkl  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hickle"
      ],
      "metadata": {
        "id": "y5gsFHkQ2lRC",
        "outputId": "7aed2756-6e3f-4541-8c3d-059f340357ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hickle\n",
            "  Downloading hickle-5.0.2-py3-none-any.whl (107 kB)\n",
            "\u001b[K     |████████████████████████████████| 107 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy!=1.20,>=1.8 in /usr/local/lib/python3.8/dist-packages (from hickle) (1.21.6)\n",
            "Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.8/dist-packages (from hickle) (3.1.0)\n",
            "Installing collected packages: hickle\n",
            "Successfully installed hickle-5.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py \\\n",
        "  --res_dir './results/20221203' \\\n",
        "  --data_root '/content/drive/My Drive/Duong/datasets/kth/' \\\n",
        "  --dataname 'kth' \\\n",
        "  --num_workers 1 \\\n",
        "  --batch_size 8 \\\n",
        "  --in_shape 10 1 128 128"
      ],
      "metadata": {
        "id": "IdLLvosiztz6",
        "outputId": "016df212-be82-44c1-d51c-480c584ec023",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use GPU: 0\n",
            "exist\n",
            "tcmalloc: large alloc 16681664512 bytes == 0x6478000 @  0x7f8fcffde1e7 0x7f8f5ffd414e 0x7f8f6002c745 0x7f8f5ffd79c8 0x5d7f65 0x560200 0x55e571 0x4eae40 0x7f8f2ea70f05 0x5d813c 0x4ff485 0x46eb22 0x59daf9 0x5176d9 0x55fa11 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x5d77c6 0x561051\n",
            "tcmalloc: large alloc 16681664512 bytes == 0x3fc394000 @  0x7f8fcffde1e7 0x7f8f5ffd414e 0x7f8f60030166 0x7f8f60022665 0x7f8f600d3640 0x5aa114 0x49ced5 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x5d77c6 0x561051 0x5d7c18 0x49ca7c 0x5d7c18 0x49ca7c 0x55e858 0x5d7cf1 0x5d9412 0x586306\n",
            "tcmalloc: large alloc 9808510976 bytes == 0x63f6000 @  0x7f8fcffde1e7 0x7f8f5ffd414e 0x7f8f6002c745 0x7f8f5ffd79c8 0x5d7f65 0x560200 0x55e571 0x4eae40 0x7f8f2ea70f05 0x5d813c 0x4ff485 0x46eb22 0x59daf9 0x5176d9 0x55fa11 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x5d77c6 0x561051\n",
            "tcmalloc: large alloc 9808510976 bytes == 0x7dfab6000 @  0x7f8fcffde1e7 0x7f8f5ffd414e 0x7f8f60030166 0x7f8f60022665 0x7f8f600d3640 0x5aa114 0x49ced5 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x5d77c6 0x561051 0x5d7c18 0x49ca7c 0x5d7c18 0x49ca7c 0x55e858 0x5d7cf1 0x5d9412 0x586306\n",
            "\n",
            "device: \tcuda\t\n",
            "res_dir: \t./results/20221203\t\n",
            "ex_name: \tDebug\t\n",
            "use_gpu: \tTrue\t\n",
            "gpu: \t0\t\n",
            "seed: \t1\t\n",
            "batch_size: \t8\t\n",
            "val_batch_size: \t16\t\n",
            "data_root: \t/content/drive/My Drive/Duong/datasets/kth/\t\n",
            "dataname: \tkth\t\n",
            "num_workers: \t1\t\n",
            "in_shape: \t[10, 1, 128, 128]\t\n",
            "hid_S: \t64\t\n",
            "hid_T: \t256\t\n",
            "N_S: \t4\t\n",
            "N_T: \t8\t\n",
            "groups: \t4\t\n",
            "epochs: \t51\t\n",
            "log_step: \t1\t\n",
            "save_epoch_freq: \t10\t\n",
            "lr: \t0.01\t\n",
            "exist\n",
            "tcmalloc: large alloc 16681664512 bytes == 0x7f8acbb20000 @  0x7f8fcffde1e7 0x7f8f5ffd414e 0x7f8f6002c745 0x7f8f5ffd79c8 0x5d7f65 0x560200 0x55e571 0x4eae40 0x7f8f2ea70f05 0x5d813c 0x4ff485 0x46eb22 0x59daf9 0x5176d9 0x55fa11 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x5d77c6 0x561051\n",
            "tcmalloc: large alloc 16681664512 bytes == 0x7f86e9640000 @  0x7f8fcffde1e7 0x7f8f5ffd414e 0x7f8f60030166 0x7f8f60022665 0x7f8f600d3640 0x5aa114 0x49ced5 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x5d77c6 0x561051 0x5d7c18 0x49ca7c 0x55e858 0x5d7cf1 0x5d9412 0x586306 0x5d808f 0x55f3fd\n",
            "tcmalloc: large alloc 9808510976 bytes == 0x539d4000 @  0x7f8fcffde1e7 0x7f8f5ffd414e 0x7f8f6002c745 0x7f8f5ffd79c8 0x5d7f65 0x560200 0x55e571 0x4eae40 0x7f8f2ea70f05 0x5d813c 0x4ff485 0x46eb22 0x59daf9 0x5176d9 0x55fa11 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x5d77c6 0x561051\n",
            "tcmalloc: large alloc 9808510976 bytes == 0x7f8acbb20000 @  0x7f8fcffde1e7 0x7f8f5ffd414e 0x7f8f60030166 0x7f8f60022665 0x7f8f600d3640 0x5aa114 0x49ced5 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x5d77c6 0x561051 0x5d7c18 0x49ca7c 0x55e858 0x5d7cf1 0x5d9412 0x586306 0x5d808f 0x55f3fd\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>  start <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "  0% 0/650 [00:08<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 46, in <module>\n",
            "    exp.train(args)\n",
            "  File \"/content/drive/MyDrive/Duong/SimVP/code/exp.py\", line 104, in train\n",
            "    loss = self.criterion(pred_y, batch_y)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py\", line 530, in forward\n",
            "    return F.mse_loss(input, target, reduction=self.reduction)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 3279, in mse_loss\n",
            "    expanded_input, expanded_target = torch.broadcast_tensors(input, target)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/functional.py\", line 73, in broadcast_tensors\n",
            "    return _VF.broadcast_tensors(tensors)  # type: ignore[attr-defined]\n",
            "RuntimeError: The size of tensor a (10) must match the size of tensor b (20) at non-singleton dimension 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/My Drive/Duong/datasets/kth'"
      ],
      "metadata": {
        "id": "Ii2kRUcy3-0h",
        "outputId": "03bab3be-ad6c-4a25-ee7c-cc8c71ffed74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataloader_kth.py   test_indices_gzip.hkl  train_indices_gzip.hkl\n",
            "test_data_gzip.hkl  train_data_gzip.hkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Try to run model"
      ],
      "metadata": {
        "id": "_GZX1vhNsq0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "id": "JsQ_SKEUst1A",
        "outputId": "a1ae6996-5aac-4eac-eb4a-8afa1c33e790",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 51, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/51)\u001b[K\rremote: Counting objects:   3% (2/51)\u001b[K\rremote: Counting objects:   5% (3/51)\u001b[K\rremote: Counting objects:   7% (4/51)\u001b[K\rremote: Counting objects:   9% (5/51)\u001b[K\rremote: Counting objects:  11% (6/51)\u001b[K\rremote: Counting objects:  13% (7/51)\u001b[K\rremote: Counting objects:  15% (8/51)\u001b[K\rremote: Counting objects:  17% (9/51)\u001b[K\rremote: Counting objects:  19% (10/51)\u001b[K\rremote: Counting objects:  21% (11/51)\u001b[K\rremote: Counting objects:  23% (12/51)\u001b[K\rremote: Counting objects:  25% (13/51)\u001b[K\rremote: Counting objects:  27% (14/51)\u001b[K\rremote: Counting objects:  29% (15/51)\u001b[K\rremote: Counting objects:  31% (16/51)\u001b[K\rremote: Counting objects:  33% (17/51)\u001b[K\rremote: Counting objects:  35% (18/51)\u001b[K\rremote: Counting objects:  37% (19/51)\u001b[K\rremote: Counting objects:  39% (20/51)\u001b[K\rremote: Counting objects:  41% (21/51)\u001b[K\rremote: Counting objects:  43% (22/51)\u001b[K\rremote: Counting objects:  45% (23/51)\u001b[K\rremote: Counting objects:  47% (24/51)\u001b[K\rremote: Counting objects:  49% (25/51)\u001b[K\rremote: Counting objects:  50% (26/51)\u001b[K\rremote: Counting objects:  52% (27/51)\u001b[K\rremote: Counting objects:  54% (28/51)\u001b[K\rremote: Counting objects:  56% (29/51)\u001b[K\rremote: Counting objects:  58% (30/51)\u001b[K\rremote: Counting objects:  60% (31/51)\u001b[K\rremote: Counting objects:  62% (32/51)\u001b[K\rremote: Counting objects:  64% (33/51)\u001b[K\rremote: Counting objects:  66% (34/51)\u001b[K\rremote: Counting objects:  68% (35/51)\u001b[K\rremote: Counting objects:  70% (36/51)\u001b[K\rremote: Counting objects:  72% (37/51)\u001b[K\rremote: Counting objects:  74% (38/51)\u001b[K\rremote: Counting objects:  76% (39/51)\u001b[K\rremote: Counting objects:  78% (40/51)\u001b[K\rremote: Counting objects:  80% (41/51)\u001b[K\rremote: Counting objects:  82% (42/51)\u001b[K\rremote: Counting objects:  84% (43/51)\u001b[K\rremote: Counting objects:  86% (44/51)\u001b[K\rremote: Counting objects:  88% (45/51)\u001b[K\rremote: Counting objects:  90% (46/51)\u001b[K\rremote: Counting objects:  92% (47/51)\u001b[K\rremote: Counting objects:  94% (48/51)\u001b[K\rremote: Counting objects:  96% (49/51)\u001b[K\rremote: Counting objects:  98% (50/51)\u001b[K\rremote: Counting objects: 100% (51/51)\u001b[K\rremote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects:   3% (1/28)\u001b[K\rremote: Compressing objects:   7% (2/28)\u001b[K\rremote: Compressing objects:  10% (3/28)\u001b[K\rremote: Compressing objects:  14% (4/28)\u001b[K\rremote: Compressing objects:  17% (5/28)\u001b[K\rremote: Compressing objects:  21% (6/28)\u001b[K\rremote: Compressing objects:  25% (7/28)\u001b[K\rremote: Compressing objects:  28% (8/28)\u001b[K\rremote: Compressing objects:  32% (9/28)\u001b[K\rremote: Compressing objects:  35% (10/28)\u001b[K\rremote: Compressing objects:  39% (11/28)\u001b[K\rremote: Compressing objects:  42% (12/28)\u001b[K\rremote: Compressing objects:  46% (13/28)\u001b[K\rremote: Compressing objects:  50% (14/28)\u001b[K\rremote: Compressing objects:  53% (15/28)\u001b[K\rremote: Compressing objects:  57% (16/28)\u001b[K\rremote: Compressing objects:  60% (17/28)\u001b[K\rremote: Compressing objects:  64% (18/28)\u001b[K\rremote: Compressing objects:  67% (19/28)\u001b[K\rremote: Compressing objects:  71% (20/28)\u001b[K\rremote: Compressing objects:  75% (21/28)\u001b[K\rremote: Compressing objects:  78% (22/28)\u001b[K\rremote: Compressing objects:  82% (23/28)\u001b[K\rremote: Compressing objects:  85% (24/28)\u001b[K\rremote: Compressing objects:  89% (25/28)\u001b[K\rremote: Compressing objects:  92% (26/28)\u001b[K\rremote: Compressing objects:  96% (27/28)\u001b[K\rremote: Compressing objects: 100% (28/28)\u001b[K\rremote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 41 (delta 27), reused 22 (delta 12), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (41/41), done.\n",
            "From https://github.com/trieuduongle/SimVP-Simpler-yet-Better-Video-Prediction\n",
            "   f07a3d2..36c3530  colab      -> origin/colab\n",
            "Updating f07a3d2..36c3530\n",
            "Fast-forward\n",
            " API/dataloader.py              |   9 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " API/dataloader_kth.py          |   4 \u001b[32m+\u001b[m\n",
            " API/dataloader_moving_mnist.py |   4 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " SimVP.ipynb                    | 665 \u001b[32m+++++++++++++++++++++++++++++++++++++++\u001b[m\u001b[31m--\u001b[m\n",
            " create_parser.py               |  45 \u001b[32m+++\u001b[m\n",
            " exp.py                         |  10 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " fake_training.py               | 131 \u001b[32m++++++++\u001b[m\n",
            " interpolate.py                 |   9 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " main.py                        |   2 \u001b[32m+\u001b[m\n",
            " requirements.txt               |   4 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 10 files changed, 847 insertions(+), 36 deletions(-)\n",
            " create mode 100644 create_parser.py\n",
            " create mode 100644 fake_training.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py \\\n",
        "  --res_dir './results/fake_training/' \\\n",
        "  --data_root '/content/drive/My Drive/Duong/datasets/' \\\n",
        "  --dataname 'mmnist' \\\n",
        "  --num_workers 8 \\\n",
        "  --batch_size 16 \\\n",
        "  --save_epoch_freq 2\\\n",
        "  --in_shape 10 1 64 64"
      ],
      "metadata": {
        "id": "oDf17M5msvnM",
        "outputId": "8899df8b-92f6-49d9-e7cd-6d6a984278e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use GPU: 0\n",
            "\n",
            "device: \tcuda\t\n",
            "res_dir: \t./results/fake_training/\t\n",
            "ex_name: \tDebug\t\n",
            "use_gpu: \tTrue\t\n",
            "gpu: \t0\t\n",
            "seed: \t1\t\n",
            "batch_size: \t16\t\n",
            "val_batch_size: \t16\t\n",
            "data_root: \t/content/drive/My Drive/Duong/datasets/\t\n",
            "dataname: \tmmnist\t\n",
            "num_workers: \t8\t\n",
            "in_shape: \t[10, 1, 64, 64]\t\n",
            "hid_S: \t64\t\n",
            "hid_T: \t256\t\n",
            "N_S: \t4\t\n",
            "N_T: \t8\t\n",
            "groups: \t4\t\n",
            "epochs: \t51\t\n",
            "log_step: \t1\t\n",
            "save_epoch_freq: \t2\t\n",
            "lr: \t0.01\t\n",
            "resume_path: \t\t\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>  start <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "  0% 0/625 [00:00<?, ?it/s]longger\n",
            "train loss: 0.1219:   0% 1/625 [00:05<1:00:43,  5.84s/it]longger\n",
            "train loss: 0.5743:   0% 2/625 [00:07<32:35,  3.14s/it]  longger\n",
            "train loss: 0.1668:   0% 3/625 [00:08<23:36,  2.28s/it]longger\n",
            "train loss: 0.0751:   1% 4/625 [00:09<19:24,  1.88s/it]longger\n",
            "train loss: 0.1162:   1% 5/625 [00:10<17:05,  1.65s/it]longger\n",
            "train loss: 0.1168:   1% 6/625 [00:12<15:41,  1.52s/it]longger\n",
            "train loss: 0.0851:   1% 7/625 [00:13<14:48,  1.44s/it]longger\n",
            "train loss: 0.0640:   1% 8/625 [00:14<14:14,  1.38s/it]longger\n",
            "train loss: 0.0572:   1% 9/625 [00:15<13:51,  1.35s/it]longger\n",
            "train loss: 0.0524:   2% 10/625 [00:17<13:36,  1.33s/it]longger\n",
            "train loss: 0.0566:   2% 10/625 [00:18<19:00,  1.86s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 47, in <module>\n",
            "    exp.train(args)\n",
            "  File \"/content/drive/MyDrive/Duong/SimVP/code/exp.py\", line 137, in train\n",
            "    self.optimizer.step()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 113, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 157, in step\n",
            "    adam(params_with_grad,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 213, in adam\n",
            "    func(params,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 305, in _single_tensor_adam\n",
            "    denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}