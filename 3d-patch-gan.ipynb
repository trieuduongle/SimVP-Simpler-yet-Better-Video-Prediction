{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trieuduongle/SimVP-Simpler-yet-Better-Video-Prediction/blob/3d-patch-gan/3d-patch-gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLrjGVvQWNxH",
        "outputId": "b4c18b90-3508-4e2a-a794-98ca51c0be7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/trieuduongle/SimVP-Simpler-yet-Better-Video-Prediction.git '/content/drive/My Drive/Duong/SimVP/code'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ8IXIA9WeV0",
        "outputId": "c831b15f-e65d-48b6-9702-f27d98c49b2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path '/content/drive/My Drive/Duong/SimVP/code' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/My Drive/Duong/SimVP/code'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snonURDKWpwk",
        "outputId": "7b318d92-ff75-4050-fe81-fae0543cc7d4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Duong/SimVP/code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.device_count()\n",
        "torch.cuda.is_available()\n",
        "torch.cuda.current_device()\n",
        "torch.cuda.device(0)\n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "id": "7wh_1WQhfFu4",
        "outputId": "99f5348d-8836-4706-d8ea-cc8ae5101e04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git fetch origin && git checkout 3d-patch-gan && git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyuC_ecGWmcU",
        "outputId": "9a96775b-6974-4177-f27d-f5caf7bc2780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects:   8% (1/12)\u001b[K\rremote: Counting objects:  16% (2/12)\u001b[K\rremote: Counting objects:  25% (3/12)\u001b[K\rremote: Counting objects:  33% (4/12)\u001b[K\rremote: Counting objects:  41% (5/12)\u001b[K\rremote: Counting objects:  50% (6/12)\u001b[K\rremote: Counting objects:  58% (7/12)\u001b[K\rremote: Counting objects:  66% (8/12)\u001b[K\rremote: Counting objects:  75% (9/12)\u001b[K\rremote: Counting objects:  83% (10/12)\u001b[K\rremote: Counting objects:  91% (11/12)\u001b[K\rremote: Counting objects: 100% (12/12)\u001b[K\rremote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects:  14% (1/7)\u001b[K\rremote: Compressing objects:  28% (2/7)\u001b[K\rremote: Compressing objects:  42% (3/7)\u001b[K\rremote: Compressing objects:  57% (4/7)\u001b[K\rremote: Compressing objects:  71% (5/7)\u001b[K\rremote: Compressing objects:  85% (6/7)\u001b[K\rremote: Compressing objects: 100% (7/7)\u001b[K\rremote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 12 (delta 4), reused 12 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (12/12), done.\n",
            "From https://github.com/trieuduongle/SimVP-Simpler-yet-Better-Video-Prediction\n",
            " * [new branch]      3d-patch-gan -> origin/3d-patch-gan\n",
            "Checking out files: 100% (9/9), done.\n",
            "Branch '3d-patch-gan' set up to track remote branch '3d-patch-gan' from 'origin'.\n",
            "Switched to a new branch '3d-patch-gan'\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash \"./data/moving_mnist/download_mmnist.sh\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SY1EmwzxWzGa",
        "outputId": "d143182a-f5da-4bea-a688-54c120b0a7a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-02 18:06:52--  http://www.cs.toronto.edu/~nitish/unsupervised_video/mnist_test_seq.npy\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 819200096 (781M)\n",
            "Saving to: ‘mnist_test_seq.npy’\n",
            "\n",
            "mnist_test_seq.npy  100%[===================>] 781.25M  9.28MB/s    in 41s     \n",
            "\n",
            "2022-12-02 18:07:33 (19.1 MB/s) - ‘mnist_test_seq.npy’ saved [819200096/819200096]\n",
            "\n",
            "--2022-12-02 18:07:33--  http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Resolving yann.lecun.com (yann.lecun.com)... 172.67.171.76, 104.21.29.36, 2606:4700:3034::6815:1d24, ...\n",
            "Connecting to yann.lecun.com (yann.lecun.com)|172.67.171.76|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9912422 (9.5M) [application/x-gzip]\n",
            "Saving to: ‘train-images-idx3-ubyte.gz’\n",
            "\n",
            "train-images-idx3-u 100%[===================>]   9.45M  61.6MB/s    in 0.2s    \n",
            "\n",
            "2022-12-02 18:07:34 (61.6 MB/s) - ‘train-images-idx3-ubyte.gz’ saved [9912422/9912422]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mXZl8SCBd2x",
        "outputId": "b06e79b3-4bd1-4078-9f03-18eb1625f09e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API\t\t main.py\t     readme_figures\t\t utils.py\n",
            "data\t\t mnist_test_seq.npy  README.md\n",
            "environment.yml  model.py\t     SimVP.ipynb\n",
            "exp.py\t\t modules.py\t     train-images-idx3-ubyte.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --batch_size 64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgflhFiSXuHA",
        "outputId": "9399cfd3-f815-456e-e2a3-4753331d5cbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use GPU: 0\n",
            "\n",
            "device: \tcuda\t\n",
            "res_dir: \t./results\t\n",
            "ex_name: \tDebug\t\n",
            "use_gpu: \tTrue\t\n",
            "gpu: \t0\t\n",
            "seed: \t1\t\n",
            "batch_size: \t64\t\n",
            "val_batch_size: \t16\t\n",
            "data_root: \t./data/\t\n",
            "dataname: \tmmnist\t\n",
            "num_workers: \t8\t\n",
            "in_shape: \t[10, 1, 64, 64]\t\n",
            "hid_S: \t64\t\n",
            "hid_T: \t256\t\n",
            "N_S: \t4\t\n",
            "N_T: \t8\t\n",
            "groups: \t4\t\n",
            "epochs: \t51\t\n",
            "log_step: \t1\t\n",
            "lr: \t0.01\t\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>  start <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "train loss: 0.0337: 100% 157/157 [00:44<00:00,  3.54it/s]\n",
            "vali loss: 0.0310:  10% 63/625 [00:03<00:27, 20.68it/s]\n",
            "vali mse:137.6444, mae:346.0001, ssim:0.4469, psnr:31.2841\n",
            "Epoch: 1 | Train Loss: 0.0460 Vali Loss: 0.0336\n",
            "\n",
            "Validation loss decreased (inf --> 0.033605).  Saving model ...\n",
            "train loss: 0.0313: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0286:  10% 63/625 [00:03<00:28, 19.47it/s]\n",
            "vali mse:126.3827, mae:296.9196, ssim:0.5107, psnr:32.2142\n",
            "Epoch: 2 | Train Loss: 0.0313 Vali Loss: 0.0309\n",
            "\n",
            "Validation loss decreased (0.033605 --> 0.030855).  Saving model ...\n",
            "train loss: 0.0283: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0269:  10% 63/625 [00:03<00:28, 19.89it/s]\n",
            "vali mse:118.7211, mae:278.7345, ssim:0.5592, psnr:32.8707\n",
            "Epoch: 3 | Train Loss: 0.0293 Vali Loss: 0.0290\n",
            "\n",
            "Validation loss decreased (0.030855 --> 0.028985).  Saving model ...\n",
            "train loss: 0.0287: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0264:  10% 63/625 [00:03<00:28, 19.55it/s]\n",
            "vali mse:117.5775, mae:265.8234, ssim:0.6161, psnr:33.4710\n",
            "Epoch: 4 | Train Loss: 0.0282 Vali Loss: 0.0287\n",
            "\n",
            "Validation loss decreased (0.028985 --> 0.028706).  Saving model ...\n",
            "train loss: 0.0263: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0261:  10% 63/625 [00:03<00:28, 19.55it/s]\n",
            "vali mse:113.0489, mae:255.9769, ssim:0.6222, psnr:33.6774\n",
            "Epoch: 5 | Train Loss: 0.0274 Vali Loss: 0.0276\n",
            "\n",
            "Validation loss decreased (0.028706 --> 0.027600).  Saving model ...\n",
            "train loss: 0.0278: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0254:  10% 63/625 [00:03<00:28, 19.75it/s]\n",
            "vali mse:108.6772, mae:268.7874, ssim:0.5823, psnr:33.3547\n",
            "Epoch: 6 | Train Loss: 0.0265 Vali Loss: 0.0265\n",
            "\n",
            "Validation loss decreased (0.027600 --> 0.026533).  Saving model ...\n",
            "train loss: 0.0257: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0237:  10% 63/625 [00:03<00:28, 19.47it/s]\n",
            "vali mse:103.5582, mae:250.0797, ssim:0.6322, psnr:33.7852\n",
            "Epoch: 7 | Train Loss: 0.0255 Vali Loss: 0.0253\n",
            "\n",
            "Validation loss decreased (0.026533 --> 0.025283).  Saving model ...\n",
            "train loss: 0.0232: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0229:  10% 63/625 [00:03<00:28, 19.39it/s]\n",
            "vali mse:99.2328, mae:234.3316, ssim:0.6954, psnr:34.5845\n",
            "Epoch: 8 | Train Loss: 0.0246 Vali Loss: 0.0242\n",
            "\n",
            "Validation loss decreased (0.025283 --> 0.024227).  Saving model ...\n",
            "train loss: 0.0225: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0222:  10% 63/625 [00:03<00:28, 19.58it/s]\n",
            "vali mse:94.9563, mae:249.7297, ssim:0.5827, psnr:33.6404\n",
            "Epoch: 9 | Train Loss: 0.0233 Vali Loss: 0.0232\n",
            "\n",
            "Validation loss decreased (0.024227 --> 0.023183).  Saving model ...\n",
            "train loss: 0.0225: 100% 157/157 [00:37<00:00,  4.24it/s]\n",
            "vali loss: 0.0218:  10% 63/625 [00:03<00:29, 19.19it/s]\n",
            "vali mse:93.5796, mae:220.0360, ssim:0.7582, psnr:35.3514\n",
            "Epoch: 10 | Train Loss: 0.0225 Vali Loss: 0.0228\n",
            "\n",
            "Validation loss decreased (0.023183 --> 0.022847).  Saving model ...\n",
            "train loss: 0.0222: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0221:  10% 63/625 [00:03<00:28, 19.44it/s]\n",
            "vali mse:92.0262, mae:232.9030, ssim:0.7741, psnr:35.7236\n",
            "Epoch: 11 | Train Loss: 0.0218 Vali Loss: 0.0225\n",
            "\n",
            "Validation loss decreased (0.022847 --> 0.022467).  Saving model ...\n",
            "train loss: 0.0215: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0207:  10% 63/625 [00:03<00:29, 19.34it/s]\n",
            "vali mse:86.8812, mae:218.1367, ssim:0.7721, psnr:35.5152\n",
            "Epoch: 12 | Train Loss: 0.0212 Vali Loss: 0.0212\n",
            "\n",
            "Validation loss decreased (0.022467 --> 0.021211).  Saving model ...\n",
            "train loss: 0.0220: 100% 157/157 [00:37<00:00,  4.22it/s]\n",
            "vali loss: 0.0198:  10% 63/625 [00:03<00:28, 19.52it/s]\n",
            "vali mse:84.9514, mae:198.9120, ssim:0.7663, psnr:35.3256\n",
            "Epoch: 13 | Train Loss: 0.0209 Vali Loss: 0.0207\n",
            "\n",
            "Validation loss decreased (0.021211 --> 0.020740).  Saving model ...\n",
            "train loss: 0.0203: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0192:  10% 63/625 [00:03<00:28, 19.60it/s]\n",
            "vali mse:83.2834, mae:202.5196, ssim:0.7973, psnr:35.9497\n",
            "Epoch: 14 | Train Loss: 0.0202 Vali Loss: 0.0203\n",
            "\n",
            "Validation loss decreased (0.020740 --> 0.020333).  Saving model ...\n",
            "train loss: 0.0191: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0185:  10% 63/625 [00:03<00:28, 19.47it/s]\n",
            "vali mse:80.9647, mae:205.6377, ssim:0.7397, psnr:35.0482\n",
            "Epoch: 15 | Train Loss: 0.0197 Vali Loss: 0.0198\n",
            "\n",
            "Validation loss decreased (0.020333 --> 0.019767).  Saving model ...\n",
            "train loss: 0.0190: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0180:  10% 63/625 [00:03<00:28, 19.65it/s]\n",
            "vali mse:79.4775, mae:203.9977, ssim:0.7803, psnr:35.3456\n",
            "Epoch: 16 | Train Loss: 0.0193 Vali Loss: 0.0194\n",
            "\n",
            "Validation loss decreased (0.019767 --> 0.019404).  Saving model ...\n",
            "train loss: 0.0203: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0188:  10% 63/625 [00:03<00:28, 19.69it/s]\n",
            "vali mse:78.8270, mae:224.6094, ssim:0.6146, psnr:33.9823\n",
            "Epoch: 17 | Train Loss: 0.0189 Vali Loss: 0.0192\n",
            "\n",
            "Validation loss decreased (0.019404 --> 0.019245).  Saving model ...\n",
            "train loss: 0.0183: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0175:  10% 63/625 [00:03<00:28, 19.74it/s]\n",
            "vali mse:76.8339, mae:188.6660, ssim:0.7742, psnr:35.5812\n",
            "Epoch: 18 | Train Loss: 0.0186 Vali Loss: 0.0188\n",
            "\n",
            "Validation loss decreased (0.019245 --> 0.018758).  Saving model ...\n",
            "train loss: 0.0182: 100% 157/157 [00:37<00:00,  4.22it/s]\n",
            "vali loss: 0.0179:  10% 63/625 [00:03<00:28, 19.46it/s]\n",
            "vali mse:75.0394, mae:185.8936, ssim:0.7845, psnr:35.5812\n",
            "Epoch: 19 | Train Loss: 0.0184 Vali Loss: 0.0183\n",
            "\n",
            "Validation loss decreased (0.018758 --> 0.018320).  Saving model ...\n",
            "train loss: 0.0166: 100% 157/157 [00:37<00:00,  4.24it/s]\n",
            "vali loss: 0.0170:  10% 63/625 [00:03<00:28, 19.45it/s]\n",
            "vali mse:74.4794, mae:179.7516, ssim:0.8058, psnr:35.8249\n",
            "Epoch: 20 | Train Loss: 0.0180 Vali Loss: 0.0182\n",
            "\n",
            "Validation loss decreased (0.018320 --> 0.018184).  Saving model ...\n",
            "train loss: 0.0174: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0167:  10% 63/625 [00:03<00:28, 19.51it/s]\n",
            "vali mse:72.6940, mae:182.0740, ssim:0.7873, psnr:35.7151\n",
            "Epoch: 21 | Train Loss: 0.0178 Vali Loss: 0.0177\n",
            "\n",
            "Validation loss decreased (0.018184 --> 0.017748).  Saving model ...\n",
            "train loss: 0.0189: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0165:  10% 63/625 [00:03<00:28, 19.50it/s]\n",
            "vali mse:71.9190, mae:178.7111, ssim:0.8263, psnr:36.3520\n",
            "Epoch: 22 | Train Loss: 0.0175 Vali Loss: 0.0176\n",
            "\n",
            "Validation loss decreased (0.017748 --> 0.017558).  Saving model ...\n",
            "train loss: 0.0168: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0165:  10% 63/625 [00:03<00:28, 19.55it/s]\n",
            "vali mse:70.7945, mae:171.0153, ssim:0.8150, psnr:35.9789\n",
            "Epoch: 23 | Train Loss: 0.0172 Vali Loss: 0.0173\n",
            "\n",
            "Validation loss decreased (0.017558 --> 0.017284).  Saving model ...\n",
            "train loss: 0.0156: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0161:  10% 63/625 [00:03<00:28, 19.67it/s]\n",
            "vali mse:69.4670, mae:169.0605, ssim:0.8081, psnr:36.1257\n",
            "Epoch: 24 | Train Loss: 0.0171 Vali Loss: 0.0170\n",
            "\n",
            "Validation loss decreased (0.017284 --> 0.016960).  Saving model ...\n",
            "train loss: 0.0155: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0155:  10% 63/625 [00:03<00:28, 19.72it/s]\n",
            "vali mse:69.3838, mae:168.5445, ssim:0.8148, psnr:36.0635\n",
            "Epoch: 25 | Train Loss: 0.0169 Vali Loss: 0.0169\n",
            "\n",
            "Validation loss decreased (0.016960 --> 0.016940).  Saving model ...\n",
            "train loss: 0.0157: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0158:  10% 63/625 [00:03<00:28, 19.45it/s]\n",
            "vali mse:68.5109, mae:177.7370, ssim:0.7696, psnr:35.8291\n",
            "Epoch: 26 | Train Loss: 0.0166 Vali Loss: 0.0167\n",
            "\n",
            "Validation loss decreased (0.016940 --> 0.016726).  Saving model ...\n",
            "train loss: 0.0161: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0156:  10% 63/625 [00:03<00:28, 19.82it/s]\n",
            "vali mse:69.3776, mae:167.9369, ssim:0.8221, psnr:36.2695\n",
            "Epoch: 27 | Train Loss: 0.0164 Vali Loss: 0.0169\n",
            "\n",
            "train loss: 0.0160: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0156:  10% 63/625 [00:03<00:28, 19.78it/s]\n",
            "vali mse:67.5283, mae:163.2062, ssim:0.8268, psnr:36.3430\n",
            "Epoch: 28 | Train Loss: 0.0164 Vali Loss: 0.0165\n",
            "\n",
            "Validation loss decreased (0.016726 --> 0.016487).  Saving model ...\n",
            "train loss: 0.0156: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0146:  10% 63/625 [00:03<00:28, 19.89it/s]\n",
            "vali mse:65.6572, mae:167.2080, ssim:0.8358, psnr:36.3493\n",
            "Epoch: 29 | Train Loss: 0.0161 Vali Loss: 0.0160\n",
            "\n",
            "Validation loss decreased (0.016487 --> 0.016030).  Saving model ...\n",
            "train loss: 0.0153: 100% 157/157 [00:37<00:00,  4.24it/s]\n",
            "vali loss: 0.0154:  10% 63/625 [00:03<00:28, 19.44it/s]\n",
            "vali mse:64.9698, mae:164.7351, ssim:0.8410, psnr:36.4464\n",
            "Epoch: 30 | Train Loss: 0.0158 Vali Loss: 0.0159\n",
            "\n",
            "Validation loss decreased (0.016030 --> 0.015862).  Saving model ...\n",
            "train loss: 0.0153:   6% 10/157 [00:03<00:45,  3.23it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 113, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 157, in step\n",
            "    adam(params_with_grad,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 213, in adam\n",
            "    func(params,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 262, in _single_tensor_adam\n",
            "    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 45, in <module>\n",
            "    exp.train(args)\n",
            "  File \"/SimVP/exp.py\", line 108, in train\n",
            "    self.optimizer.step()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 113, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/profiler.py\", line 451, in __exit__\n",
            "    torch.ops.profiler._record_function_exit(self.handle)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/_ops.py\", line 143, in __call__\n",
            "    return self._op(*args, **kwargs or {})\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull && python interpolate.py"
      ],
      "metadata": {
        "id": "gBO-hmCwu6vv",
        "outputId": "9dad3107-b7bc-4f66-b9ec-857d82aaf36d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n",
            "From https://github.com/trieuduongle/SimVP-Simpler-yet-Better-Video-Prediction\n",
            "   55ab4a7..8c50ab2  colab      -> origin/colab\n",
            "Updating 55ab4a7..8c50ab2\n",
            "Fast-forward\n",
            " exp.py | 4 \u001b[32m++\u001b[m\u001b[31m--\u001b[m\n",
            " 1 file changed, 2 insertions(+), 2 deletions(-)\n",
            "Use GPU: 0\n",
            "\n",
            "device: \tcuda\t\n",
            "res_dir: \t./results\t\n",
            "ex_name: \tDebug\t\n",
            "use_gpu: \tTrue\t\n",
            "gpu: \t0\t\n",
            "seed: \t1\t\n",
            "batch_size: \t16\t\n",
            "val_batch_size: \t16\t\n",
            "data_root: \t./data/\t\n",
            "dataname: \tmmnist\t\n",
            "num_workers: \t8\t\n",
            "in_shape: \t[10, 1, 64, 64]\t\n",
            "hid_S: \t64\t\n",
            "hid_T: \t256\t\n",
            "N_S: \t4\t\n",
            "N_T: \t8\t\n",
            "groups: \t4\t\n",
            "epochs: \t51\t\n",
            "log_step: \t1\t\n",
            "lr: \t0.01\t\n",
            "(16, 10, 1, 64, 64)\n",
            "[[ 76  51  42 ...  69  65  66]\n",
            " [ 74  31  70 ...  32  67  80]\n",
            " [253  29  83 ...  40  40  55]\n",
            " ...\n",
            " [ 82  31  74 ...  49  71  57]\n",
            " [ 49  27  32 ...  44  35  56]\n",
            " [ 69  38  73 ...  71  76  92]]\n",
            "(64, 64)\n",
            "[[99 22 42 ... 58 48 68]\n",
            " [45 42 94 ... 19 77 74]\n",
            " [65 67 12 ... 33 49 64]\n",
            " ...\n",
            " [75 55 59 ... 53 87 65]\n",
            " [62 55 98 ... 37 48 43]\n",
            " [90 57 83 ... 82 98 75]]\n",
            "(64, 64)\n",
            "[[ 72  55  23 ...  37  72  64]\n",
            " [ 52  26 118 ...  22  64  57]\n",
            " [ 36  88  10 ...  48  71  52]\n",
            " ...\n",
            " [ 67  34  59 ...  50 102  43]\n",
            " [ 43  60  51 ...  49  19  63]\n",
            " [ 91  79  89 ...  67  80  68]]\n",
            "(64, 64)\n",
            "[[ 98  86  59 ...  70  65  61]\n",
            " [ 69  28  97 ...  43  91  61]\n",
            " [ 39  83  40 ...  28  35  59]\n",
            " ...\n",
            " [ 61  42  49 ...  26 103  75]\n",
            " [ 41  67  50 ...  98  49  61]\n",
            " [ 85  62  82 ...  74  74  89]]\n",
            "(64, 64)\n",
            "[[ 89  55  34 ...  71  63  64]\n",
            " [ 81  25 122 ...  25  80  74]\n",
            " [ 41   9  45 ... 242  64  56]\n",
            " ...\n",
            " [ 60  46  82 ...  49  66  70]\n",
            " [ 55  32  85 ...  47  30  53]\n",
            " [ 81  79  79 ...  66  83  78]]\n",
            "(64, 64)\n",
            "[[ 65  43  31 ...  57  61  76]\n",
            " [ 72  21  95 ...  36  74  70]\n",
            " [ 34  20  74 ...  72  24  52]\n",
            " ...\n",
            " [100  44  71 ...  64  68  79]\n",
            " [ 60  51  57 ...  52  42  58]\n",
            " [ 77  56  77 ...  71  83  92]]\n",
            "(64, 64)\n",
            "[[ 72  50  50 ...  69  73  71]\n",
            " [ 45  37 102 ...  35  80  69]\n",
            " [ 55  58  10 ...  62  28  54]\n",
            " ...\n",
            " [106  34  74 ...  64  85  69]\n",
            " [ 39  68  49 ...  67  40  70]\n",
            " [ 78  75 100 ...  50  83  96]]\n",
            "(64, 64)\n",
            "[[ 74  50   4 ...  57  35  64]\n",
            " [ 62 247  93 ...  50  84  81]\n",
            " [ 35  75  46 ...  91  42  61]\n",
            " ...\n",
            " [ 68  25  58 ...  42  74  67]\n",
            " [ 55  61  52 ...  30  30  47]\n",
            " [ 90  56  70 ...  69  77  86]]\n",
            "(64, 64)\n",
            "[[ 79  37  13 ...  40  56  71]\n",
            " [ 74  32 145 ...  29  69  64]\n",
            " [ 65  72 247 ...  32  39  48]\n",
            " ...\n",
            " [ 83  39  47 ...  52 100  47]\n",
            " [ 58  76  52 ...  63  30  60]\n",
            " [ 89  51  78 ...  69  97  70]]\n",
            "(64, 64)\n",
            "[[ 73  38  55 ...  19  67  70]\n",
            " [ 82  21 103 ...  12  79  61]\n",
            " [ 37  51  14 ...  44  37  69]\n",
            " ...\n",
            " [ 84  55  46 ...  44  58  68]\n",
            " [ 48  66  66 ...  68  36  71]\n",
            " [ 75  60  98 ...  71  77  89]]\n",
            "(64, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Trainning with Moving MNIST dataset"
      ],
      "metadata": {
        "id": "pvsZ3mzo9BxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmpXMxrMC50q",
        "outputId": "12a3a19d-5c28-4cf5-daec-6cf6eff8052a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects:  33% (1/3)\u001b[K\rremote: Counting objects:  66% (2/3)\u001b[K\rremote: Counting objects: 100% (3/3)\u001b[K\rremote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n",
            "From https://github.com/trieuduongle/SimVP-Simpler-yet-Better-Video-Prediction\n",
            "   aaf0809..a621631  3d-patch-gan -> origin/3d-patch-gan\n",
            "Updating aaf0809..a621631\n",
            "Fast-forward\n",
            " gan.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KqQEKFi0jG9",
        "outputId": "62655e9d-20e3-4fdc-d353-bed49badf3ba"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hickle==5.0.2\n",
            "  Downloading hickle-5.0.2-py3-none-any.whl (107 kB)\n",
            "\u001b[K     |████████████████████████████████| 107 kB 30.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm==4.64.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (4.64.1)\n",
            "Collecting scikit-image==0.19.3\n",
            "  Downloading scikit_image-0.19.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.0 MB 55.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.8/dist-packages (from hickle==5.0.2->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: numpy!=1.20,>=1.8 in /usr/local/lib/python3.8/dist-packages (from hickle==5.0.2->-r requirements.txt (line 1)) (1.21.6)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3->-r requirements.txt (line 3)) (2.8.8)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3->-r requirements.txt (line 3)) (1.7.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3->-r requirements.txt (line 3)) (21.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3->-r requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3->-r requirements.txt (line 3)) (2.9.0)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3->-r requirements.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3->-r requirements.txt (line 3)) (2022.10.10)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->scikit-image==0.19.3->-r requirements.txt (line 3)) (3.0.9)\n",
            "Installing collected packages: scikit-image, hickle\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.3\n",
            "    Uninstalling scikit-image-0.18.3:\n",
            "      Successfully uninstalled scikit-image-0.18.3\n",
            "Successfully installed hickle-5.0.2 scikit-image-0.19.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout generative-approach"
      ],
      "metadata": {
        "id": "3XJt_93CJGHW",
        "outputId": "3a38d6eb-0843-4fc1-982a-b9070174d8a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Branch 'generative-approach' set up to track remote branch 'generative-approach' from 'origin'.\n",
            "Switched to a new branch 'generative-approach'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py \\\n",
        "  --res_dir './results/mnist/20221212-lan-hai-temporal-patch-gan-resume-epoch-1' \\\n",
        "  --data_root '/content/drive/My Drive/Duong/datasets/' \\\n",
        "  --dataname 'mmnist' \\\n",
        "  --num_workers 8 \\\n",
        "  --batch_size 32 \\\n",
        "  --val_batch_size 32 \\\n",
        "  --epochs 201 \\\n",
        "  --save_epoch_freq 5\\\n",
        "  --in_shape 10 1 64 64 \\\n",
        "  --pre_seq_length 10 \\\n",
        "  --aft_seq_length 10 \\\n",
        "  --image_channels 1"
      ],
      "metadata": {
        "id": "EJ-upBDx71pO",
        "outputId": "36ba3845-dde4-4610-d64d-ff0ebf8c65d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use GPU: 0\n",
            "including adv loss\n",
            "\n",
            "device: \tcuda\t\n",
            "res_dir: \t./results/mnist/20221212-lan-hai-temporal-patch-gan-resume-epoch-1\t\n",
            "ex_name: \tDebug\t\n",
            "use_gpu: \tTrue\t\n",
            "gpu: \t0\t\n",
            "seed: \t1\t\n",
            "batch_size: \t32\t\n",
            "val_batch_size: \t32\t\n",
            "data_root: \t/content/drive/My Drive/Duong/datasets/\t\n",
            "dataname: \tmmnist\t\n",
            "num_workers: \t8\t\n",
            "in_shape: \t[10, 1, 64, 64]\t\n",
            "image_channels: \t1\t\n",
            "hid_S: \t64\t\n",
            "hid_T: \t256\t\n",
            "N_S: \t4\t\n",
            "N_T: \t8\t\n",
            "groups: \t4\t\n",
            "pre_seq_length: \t10\t\n",
            "aft_seq_length: \t10\t\n",
            "epochs: \t201\t\n",
            "log_step: \t1\t\n",
            "save_epoch_freq: \t5\t\n",
            "lr: \t0.01\t\n",
            "resume_path: \t\t\n",
            "lr_D: \t0.0001\t\n",
            "gan_type: \tvanilla\t\n",
            "lambda_adv: \t0.005\t\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>  start <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "train loss: 0.0353 - NonGAN loss: 0.0318 - GAN loss: 0.0035: 100% 313/313 [17:10<00:00,  3.29s/it]\n",
            "vali loss: 0.0309:  10% 32/313 [00:13<02:00,  2.33it/s]\n",
            "vali mse:129.0843, mae:316.1860, ssim:0.4988, psnr:31.9352\n",
            "Epoch: 1 | Train Loss: 0.0424 - NonGAN loss: 0.0391 - GAN loss: 0.0033 Vali Loss: 0.0315 | Take 1051.1902 seconds\n",
            "\n",
            "Validation loss decreased (inf --> 0.031515).  Saving model ...\n",
            "train loss: 0.0348 - NonGAN loss: 0.0313 - GAN loss: 0.0035: 100% 313/313 [17:07<00:00,  3.28s/it]\n",
            "vali loss: 0.0287:  10% 32/313 [00:13<02:02,  2.29it/s]\n",
            "vali mse:119.5493, mae:282.3218, ssim:0.5915, psnr:33.0292\n",
            "Epoch: 2 | Train Loss: 0.0331 - NonGAN loss: 0.0296 - GAN loss: 0.0035 Vali Loss: 0.0292 | Take 1047.4156 seconds\n",
            "\n",
            "Validation loss decreased (0.031515 --> 0.029187).  Saving model ...\n",
            "train loss: 0.0296 - NonGAN loss: 0.0261 - GAN loss: 0.0035: 100% 313/313 [17:05<00:00,  3.28s/it]\n",
            "vali loss: 0.0273:  10% 32/313 [00:13<01:55,  2.43it/s]Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "vali loss: 0.0273:  10% 32/313 [00:14<02:04,  2.27it/s]\n",
            "vali mse:114.2182, mae:271.0782, ssim:0.6454, psnr:33.6970\n",
            "Epoch: 3 | Train Loss: 0.0318 - NonGAN loss: 0.0283 - GAN loss: 0.0035 Vali Loss: 0.0279 | Take 1045.4053 seconds\n",
            "\n",
            "Validation loss decreased (0.029187 --> 0.027885).  Saving model ...\n",
            "train loss: 0.0318 - NonGAN loss: 0.0283 - GAN loss: 0.0035: 100% 313/313 [17:03<00:00,  3.27s/it]\n",
            "vali loss: 0.0269:  10% 32/313 [00:14<02:03,  2.27it/s]\n",
            "vali mse:111.7574, mae:254.4832, ssim:0.6588, psnr:34.0384\n",
            "Epoch: 4 | Train Loss: 0.0306 - NonGAN loss: 0.0271 - GAN loss: 0.0035 Vali Loss: 0.0273 | Take 1043.9415 seconds\n",
            "\n",
            "Validation loss decreased (0.027885 --> 0.027285).  Saving model ...\n",
            "train loss: 0.0293 - NonGAN loss: 0.0258 - GAN loss: 0.0035: 100% 313/313 [17:06<00:00,  3.28s/it]\n",
            "vali loss: 0.0255:  10% 32/313 [00:14<02:03,  2.28it/s]\n",
            "vali mse:106.8948, mae:248.5093, ssim:0.6463, psnr:33.9609\n",
            "Epoch: 5 | Train Loss: 0.0297 - NonGAN loss: 0.0262 - GAN loss: 0.0035 Vali Loss: 0.0261 | Take 1046.1398 seconds\n",
            "\n",
            "Validation loss decreased (0.027285 --> 0.026098).  Saving model ...\n",
            "train loss: 0.0286 - NonGAN loss: 0.0251 - GAN loss: 0.0035: 100% 313/313 [17:05<00:00,  3.28s/it]\n",
            "vali loss: 0.0247:  10% 32/313 [00:14<02:03,  2.28it/s]\n",
            "vali mse:103.7528, mae:243.9124, ssim:0.6928, psnr:34.3940\n",
            "Epoch: 6 | Train Loss: 0.0289 - NonGAN loss: 0.0254 - GAN loss: 0.0035 Vali Loss: 0.0253 | Take 1045.5307 seconds\n",
            "\n",
            "Validation loss decreased (0.026098 --> 0.025330).  Saving model ...\n",
            "train loss: 0.0294 - NonGAN loss: 0.0259 - GAN loss: 0.0035: 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "vali loss: 0.0235:  10% 32/313 [00:14<02:03,  2.28it/s]\n",
            "vali mse:100.2075, mae:243.3363, ssim:0.6558, psnr:34.0676\n",
            "Epoch: 7 | Train Loss: 0.0281 - NonGAN loss: 0.0247 - GAN loss: 0.0035 Vali Loss: 0.0245 | Take 1042.7432 seconds\n",
            "\n",
            "Validation loss decreased (0.025330 --> 0.024465).  Saving model ...\n",
            "train loss: 0.0266 - NonGAN loss: 0.0232 - GAN loss: 0.0035: 100% 313/313 [17:04<00:00,  3.27s/it]\n",
            "vali loss: 0.0228:  10% 32/313 [00:14<02:03,  2.27it/s]\n",
            "vali mse:96.0722, mae:230.6859, ssim:0.7082, psnr:34.5756\n",
            "Epoch: 8 | Train Loss: 0.0272 - NonGAN loss: 0.0237 - GAN loss: 0.0035 Vali Loss: 0.0235 | Take 1044.8356 seconds\n",
            "\n",
            "Validation loss decreased (0.024465 --> 0.023455).  Saving model ...\n",
            "train loss: 0.0263 - NonGAN loss: 0.0229 - GAN loss: 0.0035: 100% 313/313 [17:03<00:00,  3.27s/it]\n",
            "vali loss: 0.0228:  10% 32/313 [00:14<02:03,  2.27it/s]\n",
            "vali mse:95.5149, mae:226.7143, ssim:0.6966, psnr:34.5277\n",
            "Epoch: 9 | Train Loss: 0.0264 - NonGAN loss: 0.0230 - GAN loss: 0.0035 Vali Loss: 0.0233 | Take 1044.0782 seconds\n",
            "\n",
            "Validation loss decreased (0.023455 --> 0.023319).  Saving model ...\n",
            "train loss: 0.0247 - NonGAN loss: 0.0213 - GAN loss: 0.0035: 100% 313/313 [17:05<00:00,  3.28s/it]\n",
            "vali loss: 0.0213:  10% 32/313 [00:14<02:04,  2.26it/s]\n",
            "vali mse:89.8880, mae:213.9799, ssim:0.7221, psnr:34.8574\n",
            "Epoch: 10 | Train Loss: 0.0258 - NonGAN loss: 0.0223 - GAN loss: 0.0035 Vali Loss: 0.0219 | Take 1045.9871 seconds\n",
            "\n",
            "Validation loss decreased (0.023319 --> 0.021946).  Saving model ...\n",
            "train loss: 0.0261 - NonGAN loss: 0.0226 - GAN loss: 0.0035: 100% 313/313 [17:05<00:00,  3.28s/it]\n",
            "vali loss: 0.0216:  10% 32/313 [00:14<02:03,  2.28it/s]\n",
            "vali mse:88.5738, mae:217.0775, ssim:0.7452, psnr:34.9569\n",
            "Epoch: 11 | Train Loss: 0.0252 - NonGAN loss: 0.0217 - GAN loss: 0.0035 Vali Loss: 0.0216 | Take 1046.0573 seconds\n",
            "\n",
            "Validation loss decreased (0.021946 --> 0.021625).  Saving model ...\n",
            "train loss: 0.0239 - NonGAN loss: 0.0205 - GAN loss: 0.0035: 100% 313/313 [17:04<00:00,  3.27s/it]\n",
            "vali loss: 0.0206:  10% 32/313 [00:13<02:02,  2.29it/s]\n",
            "vali mse:86.0583, mae:202.3411, ssim:0.7394, psnr:35.1299\n",
            "Epoch: 12 | Train Loss: 0.0246 - NonGAN loss: 0.0212 - GAN loss: 0.0035 Vali Loss: 0.0210 | Take 1044.6050 seconds\n",
            "\n",
            "Validation loss decreased (0.021625 --> 0.021011).  Saving model ...\n",
            "train loss: 0.0265 - NonGAN loss: 0.0231 - GAN loss: 0.0035: 100% 313/313 [17:06<00:00,  3.28s/it]\n",
            "vali loss: 0.0202:  10% 32/313 [00:14<02:03,  2.27it/s]\n",
            "vali mse:84.9861, mae:209.7262, ssim:0.7700, psnr:35.3207\n",
            "Epoch: 13 | Train Loss: 0.0242 - NonGAN loss: 0.0207 - GAN loss: 0.0035 Vali Loss: 0.0207 | Take 1047.1999 seconds\n",
            "\n",
            "Validation loss decreased (0.021011 --> 0.020749).  Saving model ...\n",
            "train loss: 0.0233 - NonGAN loss: 0.0199 - GAN loss: 0.0035: 100% 313/313 [17:04<00:00,  3.27s/it]\n",
            "vali loss: 0.0197:  10% 32/313 [00:14<02:04,  2.26it/s]\n",
            "vali mse:83.2185, mae:204.0763, ssim:0.7468, psnr:35.0623\n",
            "Epoch: 14 | Train Loss: 0.0238 - NonGAN loss: 0.0204 - GAN loss: 0.0035 Vali Loss: 0.0203 | Take 1044.9224 seconds\n",
            "\n",
            "Validation loss decreased (0.020749 --> 0.020317).  Saving model ...\n",
            "train loss: 0.0224 - NonGAN loss: 0.0190 - GAN loss: 0.0035: 100% 313/313 [17:05<00:00,  3.28s/it]\n",
            "vali loss: 0.0197:  10% 32/313 [00:14<02:04,  2.25it/s]\n",
            "vali mse:82.5204, mae:198.9529, ssim:0.7746, psnr:35.4054\n",
            "Epoch: 15 | Train Loss: 0.0234 - NonGAN loss: 0.0199 - GAN loss: 0.0035 Vali Loss: 0.0201 | Take 1045.8096 seconds\n",
            "\n",
            "Validation loss decreased (0.020317 --> 0.020147).  Saving model ...\n",
            "train loss: 0.0230 - NonGAN loss: 0.0196 - GAN loss: 0.0035: 100% 313/313 [17:05<00:00,  3.28s/it]\n",
            "vali loss: 0.0192:  10% 32/313 [00:14<02:03,  2.28it/s]\n",
            "vali mse:79.9282, mae:197.7829, ssim:0.7809, psnr:35.3860\n",
            "Epoch: 16 | Train Loss: 0.0231 - NonGAN loss: 0.0196 - GAN loss: 0.0035 Vali Loss: 0.0195 | Take 1045.8742 seconds\n",
            "\n",
            "Validation loss decreased (0.020147 --> 0.019514).  Saving model ...\n",
            "train loss: 0.0252 - NonGAN loss: 0.0217 - GAN loss: 0.0035: 100% 313/313 [17:05<00:00,  3.28s/it]\n",
            "vali loss: 0.0191:  10% 32/313 [00:14<02:04,  2.26it/s]\n",
            "vali mse:79.1982, mae:194.4990, ssim:0.7895, psnr:35.6398\n",
            "Epoch: 17 | Train Loss: 0.0228 - NonGAN loss: 0.0194 - GAN loss: 0.0035 Vali Loss: 0.0193 | Take 1046.3070 seconds\n",
            "\n",
            "Validation loss decreased (0.019514 --> 0.019336).  Saving model ...\n",
            "train loss: 0.0217 - NonGAN loss: 0.0182 - GAN loss: 0.0035: 100% 313/313 [17:04<00:00,  3.27s/it]\n",
            "vali loss: 0.0185:  10% 32/313 [00:14<02:03,  2.27it/s]\n",
            "vali mse:78.9998, mae:187.6176, ssim:0.7854, psnr:35.5809\n",
            "Epoch: 18 | Train Loss: 0.0226 - NonGAN loss: 0.0191 - GAN loss: 0.0035 Vali Loss: 0.0193 | Take 1044.5925 seconds\n",
            "\n",
            "Validation loss decreased (0.019336 --> 0.019287).  Saving model ...\n",
            "train loss: 0.0202 - NonGAN loss: 0.0167 - GAN loss: 0.0035: 100% 313/313 [17:04<00:00,  3.27s/it]\n",
            "vali loss: 0.0182:  10% 32/313 [00:14<02:04,  2.26it/s]\n",
            "vali mse:77.0059, mae:188.1823, ssim:0.7786, psnr:35.5715\n",
            "Epoch: 19 | Train Loss: 0.0222 - NonGAN loss: 0.0187 - GAN loss: 0.0035 Vali Loss: 0.0188 | Take 1046.4295 seconds\n",
            "\n",
            "Validation loss decreased (0.019287 --> 0.018801).  Saving model ...\n",
            "train loss: 0.0211 - NonGAN loss: 0.0177 - GAN loss: 0.0035: 100% 313/313 [17:05<00:00,  3.28s/it]\n",
            "vali loss: 0.0175:  10% 32/313 [00:14<02:03,  2.28it/s]\n",
            "vali mse:75.4649, mae:188.5243, ssim:0.7592, psnr:35.6095\n",
            "Epoch: 20 | Train Loss: 0.0221 - NonGAN loss: 0.0187 - GAN loss: 0.0035 Vali Loss: 0.0184 | Take 1045.9624 seconds\n",
            "\n",
            "Validation loss decreased (0.018801 --> 0.018424).  Saving model ...\n",
            "train loss: 0.0235 - NonGAN loss: 0.0200 - GAN loss: 0.0035: 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "vali loss: 0.0178:  10% 32/313 [00:14<02:05,  2.25it/s]\n",
            "vali mse:74.9600, mae:184.2629, ssim:0.8137, psnr:36.0432\n",
            "Epoch: 21 | Train Loss: 0.0217 - NonGAN loss: 0.0183 - GAN loss: 0.0035 Vali Loss: 0.0183 | Take 1043.3075 seconds\n",
            "\n",
            "Validation loss decreased (0.018424 --> 0.018301).  Saving model ...\n",
            "train loss: 0.0202 - NonGAN loss: 0.0167 - GAN loss: 0.0035: 100% 313/313 [17:05<00:00,  3.28s/it]\n",
            "vali loss: 0.0174:  10% 32/313 [00:13<01:55,  2.43it/s]Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "vali loss: 0.0174:  10% 32/313 [00:14<02:05,  2.24it/s]\n",
            "vali mse:73.5509, mae:178.7181, ssim:0.7988, psnr:35.7442\n",
            "Epoch: 22 | Train Loss: 0.0216 - NonGAN loss: 0.0181 - GAN loss: 0.0035 Vali Loss: 0.0180 | Take 1046.0369 seconds\n",
            "\n",
            "Validation loss decreased (0.018301 --> 0.017957).  Saving model ...\n",
            "train loss: 0.0220 - NonGAN loss: 0.0186 - GAN loss: 0.0035:  75% 236/313 [12:55<04:13,  3.29s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 14, in <module>\n",
            "    exp.train(args)\n",
            "  File \"/content/drive/MyDrive/Duong/SimVP/code/exp.py\", line 154, in train\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\", line 487, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\", line 197, in backward\n",
            "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from API.dataloader_moving_mnist import load_data\n",
        "\n",
        "train_loader, vali_loader, test_loader, data_mean, data_std =  load_data(9,10, '/content/drive/My Drive/Duong/datasets/', 1)\n",
        "\n",
        "for batch_x, batch_y in train_loader:\n",
        "  print(batch_x.size())\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYx9hxIfRoK9",
        "outputId": "0c18895b-9b15-4f59-926c-4c1dfba06b81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([9, 10, 1, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py \\\n",
        "  --res_dir './results/mnist/20221213-lan-mot-model-dua-pytorch-gan' \\\n",
        "  --data_root '/content/drive/My Drive/Duong/datasets/' \\\n",
        "  --dataname 'mmnist' \\\n",
        "  --num_workers 8 \\\n",
        "  --batch_size 32 \\\n",
        "  --val_batch_size 32 \\\n",
        "  --epochs 201 \\\n",
        "  --save_epoch_freq 5\\\n",
        "  --in_shape 10 1 64 64 \\\n",
        "  --pre_seq_length 10 \\\n",
        "  --aft_seq_length 10 \\\n",
        "  --image_channels 1"
      ],
      "metadata": {
        "id": "MR7PeFTgFzDR",
        "outputId": "8c25c088-54e5-4203-c306-bcb38d080e46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use GPU: 0\n",
            "\n",
            "device: \tcuda\t\n",
            "res_dir: \t./results/mnist/20221213-lan-mot-model-dua-pytorch-gan\t\n",
            "ex_name: \tDebug\t\n",
            "use_gpu: \tTrue\t\n",
            "gpu: \t0\t\n",
            "seed: \t1\t\n",
            "batch_size: \t32\t\n",
            "val_batch_size: \t32\t\n",
            "data_root: \t/content/drive/My Drive/Duong/datasets/\t\n",
            "dataname: \tmmnist\t\n",
            "num_workers: \t8\t\n",
            "in_shape: \t[10, 1, 64, 64]\t\n",
            "image_channels: \t1\t\n",
            "hid_S: \t64\t\n",
            "hid_T: \t256\t\n",
            "N_S: \t4\t\n",
            "N_T: \t8\t\n",
            "groups: \t4\t\n",
            "pre_seq_length: \t10\t\n",
            "aft_seq_length: \t10\t\n",
            "epochs: \t201\t\n",
            "log_step: \t1\t\n",
            "save_epoch_freq: \t5\t\n",
            "lr: \t0.01\t\n",
            "resume_path: \t\t\n",
            "lr_D: \t0.0001\t\n",
            "gan_type: \tvanilla\t\n",
            "lambda_adv: \t0.005\t\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>  start <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "train loss: 0.0331 - NonGAN loss: 0.0318 - Raw GAN loss: 0.250117600 - Discriminator loss: 0.250004083: 100% 313/313 [16:43<00:00,  3.21s/it]\n",
            "vali loss: 0.0309:  10% 32/313 [00:13<01:57,  2.40it/s]\n",
            "vali mse:128.8880, mae:314.9059, ssim:0.5170, psnr:32.1023\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 1 | Train Loss: 0.0403 - NonGAN loss: 0.0391 - GAN loss: 0.250121111 - Discriminator loss: 0.250003174 Vali Loss: 0.0315 | Take 1024.5131 seconds\n",
            "\n",
            "Validation loss decreased (inf --> 0.031467).  Saving model ...\n",
            "train loss: 0.0302 - NonGAN loss: 0.0289 - Raw GAN loss: 0.250118017 - Discriminator loss: 0.250001550: 100% 313/313 [16:43<00:00,  3.20s/it]\n",
            "vali loss: 0.0289:  10% 32/313 [00:13<01:59,  2.35it/s]\n",
            "vali mse:119.8548, mae:283.6753, ssim:0.5822, psnr:32.9925\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 2 | Train Loss: 0.0310 - NonGAN loss: 0.0297 - GAN loss: 0.250118706 - Discriminator loss: 0.250002763 Vali Loss: 0.0293 | Take 1024.2929 seconds\n",
            "\n",
            "Validation loss decreased (0.031467 --> 0.029262).  Saving model ...\n",
            "train loss: 0.0301 - NonGAN loss: 0.0288 - Raw GAN loss: 0.250114918 - Discriminator loss: 0.250001609: 100% 313/313 [16:41<00:00,  3.20s/it]\n",
            "vali loss: 0.0276:  10% 32/313 [00:13<02:00,  2.34it/s]\n",
            "vali mse:115.0819, mae:272.8388, ssim:0.5986, psnr:33.2573\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 3 | Train Loss: 0.0293 - NonGAN loss: 0.0281 - GAN loss: 0.250117295 - Discriminator loss: 0.250002189 Vali Loss: 0.0281 | Take 1022.3566 seconds\n",
            "\n",
            "Validation loss decreased (0.029262 --> 0.028096).  Saving model ...\n",
            "train loss: 0.0275 - NonGAN loss: 0.0263 - Raw GAN loss: 0.250116885 - Discriminator loss: 0.250001490: 100% 313/313 [16:43<00:00,  3.20s/it]\n",
            "vali loss: 0.0265:  10% 32/313 [00:13<01:59,  2.34it/s]\n",
            "vali mse:110.9800, mae:260.4633, ssim:0.6125, psnr:33.5656\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 4 | Train Loss: 0.0284 - NonGAN loss: 0.0272 - GAN loss: 0.250115850 - Discriminator loss: 0.250001720 Vali Loss: 0.0271 | Take 1023.8683 seconds\n",
            "\n",
            "Validation loss decreased (0.028096 --> 0.027095).  Saving model ...\n",
            "train loss: 0.0268 - NonGAN loss: 0.0255 - Raw GAN loss: 0.250113964 - Discriminator loss: 0.250001550: 100% 313/313 [16:43<00:00,  3.20s/it]\n",
            "vali loss: 0.0254:  10% 32/313 [00:13<01:59,  2.35it/s]\n",
            "vali mse:106.8668, mae:249.7101, ssim:0.6754, psnr:34.1577\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 5 | Train Loss: 0.0275 - NonGAN loss: 0.0262 - GAN loss: 0.250114198 - Discriminator loss: 0.250001284 Vali Loss: 0.0261 | Take 1024.0504 seconds\n",
            "\n",
            "Validation loss decreased (0.027095 --> 0.026091).  Saving model ...\n",
            "train loss: 0.0264 - NonGAN loss: 0.0252 - Raw GAN loss: 0.250111073 - Discriminator loss: 0.249999642: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0251:  10% 32/313 [00:13<01:59,  2.36it/s]\n",
            "vali mse:104.8620, mae:247.1304, ssim:0.6773, psnr:34.2078\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 6 | Train Loss: 0.0268 - NonGAN loss: 0.0255 - GAN loss: 0.250112630 - Discriminator loss: 0.250000908 Vali Loss: 0.0256 | Take 1023.1708 seconds\n",
            "\n",
            "Validation loss decreased (0.026091 --> 0.025601).  Saving model ...\n",
            "train loss: 0.0251 - NonGAN loss: 0.0239 - Raw GAN loss: 0.250110239 - Discriminator loss: 0.250000268: 100% 313/313 [16:43<00:00,  3.20s/it]\n",
            "vali loss: 0.0240:  10% 32/313 [00:13<01:59,  2.34it/s]\n",
            "vali mse:101.7099, mae:247.6287, ssim:0.6702, psnr:34.0819\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 7 | Train Loss: 0.0259 - NonGAN loss: 0.0246 - GAN loss: 0.250111159 - Discriminator loss: 0.250000480 Vali Loss: 0.0248 | Take 1023.7949 seconds\n",
            "\n",
            "Validation loss decreased (0.025601 --> 0.024832).  Saving model ...\n",
            "train loss: 0.0261 - NonGAN loss: 0.0249 - Raw GAN loss: 0.250109255 - Discriminator loss: 0.249999583: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0233:  10% 32/313 [00:13<02:01,  2.31it/s]\n",
            "vali mse:96.7915, mae:241.4340, ssim:0.6980, psnr:34.3862\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 8 | Train Loss: 0.0250 - NonGAN loss: 0.0238 - GAN loss: 0.250109661 - Discriminator loss: 0.250000197 Vali Loss: 0.0236 | Take 1023.4550 seconds\n",
            "\n",
            "Validation loss decreased (0.024832 --> 0.023631).  Saving model ...\n",
            "train loss: 0.0234 - NonGAN loss: 0.0221 - Raw GAN loss: 0.250106096 - Discriminator loss: 0.249999821: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0228:  10% 32/313 [00:13<02:00,  2.34it/s]\n",
            "vali mse:94.6360, mae:232.7882, ssim:0.6960, psnr:34.2926\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 9 | Train Loss: 0.0243 - NonGAN loss: 0.0230 - GAN loss: 0.250108127 - Discriminator loss: 0.249999928 Vali Loss: 0.0231 | Take 1023.7769 seconds\n",
            "\n",
            "Validation loss decreased (0.023631 --> 0.023105).  Saving model ...\n",
            "train loss: 0.0257 - NonGAN loss: 0.0244 - Raw GAN loss: 0.250104904 - Discriminator loss: 0.250000477: 100% 313/313 [16:43<00:00,  3.21s/it]\n",
            "vali loss: 0.0216:  10% 32/313 [00:13<01:59,  2.35it/s]\n",
            "vali mse:91.0309, mae:223.8947, ssim:0.7249, psnr:34.6504\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 10 | Train Loss: 0.0234 - NonGAN loss: 0.0222 - GAN loss: 0.250106712 - Discriminator loss: 0.249999655 Vali Loss: 0.0222 | Take 1023.6770 seconds\n",
            "\n",
            "Validation loss decreased (0.023105 --> 0.022225).  Saving model ...\n",
            "train loss: 0.0206 - NonGAN loss: 0.0193 - Raw GAN loss: 0.250105053 - Discriminator loss: 0.250000030: 100% 313/313 [16:43<00:00,  3.20s/it]\n",
            "vali loss: 0.0214:  10% 32/313 [00:13<01:59,  2.35it/s]\n",
            "vali mse:88.6591, mae:208.2479, ssim:0.7510, psnr:35.2053\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 11 | Train Loss: 0.0228 - NonGAN loss: 0.0216 - GAN loss: 0.250105180 - Discriminator loss: 0.249999436 Vali Loss: 0.0216 | Take 1023.9986 seconds\n",
            "\n",
            "Validation loss decreased (0.022225 --> 0.021646).  Saving model ...\n",
            "train loss: 0.0238 - NonGAN loss: 0.0225 - Raw GAN loss: 0.250101417 - Discriminator loss: 0.249999076: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0208:  10% 32/313 [00:13<01:58,  2.36it/s]\n",
            "vali mse:86.3296, mae:214.3259, ssim:0.7544, psnr:35.0099\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 12 | Train Loss: 0.0225 - NonGAN loss: 0.0212 - GAN loss: 0.250103646 - Discriminator loss: 0.249999195 Vali Loss: 0.0211 | Take 1023.5395 seconds\n",
            "\n",
            "Validation loss decreased (0.021646 --> 0.021077).  Saving model ...\n",
            "train loss: 0.0240 - NonGAN loss: 0.0228 - Raw GAN loss: 0.250100821 - Discriminator loss: 0.249999762: 100% 313/313 [16:43<00:00,  3.20s/it]\n",
            "vali loss: 0.0201:  10% 32/313 [00:13<02:01,  2.31it/s]\n",
            "vali mse:86.1143, mae:197.9144, ssim:0.7666, psnr:35.4284\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 13 | Train Loss: 0.0220 - NonGAN loss: 0.0207 - GAN loss: 0.250102316 - Discriminator loss: 0.249999043 Vali Loss: 0.0210 | Take 1027.5719 seconds\n",
            "\n",
            "Validation loss decreased (0.021077 --> 0.021024).  Saving model ...\n",
            "train loss: 0.0221 - NonGAN loss: 0.0209 - Raw GAN loss: 0.250098556 - Discriminator loss: 0.249998435: 100% 313/313 [16:43<00:00,  3.20s/it]\n",
            "vali loss: 0.0196:  10% 32/313 [00:13<01:59,  2.34it/s]\n",
            "vali mse:83.2661, mae:208.5506, ssim:0.7214, psnr:34.7430\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 14 | Train Loss: 0.0216 - NonGAN loss: 0.0203 - GAN loss: 0.250100920 - Discriminator loss: 0.249998848 Vali Loss: 0.0203 | Take 1024.0621 seconds\n",
            "\n",
            "Validation loss decreased (0.021024 --> 0.020329).  Saving model ...\n",
            "train loss: 0.0211 - NonGAN loss: 0.0199 - Raw GAN loss: 0.250100136 - Discriminator loss: 0.249998808: 100% 313/313 [16:43<00:00,  3.20s/it]\n",
            "vali loss: 0.0194:  10% 32/313 [00:13<01:59,  2.36it/s]\n",
            "vali mse:81.2714, mae:197.4784, ssim:0.7553, psnr:35.2663\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 15 | Train Loss: 0.0212 - NonGAN loss: 0.0200 - GAN loss: 0.250099426 - Discriminator loss: 0.249998705 Vali Loss: 0.0198 | Take 1023.8610 seconds\n",
            "\n",
            "Validation loss decreased (0.020329 --> 0.019842).  Saving model ...\n",
            "train loss: 0.0227 - NonGAN loss: 0.0215 - Raw GAN loss: 0.250096649 - Discriminator loss: 0.249999791: 100% 313/313 [16:43<00:00,  3.21s/it]\n",
            "vali loss: 0.0190:  10% 32/313 [00:13<01:59,  2.35it/s]\n",
            "vali mse:80.2358, mae:192.9972, ssim:0.7821, psnr:35.4532\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 16 | Train Loss: 0.0209 - NonGAN loss: 0.0197 - GAN loss: 0.250098044 - Discriminator loss: 0.249998527 Vali Loss: 0.0196 | Take 1024.4774 seconds\n",
            "\n",
            "Validation loss decreased (0.019842 --> 0.019589).  Saving model ...\n",
            "train loss: 0.0208 - NonGAN loss: 0.0195 - Raw GAN loss: 0.250095844 - Discriminator loss: 0.249997824: 100% 313/313 [16:44<00:00,  3.21s/it]\n",
            "vali loss: 0.0190:  10% 32/313 [00:13<02:00,  2.34it/s]\n",
            "vali mse:79.9587, mae:187.9091, ssim:0.7768, psnr:35.5765\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 17 | Train Loss: 0.0206 - NonGAN loss: 0.0194 - GAN loss: 0.250096642 - Discriminator loss: 0.249998325 Vali Loss: 0.0195 | Take 1025.1929 seconds\n",
            "\n",
            "Validation loss decreased (0.019589 --> 0.019521).  Saving model ...\n",
            "train loss: 0.0200 - NonGAN loss: 0.0188 - Raw GAN loss: 0.250096053 - Discriminator loss: 0.249997705: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0182:  10% 32/313 [00:13<01:59,  2.35it/s]\n",
            "vali mse:77.3166, mae:193.9320, ssim:0.7563, psnr:35.4800\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 18 | Train Loss: 0.0203 - NonGAN loss: 0.0191 - GAN loss: 0.250095275 - Discriminator loss: 0.249998199 Vali Loss: 0.0189 | Take 1023.6074 seconds\n",
            "\n",
            "Validation loss decreased (0.019521 --> 0.018876).  Saving model ...\n",
            "train loss: 0.0206 - NonGAN loss: 0.0193 - Raw GAN loss: 0.250094652 - Discriminator loss: 0.249997228: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0186:  10% 32/313 [00:13<01:59,  2.36it/s]\n",
            "vali mse:78.1127, mae:188.4859, ssim:0.7854, psnr:35.4902\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 19 | Train Loss: 0.0201 - NonGAN loss: 0.0189 - GAN loss: 0.250093945 - Discriminator loss: 0.249998053 Vali Loss: 0.0191 | Take 1023.3683 seconds\n",
            "\n",
            "train loss: 0.0195 - NonGAN loss: 0.0182 - Raw GAN loss: 0.250092357 - Discriminator loss: 0.249997556: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0178:  10% 32/313 [00:13<02:00,  2.33it/s]\n",
            "vali mse:75.5598, mae:180.3233, ssim:0.8086, psnr:35.9734\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 20 | Train Loss: 0.0198 - NonGAN loss: 0.0185 - GAN loss: 0.250092498 - Discriminator loss: 0.249997953 Vali Loss: 0.0184 | Take 1023.4553 seconds\n",
            "\n",
            "Validation loss decreased (0.018876 --> 0.018447).  Saving model ...\n",
            "train loss: 0.0184 - NonGAN loss: 0.0171 - Raw GAN loss: 0.250092238 - Discriminator loss: 0.249997303: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0174:  10% 32/313 [00:13<01:59,  2.36it/s]\n",
            "vali mse:74.5328, mae:185.1846, ssim:0.8017, psnr:35.7621\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 21 | Train Loss: 0.0195 - NonGAN loss: 0.0182 - GAN loss: 0.250091192 - Discriminator loss: 0.249997869 Vali Loss: 0.0182 | Take 1023.2126 seconds\n",
            "\n",
            "Validation loss decreased (0.018447 --> 0.018197).  Saving model ...\n",
            "train loss: 0.0196 - NonGAN loss: 0.0183 - Raw GAN loss: 0.250091642 - Discriminator loss: 0.249997929: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0175:  10% 32/313 [00:13<02:00,  2.33it/s]\n",
            "vali mse:73.8357, mae:182.5983, ssim:0.7949, psnr:35.6652\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 22 | Train Loss: 0.0194 - NonGAN loss: 0.0181 - GAN loss: 0.250089789 - Discriminator loss: 0.249997754 Vali Loss: 0.0180 | Take 1024.8904 seconds\n",
            "\n",
            "Validation loss decreased (0.018197 --> 0.018027).  Saving model ...\n",
            "train loss: 0.0184 - NonGAN loss: 0.0171 - Raw GAN loss: 0.250083506 - Discriminator loss: 0.249998450: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0171:  10% 32/313 [00:13<02:00,  2.33it/s]\n",
            "vali mse:72.7979, mae:195.7074, ssim:0.7207, psnr:35.0890\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 23 | Train Loss: 0.0191 - NonGAN loss: 0.0179 - GAN loss: 0.250088530 - Discriminator loss: 0.249997609 Vali Loss: 0.0178 | Take 1023.6179 seconds\n",
            "\n",
            "Validation loss decreased (0.018027 --> 0.017773).  Saving model ...\n",
            "train loss: 0.0186 - NonGAN loss: 0.0173 - Raw GAN loss: 0.250084162 - Discriminator loss: 0.249997184: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0169:  10% 32/313 [00:13<02:00,  2.34it/s]\n",
            "vali mse:72.3167, mae:178.0713, ssim:0.8185, psnr:36.0102\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 24 | Train Loss: 0.0189 - NonGAN loss: 0.0176 - GAN loss: 0.250087184 - Discriminator loss: 0.249997527 Vali Loss: 0.0177 | Take 1023.2239 seconds\n",
            "\n",
            "Validation loss decreased (0.017773 --> 0.017656).  Saving model ...\n",
            "train loss: 0.0186 - NonGAN loss: 0.0173 - Raw GAN loss: 0.250088036 - Discriminator loss: 0.249997437: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0160:  10% 32/313 [00:13<02:01,  2.32it/s]\n",
            "vali mse:70.4919, mae:183.9406, ssim:0.7695, psnr:35.5195\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 25 | Train Loss: 0.0187 - NonGAN loss: 0.0174 - GAN loss: 0.250085938 - Discriminator loss: 0.249997371 Vali Loss: 0.0172 | Take 1023.8056 seconds\n",
            "\n",
            "Validation loss decreased (0.017656 --> 0.017210).  Saving model ...\n",
            "train loss: 0.0175 - NonGAN loss: 0.0163 - Raw GAN loss: 0.250085682 - Discriminator loss: 0.249997646: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0166:  10% 32/313 [00:13<02:01,  2.32it/s]\n",
            "vali mse:71.8051, mae:177.1409, ssim:0.8014, psnr:35.7489\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 26 | Train Loss: 0.0185 - NonGAN loss: 0.0172 - GAN loss: 0.250084622 - Discriminator loss: 0.249997277 Vali Loss: 0.0175 | Take 1023.5309 seconds\n",
            "\n",
            "train loss: 0.0177 - NonGAN loss: 0.0164 - Raw GAN loss: 0.250084132 - Discriminator loss: 0.249997407: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0162:  10% 32/313 [00:13<02:01,  2.31it/s]\n",
            "vali mse:69.6223, mae:176.6281, ssim:0.8229, psnr:36.0959\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 27 | Train Loss: 0.0182 - NonGAN loss: 0.0170 - GAN loss: 0.250083492 - Discriminator loss: 0.249997210 Vali Loss: 0.0170 | Take 1023.8608 seconds\n",
            "\n",
            "Validation loss decreased (0.017210 --> 0.016998).  Saving model ...\n",
            "train loss: 0.0184 - NonGAN loss: 0.0172 - Raw GAN loss: 0.250081897 - Discriminator loss: 0.249997348:  29% 90/313 [04:49<11:54,  3.21s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull && python interpolate.py \\\n",
        "  --data_root '/content/drive/My Drive/Duong/datasets/' \\\n",
        "  --resume_path './results/mnist/20221212-lan-hai-temporal-patch-gan-resume-epoch-1/Debug/checkpoints/3.pth' \\\n",
        "  --res_dir './results/mnist/20221212-lan-hai-temporal-patch-gan-resume-epoch-1'"
      ],
      "metadata": {
        "id": "pO2tW7f1LCum",
        "outputId": "fbf78b80-748f-4af7-c5bf-f2e295e73318",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n",
            "Use GPU: 0\n",
            "Traceback (most recent call last):\n",
            "  File \"interpolate.py\", line 18, in <module>\n",
            "    main()\n",
            "  File \"interpolate.py\", line 14, in main\n",
            "    exp = Exp(args)\n",
            "  File \"/content/drive/MyDrive/Duong/SimVP/code/exp.py\", line 24, in __init__\n",
            "    self._preparation()\n",
            "  File \"/content/drive/MyDrive/Duong/SimVP/code/exp.py\", line 62, in _preparation\n",
            "    self._build_model()\n",
            "  File \"/content/drive/MyDrive/Duong/SimVP/code/exp.py\", line 77, in _build_model\n",
            "    raise (ValueError('Resume path does not exist'))\n",
            "ValueError: Resume path does not exist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traning with KTH dataset"
      ],
      "metadata": {
        "id": "73U9z7Fazp94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/My Drive/Duong/datasets/kth.zip' -d '/content/drive/My Drive/Duong/datasets/kth'"
      ],
      "metadata": {
        "id": "xmo39p-uyn2h",
        "outputId": "7e5fb337-a81b-4f93-bdbb-f38ff0405419",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/My Drive/Duong/datasets/kth.zip\n",
            "warning:  stripped absolute path spec from /\n",
            "mapname:  conversion of  failed\n",
            " extracting: /content/drive/My Drive/Duong/datasets/kth/dataloader_kth.py  \n",
            " extracting: /content/drive/My Drive/Duong/datasets/kth/test_data_gzip.hkl  \n",
            " extracting: /content/drive/My Drive/Duong/datasets/kth/train_data_gzip.hkl  \n",
            " extracting: /content/drive/My Drive/Duong/datasets/kth/test_indices_gzip.hkl  \n",
            " extracting: /content/drive/My Drive/Duong/datasets/kth/train_indices_gzip.hkl  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hickle"
      ],
      "metadata": {
        "id": "y5gsFHkQ2lRC",
        "outputId": "7aed2756-6e3f-4541-8c3d-059f340357ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hickle\n",
            "  Downloading hickle-5.0.2-py3-none-any.whl (107 kB)\n",
            "\u001b[K     |████████████████████████████████| 107 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy!=1.20,>=1.8 in /usr/local/lib/python3.8/dist-packages (from hickle) (1.21.6)\n",
            "Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.8/dist-packages (from hickle) (3.1.0)\n",
            "Installing collected packages: hickle\n",
            "Successfully installed hickle-5.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py \\\n",
        "  --res_dir './results/20221203' \\\n",
        "  --data_root '/content/drive/My Drive/Duong/datasets/kth/' \\\n",
        "  --dataname 'kth' \\\n",
        "  --num_workers 1 \\\n",
        "  --batch_size 8 \\\n",
        "  --in_shape 10 1 128 128"
      ],
      "metadata": {
        "id": "IdLLvosiztz6",
        "outputId": "016df212-be82-44c1-d51c-480c584ec023",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use GPU: 0\n",
            "exist\n",
            "tcmalloc: large alloc 16681664512 bytes == 0x6478000 @  0x7f8fcffde1e7 0x7f8f5ffd414e 0x7f8f6002c745 0x7f8f5ffd79c8 0x5d7f65 0x560200 0x55e571 0x4eae40 0x7f8f2ea70f05 0x5d813c 0x4ff485 0x46eb22 0x59daf9 0x5176d9 0x55fa11 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x5d77c6 0x561051\n",
            "tcmalloc: large alloc 16681664512 bytes == 0x3fc394000 @  0x7f8fcffde1e7 0x7f8f5ffd414e 0x7f8f60030166 0x7f8f60022665 0x7f8f600d3640 0x5aa114 0x49ced5 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x5d77c6 0x561051 0x5d7c18 0x49ca7c 0x5d7c18 0x49ca7c 0x55e858 0x5d7cf1 0x5d9412 0x586306\n",
            "tcmalloc: large alloc 9808510976 bytes == 0x63f6000 @  0x7f8fcffde1e7 0x7f8f5ffd414e 0x7f8f6002c745 0x7f8f5ffd79c8 0x5d7f65 0x560200 0x55e571 0x4eae40 0x7f8f2ea70f05 0x5d813c 0x4ff485 0x46eb22 0x59daf9 0x5176d9 0x55fa11 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x5d77c6 0x561051\n",
            "tcmalloc: large alloc 9808510976 bytes == 0x7dfab6000 @  0x7f8fcffde1e7 0x7f8f5ffd414e 0x7f8f60030166 0x7f8f60022665 0x7f8f600d3640 0x5aa114 0x49ced5 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x5d77c6 0x561051 0x5d7c18 0x49ca7c 0x5d7c18 0x49ca7c 0x55e858 0x5d7cf1 0x5d9412 0x586306\n",
            "\n",
            "device: \tcuda\t\n",
            "res_dir: \t./results/20221203\t\n",
            "ex_name: \tDebug\t\n",
            "use_gpu: \tTrue\t\n",
            "gpu: \t0\t\n",
            "seed: \t1\t\n",
            "batch_size: \t8\t\n",
            "val_batch_size: \t16\t\n",
            "data_root: \t/content/drive/My Drive/Duong/datasets/kth/\t\n",
            "dataname: \tkth\t\n",
            "num_workers: \t1\t\n",
            "in_shape: \t[10, 1, 128, 128]\t\n",
            "hid_S: \t64\t\n",
            "hid_T: \t256\t\n",
            "N_S: \t4\t\n",
            "N_T: \t8\t\n",
            "groups: \t4\t\n",
            "epochs: \t51\t\n",
            "log_step: \t1\t\n",
            "save_epoch_freq: \t10\t\n",
            "lr: \t0.01\t\n",
            "exist\n",
            "tcmalloc: large alloc 16681664512 bytes == 0x7f8acbb20000 @  0x7f8fcffde1e7 0x7f8f5ffd414e 0x7f8f6002c745 0x7f8f5ffd79c8 0x5d7f65 0x560200 0x55e571 0x4eae40 0x7f8f2ea70f05 0x5d813c 0x4ff485 0x46eb22 0x59daf9 0x5176d9 0x55fa11 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x5d77c6 0x561051\n",
            "tcmalloc: large alloc 16681664512 bytes == 0x7f86e9640000 @  0x7f8fcffde1e7 0x7f8f5ffd414e 0x7f8f60030166 0x7f8f60022665 0x7f8f600d3640 0x5aa114 0x49ced5 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x5d77c6 0x561051 0x5d7c18 0x49ca7c 0x55e858 0x5d7cf1 0x5d9412 0x586306 0x5d808f 0x55f3fd\n",
            "tcmalloc: large alloc 9808510976 bytes == 0x539d4000 @  0x7f8fcffde1e7 0x7f8f5ffd414e 0x7f8f6002c745 0x7f8f5ffd79c8 0x5d7f65 0x560200 0x55e571 0x4eae40 0x7f8f2ea70f05 0x5d813c 0x4ff485 0x46eb22 0x59daf9 0x5176d9 0x55fa11 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x5d77c6 0x561051\n",
            "tcmalloc: large alloc 9808510976 bytes == 0x7f8acbb20000 @  0x7f8fcffde1e7 0x7f8f5ffd414e 0x7f8f60030166 0x7f8f60022665 0x7f8f600d3640 0x5aa114 0x49ced5 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x5d77c6 0x561051 0x5d7c18 0x49ca7c 0x55e858 0x5d7cf1 0x5d9412 0x586306 0x5d808f 0x55f3fd\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>  start <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "  0% 0/650 [00:08<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 46, in <module>\n",
            "    exp.train(args)\n",
            "  File \"/content/drive/MyDrive/Duong/SimVP/code/exp.py\", line 104, in train\n",
            "    loss = self.criterion(pred_y, batch_y)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py\", line 530, in forward\n",
            "    return F.mse_loss(input, target, reduction=self.reduction)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 3279, in mse_loss\n",
            "    expanded_input, expanded_target = torch.broadcast_tensors(input, target)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/functional.py\", line 73, in broadcast_tensors\n",
            "    return _VF.broadcast_tensors(tensors)  # type: ignore[attr-defined]\n",
            "RuntimeError: The size of tensor a (10) must match the size of tensor b (20) at non-singleton dimension 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/My Drive/Duong/datasets/kth'"
      ],
      "metadata": {
        "id": "Ii2kRUcy3-0h",
        "outputId": "03bab3be-ad6c-4a25-ee7c-cc8c71ffed74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataloader_kth.py   test_indices_gzip.hkl  train_indices_gzip.hkl\n",
            "test_data_gzip.hkl  train_data_gzip.hkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Try to run model"
      ],
      "metadata": {
        "id": "_GZX1vhNsq0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "id": "JsQ_SKEUst1A",
        "outputId": "a1ae6996-5aac-4eac-eb4a-8afa1c33e790",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 51, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/51)\u001b[K\rremote: Counting objects:   3% (2/51)\u001b[K\rremote: Counting objects:   5% (3/51)\u001b[K\rremote: Counting objects:   7% (4/51)\u001b[K\rremote: Counting objects:   9% (5/51)\u001b[K\rremote: Counting objects:  11% (6/51)\u001b[K\rremote: Counting objects:  13% (7/51)\u001b[K\rremote: Counting objects:  15% (8/51)\u001b[K\rremote: Counting objects:  17% (9/51)\u001b[K\rremote: Counting objects:  19% (10/51)\u001b[K\rremote: Counting objects:  21% (11/51)\u001b[K\rremote: Counting objects:  23% (12/51)\u001b[K\rremote: Counting objects:  25% (13/51)\u001b[K\rremote: Counting objects:  27% (14/51)\u001b[K\rremote: Counting objects:  29% (15/51)\u001b[K\rremote: Counting objects:  31% (16/51)\u001b[K\rremote: Counting objects:  33% (17/51)\u001b[K\rremote: Counting objects:  35% (18/51)\u001b[K\rremote: Counting objects:  37% (19/51)\u001b[K\rremote: Counting objects:  39% (20/51)\u001b[K\rremote: Counting objects:  41% (21/51)\u001b[K\rremote: Counting objects:  43% (22/51)\u001b[K\rremote: Counting objects:  45% (23/51)\u001b[K\rremote: Counting objects:  47% (24/51)\u001b[K\rremote: Counting objects:  49% (25/51)\u001b[K\rremote: Counting objects:  50% (26/51)\u001b[K\rremote: Counting objects:  52% (27/51)\u001b[K\rremote: Counting objects:  54% (28/51)\u001b[K\rremote: Counting objects:  56% (29/51)\u001b[K\rremote: Counting objects:  58% (30/51)\u001b[K\rremote: Counting objects:  60% (31/51)\u001b[K\rremote: Counting objects:  62% (32/51)\u001b[K\rremote: Counting objects:  64% (33/51)\u001b[K\rremote: Counting objects:  66% (34/51)\u001b[K\rremote: Counting objects:  68% (35/51)\u001b[K\rremote: Counting objects:  70% (36/51)\u001b[K\rremote: Counting objects:  72% (37/51)\u001b[K\rremote: Counting objects:  74% (38/51)\u001b[K\rremote: Counting objects:  76% (39/51)\u001b[K\rremote: Counting objects:  78% (40/51)\u001b[K\rremote: Counting objects:  80% (41/51)\u001b[K\rremote: Counting objects:  82% (42/51)\u001b[K\rremote: Counting objects:  84% (43/51)\u001b[K\rremote: Counting objects:  86% (44/51)\u001b[K\rremote: Counting objects:  88% (45/51)\u001b[K\rremote: Counting objects:  90% (46/51)\u001b[K\rremote: Counting objects:  92% (47/51)\u001b[K\rremote: Counting objects:  94% (48/51)\u001b[K\rremote: Counting objects:  96% (49/51)\u001b[K\rremote: Counting objects:  98% (50/51)\u001b[K\rremote: Counting objects: 100% (51/51)\u001b[K\rremote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects:   3% (1/28)\u001b[K\rremote: Compressing objects:   7% (2/28)\u001b[K\rremote: Compressing objects:  10% (3/28)\u001b[K\rremote: Compressing objects:  14% (4/28)\u001b[K\rremote: Compressing objects:  17% (5/28)\u001b[K\rremote: Compressing objects:  21% (6/28)\u001b[K\rremote: Compressing objects:  25% (7/28)\u001b[K\rremote: Compressing objects:  28% (8/28)\u001b[K\rremote: Compressing objects:  32% (9/28)\u001b[K\rremote: Compressing objects:  35% (10/28)\u001b[K\rremote: Compressing objects:  39% (11/28)\u001b[K\rremote: Compressing objects:  42% (12/28)\u001b[K\rremote: Compressing objects:  46% (13/28)\u001b[K\rremote: Compressing objects:  50% (14/28)\u001b[K\rremote: Compressing objects:  53% (15/28)\u001b[K\rremote: Compressing objects:  57% (16/28)\u001b[K\rremote: Compressing objects:  60% (17/28)\u001b[K\rremote: Compressing objects:  64% (18/28)\u001b[K\rremote: Compressing objects:  67% (19/28)\u001b[K\rremote: Compressing objects:  71% (20/28)\u001b[K\rremote: Compressing objects:  75% (21/28)\u001b[K\rremote: Compressing objects:  78% (22/28)\u001b[K\rremote: Compressing objects:  82% (23/28)\u001b[K\rremote: Compressing objects:  85% (24/28)\u001b[K\rremote: Compressing objects:  89% (25/28)\u001b[K\rremote: Compressing objects:  92% (26/28)\u001b[K\rremote: Compressing objects:  96% (27/28)\u001b[K\rremote: Compressing objects: 100% (28/28)\u001b[K\rremote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 41 (delta 27), reused 22 (delta 12), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (41/41), done.\n",
            "From https://github.com/trieuduongle/SimVP-Simpler-yet-Better-Video-Prediction\n",
            "   f07a3d2..36c3530  colab      -> origin/colab\n",
            "Updating f07a3d2..36c3530\n",
            "Fast-forward\n",
            " API/dataloader.py              |   9 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " API/dataloader_kth.py          |   4 \u001b[32m+\u001b[m\n",
            " API/dataloader_moving_mnist.py |   4 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " SimVP.ipynb                    | 665 \u001b[32m+++++++++++++++++++++++++++++++++++++++\u001b[m\u001b[31m--\u001b[m\n",
            " create_parser.py               |  45 \u001b[32m+++\u001b[m\n",
            " exp.py                         |  10 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " fake_training.py               | 131 \u001b[32m++++++++\u001b[m\n",
            " interpolate.py                 |   9 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " main.py                        |   2 \u001b[32m+\u001b[m\n",
            " requirements.txt               |   4 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 10 files changed, 847 insertions(+), 36 deletions(-)\n",
            " create mode 100644 create_parser.py\n",
            " create mode 100644 fake_training.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py \\\n",
        "  --res_dir './results/fake_training/' \\\n",
        "  --data_root '/content/drive/My Drive/Duong/datasets/' \\\n",
        "  --dataname 'mmnist' \\\n",
        "  --num_workers 8 \\\n",
        "  --batch_size 16 \\\n",
        "  --save_epoch_freq 2\\\n",
        "  --in_shape 10 1 64 64"
      ],
      "metadata": {
        "id": "oDf17M5msvnM",
        "outputId": "8899df8b-92f6-49d9-e7cd-6d6a984278e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use GPU: 0\n",
            "\n",
            "device: \tcuda\t\n",
            "res_dir: \t./results/fake_training/\t\n",
            "ex_name: \tDebug\t\n",
            "use_gpu: \tTrue\t\n",
            "gpu: \t0\t\n",
            "seed: \t1\t\n",
            "batch_size: \t16\t\n",
            "val_batch_size: \t16\t\n",
            "data_root: \t/content/drive/My Drive/Duong/datasets/\t\n",
            "dataname: \tmmnist\t\n",
            "num_workers: \t8\t\n",
            "in_shape: \t[10, 1, 64, 64]\t\n",
            "hid_S: \t64\t\n",
            "hid_T: \t256\t\n",
            "N_S: \t4\t\n",
            "N_T: \t8\t\n",
            "groups: \t4\t\n",
            "epochs: \t51\t\n",
            "log_step: \t1\t\n",
            "save_epoch_freq: \t2\t\n",
            "lr: \t0.01\t\n",
            "resume_path: \t\t\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>  start <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "  0% 0/625 [00:00<?, ?it/s]longger\n",
            "train loss: 0.1219:   0% 1/625 [00:05<1:00:43,  5.84s/it]longger\n",
            "train loss: 0.5743:   0% 2/625 [00:07<32:35,  3.14s/it]  longger\n",
            "train loss: 0.1668:   0% 3/625 [00:08<23:36,  2.28s/it]longger\n",
            "train loss: 0.0751:   1% 4/625 [00:09<19:24,  1.88s/it]longger\n",
            "train loss: 0.1162:   1% 5/625 [00:10<17:05,  1.65s/it]longger\n",
            "train loss: 0.1168:   1% 6/625 [00:12<15:41,  1.52s/it]longger\n",
            "train loss: 0.0851:   1% 7/625 [00:13<14:48,  1.44s/it]longger\n",
            "train loss: 0.0640:   1% 8/625 [00:14<14:14,  1.38s/it]longger\n",
            "train loss: 0.0572:   1% 9/625 [00:15<13:51,  1.35s/it]longger\n",
            "train loss: 0.0524:   2% 10/625 [00:17<13:36,  1.33s/it]longger\n",
            "train loss: 0.0566:   2% 10/625 [00:18<19:00,  1.86s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 47, in <module>\n",
            "    exp.train(args)\n",
            "  File \"/content/drive/MyDrive/Duong/SimVP/code/exp.py\", line 137, in train\n",
            "    self.optimizer.step()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 113, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 157, in step\n",
            "    adam(params_with_grad,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 213, in adam\n",
            "    func(params,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 305, in _single_tensor_adam\n",
            "    denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}