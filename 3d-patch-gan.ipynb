{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trieuduongle/SimVP-Simpler-yet-Better-Video-Prediction/blob/3d-patch-gan/3d-patch-gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLrjGVvQWNxH",
        "outputId": "fe0dfdff-a802-404a-e466-3ab8b3aad7ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/trieuduongle/SimVP-Simpler-yet-Better-Video-Prediction.git '/content/drive/My Drive/Duong/SimVP/code'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ8IXIA9WeV0",
        "outputId": "c831b15f-e65d-48b6-9702-f27d98c49b2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path '/content/drive/My Drive/Duong/SimVP/code' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/My Drive/Duong/SimVP/code'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snonURDKWpwk",
        "outputId": "2eb49502-265b-4ad3-fa2e-3cee874aa641"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Duong/SimVP/code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.device_count()\n",
        "torch.cuda.is_available()\n",
        "torch.cuda.current_device()\n",
        "torch.cuda.device(0)\n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "id": "7wh_1WQhfFu4",
        "outputId": "99f5348d-8836-4706-d8ea-cc8ae5101e04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git fetch origin && git checkout 3d-patch-gan && git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyuC_ecGWmcU",
        "outputId": "b8f73612-d2cc-48cd-cd22-695a33798869"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking out files: 100% (15/15), done.\n",
            "Switched to branch '3d-patch-gan'\n",
            "Your branch is behind 'origin/3d-patch-gan' by 1 commit, and can be fast-forwarded.\n",
            "  (use \"git pull\" to update your local branch)\n",
            "Updating a621631..07bd716\n",
            "Fast-forward\n",
            " 3d-patch-gan.ipynb | 299 \u001b[32m++++++++++++++++++++++++++++++++++++++++++++++++\u001b[m\u001b[31m-----\u001b[m\n",
            " 1 file changed, 275 insertions(+), 24 deletions(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash \"./data/moving_mnist/download_mmnist.sh\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SY1EmwzxWzGa",
        "outputId": "d143182a-f5da-4bea-a688-54c120b0a7a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-02 18:06:52--  http://www.cs.toronto.edu/~nitish/unsupervised_video/mnist_test_seq.npy\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 819200096 (781M)\n",
            "Saving to: ‘mnist_test_seq.npy’\n",
            "\n",
            "mnist_test_seq.npy  100%[===================>] 781.25M  9.28MB/s    in 41s     \n",
            "\n",
            "2022-12-02 18:07:33 (19.1 MB/s) - ‘mnist_test_seq.npy’ saved [819200096/819200096]\n",
            "\n",
            "--2022-12-02 18:07:33--  http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Resolving yann.lecun.com (yann.lecun.com)... 172.67.171.76, 104.21.29.36, 2606:4700:3034::6815:1d24, ...\n",
            "Connecting to yann.lecun.com (yann.lecun.com)|172.67.171.76|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9912422 (9.5M) [application/x-gzip]\n",
            "Saving to: ‘train-images-idx3-ubyte.gz’\n",
            "\n",
            "train-images-idx3-u 100%[===================>]   9.45M  61.6MB/s    in 0.2s    \n",
            "\n",
            "2022-12-02 18:07:34 (61.6 MB/s) - ‘train-images-idx3-ubyte.gz’ saved [9912422/9912422]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mXZl8SCBd2x",
        "outputId": "b06e79b3-4bd1-4078-9f03-18eb1625f09e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API\t\t main.py\t     readme_figures\t\t utils.py\n",
            "data\t\t mnist_test_seq.npy  README.md\n",
            "environment.yml  model.py\t     SimVP.ipynb\n",
            "exp.py\t\t modules.py\t     train-images-idx3-ubyte.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --batch_size 64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgflhFiSXuHA",
        "outputId": "9399cfd3-f815-456e-e2a3-4753331d5cbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use GPU: 0\n",
            "\n",
            "device: \tcuda\t\n",
            "res_dir: \t./results\t\n",
            "ex_name: \tDebug\t\n",
            "use_gpu: \tTrue\t\n",
            "gpu: \t0\t\n",
            "seed: \t1\t\n",
            "batch_size: \t64\t\n",
            "val_batch_size: \t16\t\n",
            "data_root: \t./data/\t\n",
            "dataname: \tmmnist\t\n",
            "num_workers: \t8\t\n",
            "in_shape: \t[10, 1, 64, 64]\t\n",
            "hid_S: \t64\t\n",
            "hid_T: \t256\t\n",
            "N_S: \t4\t\n",
            "N_T: \t8\t\n",
            "groups: \t4\t\n",
            "epochs: \t51\t\n",
            "log_step: \t1\t\n",
            "lr: \t0.01\t\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>  start <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "train loss: 0.0337: 100% 157/157 [00:44<00:00,  3.54it/s]\n",
            "vali loss: 0.0310:  10% 63/625 [00:03<00:27, 20.68it/s]\n",
            "vali mse:137.6444, mae:346.0001, ssim:0.4469, psnr:31.2841\n",
            "Epoch: 1 | Train Loss: 0.0460 Vali Loss: 0.0336\n",
            "\n",
            "Validation loss decreased (inf --> 0.033605).  Saving model ...\n",
            "train loss: 0.0313: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0286:  10% 63/625 [00:03<00:28, 19.47it/s]\n",
            "vali mse:126.3827, mae:296.9196, ssim:0.5107, psnr:32.2142\n",
            "Epoch: 2 | Train Loss: 0.0313 Vali Loss: 0.0309\n",
            "\n",
            "Validation loss decreased (0.033605 --> 0.030855).  Saving model ...\n",
            "train loss: 0.0283: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0269:  10% 63/625 [00:03<00:28, 19.89it/s]\n",
            "vali mse:118.7211, mae:278.7345, ssim:0.5592, psnr:32.8707\n",
            "Epoch: 3 | Train Loss: 0.0293 Vali Loss: 0.0290\n",
            "\n",
            "Validation loss decreased (0.030855 --> 0.028985).  Saving model ...\n",
            "train loss: 0.0287: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0264:  10% 63/625 [00:03<00:28, 19.55it/s]\n",
            "vali mse:117.5775, mae:265.8234, ssim:0.6161, psnr:33.4710\n",
            "Epoch: 4 | Train Loss: 0.0282 Vali Loss: 0.0287\n",
            "\n",
            "Validation loss decreased (0.028985 --> 0.028706).  Saving model ...\n",
            "train loss: 0.0263: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0261:  10% 63/625 [00:03<00:28, 19.55it/s]\n",
            "vali mse:113.0489, mae:255.9769, ssim:0.6222, psnr:33.6774\n",
            "Epoch: 5 | Train Loss: 0.0274 Vali Loss: 0.0276\n",
            "\n",
            "Validation loss decreased (0.028706 --> 0.027600).  Saving model ...\n",
            "train loss: 0.0278: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0254:  10% 63/625 [00:03<00:28, 19.75it/s]\n",
            "vali mse:108.6772, mae:268.7874, ssim:0.5823, psnr:33.3547\n",
            "Epoch: 6 | Train Loss: 0.0265 Vali Loss: 0.0265\n",
            "\n",
            "Validation loss decreased (0.027600 --> 0.026533).  Saving model ...\n",
            "train loss: 0.0257: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0237:  10% 63/625 [00:03<00:28, 19.47it/s]\n",
            "vali mse:103.5582, mae:250.0797, ssim:0.6322, psnr:33.7852\n",
            "Epoch: 7 | Train Loss: 0.0255 Vali Loss: 0.0253\n",
            "\n",
            "Validation loss decreased (0.026533 --> 0.025283).  Saving model ...\n",
            "train loss: 0.0232: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0229:  10% 63/625 [00:03<00:28, 19.39it/s]\n",
            "vali mse:99.2328, mae:234.3316, ssim:0.6954, psnr:34.5845\n",
            "Epoch: 8 | Train Loss: 0.0246 Vali Loss: 0.0242\n",
            "\n",
            "Validation loss decreased (0.025283 --> 0.024227).  Saving model ...\n",
            "train loss: 0.0225: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0222:  10% 63/625 [00:03<00:28, 19.58it/s]\n",
            "vali mse:94.9563, mae:249.7297, ssim:0.5827, psnr:33.6404\n",
            "Epoch: 9 | Train Loss: 0.0233 Vali Loss: 0.0232\n",
            "\n",
            "Validation loss decreased (0.024227 --> 0.023183).  Saving model ...\n",
            "train loss: 0.0225: 100% 157/157 [00:37<00:00,  4.24it/s]\n",
            "vali loss: 0.0218:  10% 63/625 [00:03<00:29, 19.19it/s]\n",
            "vali mse:93.5796, mae:220.0360, ssim:0.7582, psnr:35.3514\n",
            "Epoch: 10 | Train Loss: 0.0225 Vali Loss: 0.0228\n",
            "\n",
            "Validation loss decreased (0.023183 --> 0.022847).  Saving model ...\n",
            "train loss: 0.0222: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0221:  10% 63/625 [00:03<00:28, 19.44it/s]\n",
            "vali mse:92.0262, mae:232.9030, ssim:0.7741, psnr:35.7236\n",
            "Epoch: 11 | Train Loss: 0.0218 Vali Loss: 0.0225\n",
            "\n",
            "Validation loss decreased (0.022847 --> 0.022467).  Saving model ...\n",
            "train loss: 0.0215: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0207:  10% 63/625 [00:03<00:29, 19.34it/s]\n",
            "vali mse:86.8812, mae:218.1367, ssim:0.7721, psnr:35.5152\n",
            "Epoch: 12 | Train Loss: 0.0212 Vali Loss: 0.0212\n",
            "\n",
            "Validation loss decreased (0.022467 --> 0.021211).  Saving model ...\n",
            "train loss: 0.0220: 100% 157/157 [00:37<00:00,  4.22it/s]\n",
            "vali loss: 0.0198:  10% 63/625 [00:03<00:28, 19.52it/s]\n",
            "vali mse:84.9514, mae:198.9120, ssim:0.7663, psnr:35.3256\n",
            "Epoch: 13 | Train Loss: 0.0209 Vali Loss: 0.0207\n",
            "\n",
            "Validation loss decreased (0.021211 --> 0.020740).  Saving model ...\n",
            "train loss: 0.0203: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0192:  10% 63/625 [00:03<00:28, 19.60it/s]\n",
            "vali mse:83.2834, mae:202.5196, ssim:0.7973, psnr:35.9497\n",
            "Epoch: 14 | Train Loss: 0.0202 Vali Loss: 0.0203\n",
            "\n",
            "Validation loss decreased (0.020740 --> 0.020333).  Saving model ...\n",
            "train loss: 0.0191: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0185:  10% 63/625 [00:03<00:28, 19.47it/s]\n",
            "vali mse:80.9647, mae:205.6377, ssim:0.7397, psnr:35.0482\n",
            "Epoch: 15 | Train Loss: 0.0197 Vali Loss: 0.0198\n",
            "\n",
            "Validation loss decreased (0.020333 --> 0.019767).  Saving model ...\n",
            "train loss: 0.0190: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0180:  10% 63/625 [00:03<00:28, 19.65it/s]\n",
            "vali mse:79.4775, mae:203.9977, ssim:0.7803, psnr:35.3456\n",
            "Epoch: 16 | Train Loss: 0.0193 Vali Loss: 0.0194\n",
            "\n",
            "Validation loss decreased (0.019767 --> 0.019404).  Saving model ...\n",
            "train loss: 0.0203: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0188:  10% 63/625 [00:03<00:28, 19.69it/s]\n",
            "vali mse:78.8270, mae:224.6094, ssim:0.6146, psnr:33.9823\n",
            "Epoch: 17 | Train Loss: 0.0189 Vali Loss: 0.0192\n",
            "\n",
            "Validation loss decreased (0.019404 --> 0.019245).  Saving model ...\n",
            "train loss: 0.0183: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0175:  10% 63/625 [00:03<00:28, 19.74it/s]\n",
            "vali mse:76.8339, mae:188.6660, ssim:0.7742, psnr:35.5812\n",
            "Epoch: 18 | Train Loss: 0.0186 Vali Loss: 0.0188\n",
            "\n",
            "Validation loss decreased (0.019245 --> 0.018758).  Saving model ...\n",
            "train loss: 0.0182: 100% 157/157 [00:37<00:00,  4.22it/s]\n",
            "vali loss: 0.0179:  10% 63/625 [00:03<00:28, 19.46it/s]\n",
            "vali mse:75.0394, mae:185.8936, ssim:0.7845, psnr:35.5812\n",
            "Epoch: 19 | Train Loss: 0.0184 Vali Loss: 0.0183\n",
            "\n",
            "Validation loss decreased (0.018758 --> 0.018320).  Saving model ...\n",
            "train loss: 0.0166: 100% 157/157 [00:37<00:00,  4.24it/s]\n",
            "vali loss: 0.0170:  10% 63/625 [00:03<00:28, 19.45it/s]\n",
            "vali mse:74.4794, mae:179.7516, ssim:0.8058, psnr:35.8249\n",
            "Epoch: 20 | Train Loss: 0.0180 Vali Loss: 0.0182\n",
            "\n",
            "Validation loss decreased (0.018320 --> 0.018184).  Saving model ...\n",
            "train loss: 0.0174: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0167:  10% 63/625 [00:03<00:28, 19.51it/s]\n",
            "vali mse:72.6940, mae:182.0740, ssim:0.7873, psnr:35.7151\n",
            "Epoch: 21 | Train Loss: 0.0178 Vali Loss: 0.0177\n",
            "\n",
            "Validation loss decreased (0.018184 --> 0.017748).  Saving model ...\n",
            "train loss: 0.0189: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0165:  10% 63/625 [00:03<00:28, 19.50it/s]\n",
            "vali mse:71.9190, mae:178.7111, ssim:0.8263, psnr:36.3520\n",
            "Epoch: 22 | Train Loss: 0.0175 Vali Loss: 0.0176\n",
            "\n",
            "Validation loss decreased (0.017748 --> 0.017558).  Saving model ...\n",
            "train loss: 0.0168: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0165:  10% 63/625 [00:03<00:28, 19.55it/s]\n",
            "vali mse:70.7945, mae:171.0153, ssim:0.8150, psnr:35.9789\n",
            "Epoch: 23 | Train Loss: 0.0172 Vali Loss: 0.0173\n",
            "\n",
            "Validation loss decreased (0.017558 --> 0.017284).  Saving model ...\n",
            "train loss: 0.0156: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0161:  10% 63/625 [00:03<00:28, 19.67it/s]\n",
            "vali mse:69.4670, mae:169.0605, ssim:0.8081, psnr:36.1257\n",
            "Epoch: 24 | Train Loss: 0.0171 Vali Loss: 0.0170\n",
            "\n",
            "Validation loss decreased (0.017284 --> 0.016960).  Saving model ...\n",
            "train loss: 0.0155: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0155:  10% 63/625 [00:03<00:28, 19.72it/s]\n",
            "vali mse:69.3838, mae:168.5445, ssim:0.8148, psnr:36.0635\n",
            "Epoch: 25 | Train Loss: 0.0169 Vali Loss: 0.0169\n",
            "\n",
            "Validation loss decreased (0.016960 --> 0.016940).  Saving model ...\n",
            "train loss: 0.0157: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0158:  10% 63/625 [00:03<00:28, 19.45it/s]\n",
            "vali mse:68.5109, mae:177.7370, ssim:0.7696, psnr:35.8291\n",
            "Epoch: 26 | Train Loss: 0.0166 Vali Loss: 0.0167\n",
            "\n",
            "Validation loss decreased (0.016940 --> 0.016726).  Saving model ...\n",
            "train loss: 0.0161: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0156:  10% 63/625 [00:03<00:28, 19.82it/s]\n",
            "vali mse:69.3776, mae:167.9369, ssim:0.8221, psnr:36.2695\n",
            "Epoch: 27 | Train Loss: 0.0164 Vali Loss: 0.0169\n",
            "\n",
            "train loss: 0.0160: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0156:  10% 63/625 [00:03<00:28, 19.78it/s]\n",
            "vali mse:67.5283, mae:163.2062, ssim:0.8268, psnr:36.3430\n",
            "Epoch: 28 | Train Loss: 0.0164 Vali Loss: 0.0165\n",
            "\n",
            "Validation loss decreased (0.016726 --> 0.016487).  Saving model ...\n",
            "train loss: 0.0156: 100% 157/157 [00:37<00:00,  4.23it/s]\n",
            "vali loss: 0.0146:  10% 63/625 [00:03<00:28, 19.89it/s]\n",
            "vali mse:65.6572, mae:167.2080, ssim:0.8358, psnr:36.3493\n",
            "Epoch: 29 | Train Loss: 0.0161 Vali Loss: 0.0160\n",
            "\n",
            "Validation loss decreased (0.016487 --> 0.016030).  Saving model ...\n",
            "train loss: 0.0153: 100% 157/157 [00:37<00:00,  4.24it/s]\n",
            "vali loss: 0.0154:  10% 63/625 [00:03<00:28, 19.44it/s]\n",
            "vali mse:64.9698, mae:164.7351, ssim:0.8410, psnr:36.4464\n",
            "Epoch: 30 | Train Loss: 0.0158 Vali Loss: 0.0159\n",
            "\n",
            "Validation loss decreased (0.016030 --> 0.015862).  Saving model ...\n",
            "train loss: 0.0153:   6% 10/157 [00:03<00:45,  3.23it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 113, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 157, in step\n",
            "    adam(params_with_grad,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 213, in adam\n",
            "    func(params,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 262, in _single_tensor_adam\n",
            "    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 45, in <module>\n",
            "    exp.train(args)\n",
            "  File \"/SimVP/exp.py\", line 108, in train\n",
            "    self.optimizer.step()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 113, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/profiler.py\", line 451, in __exit__\n",
            "    torch.ops.profiler._record_function_exit(self.handle)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/_ops.py\", line 143, in __call__\n",
            "    return self._op(*args, **kwargs or {})\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull && python interpolate.py"
      ],
      "metadata": {
        "id": "gBO-hmCwu6vv",
        "outputId": "9dad3107-b7bc-4f66-b9ec-857d82aaf36d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n",
            "From https://github.com/trieuduongle/SimVP-Simpler-yet-Better-Video-Prediction\n",
            "   55ab4a7..8c50ab2  colab      -> origin/colab\n",
            "Updating 55ab4a7..8c50ab2\n",
            "Fast-forward\n",
            " exp.py | 4 \u001b[32m++\u001b[m\u001b[31m--\u001b[m\n",
            " 1 file changed, 2 insertions(+), 2 deletions(-)\n",
            "Use GPU: 0\n",
            "\n",
            "device: \tcuda\t\n",
            "res_dir: \t./results\t\n",
            "ex_name: \tDebug\t\n",
            "use_gpu: \tTrue\t\n",
            "gpu: \t0\t\n",
            "seed: \t1\t\n",
            "batch_size: \t16\t\n",
            "val_batch_size: \t16\t\n",
            "data_root: \t./data/\t\n",
            "dataname: \tmmnist\t\n",
            "num_workers: \t8\t\n",
            "in_shape: \t[10, 1, 64, 64]\t\n",
            "hid_S: \t64\t\n",
            "hid_T: \t256\t\n",
            "N_S: \t4\t\n",
            "N_T: \t8\t\n",
            "groups: \t4\t\n",
            "epochs: \t51\t\n",
            "log_step: \t1\t\n",
            "lr: \t0.01\t\n",
            "(16, 10, 1, 64, 64)\n",
            "[[ 76  51  42 ...  69  65  66]\n",
            " [ 74  31  70 ...  32  67  80]\n",
            " [253  29  83 ...  40  40  55]\n",
            " ...\n",
            " [ 82  31  74 ...  49  71  57]\n",
            " [ 49  27  32 ...  44  35  56]\n",
            " [ 69  38  73 ...  71  76  92]]\n",
            "(64, 64)\n",
            "[[99 22 42 ... 58 48 68]\n",
            " [45 42 94 ... 19 77 74]\n",
            " [65 67 12 ... 33 49 64]\n",
            " ...\n",
            " [75 55 59 ... 53 87 65]\n",
            " [62 55 98 ... 37 48 43]\n",
            " [90 57 83 ... 82 98 75]]\n",
            "(64, 64)\n",
            "[[ 72  55  23 ...  37  72  64]\n",
            " [ 52  26 118 ...  22  64  57]\n",
            " [ 36  88  10 ...  48  71  52]\n",
            " ...\n",
            " [ 67  34  59 ...  50 102  43]\n",
            " [ 43  60  51 ...  49  19  63]\n",
            " [ 91  79  89 ...  67  80  68]]\n",
            "(64, 64)\n",
            "[[ 98  86  59 ...  70  65  61]\n",
            " [ 69  28  97 ...  43  91  61]\n",
            " [ 39  83  40 ...  28  35  59]\n",
            " ...\n",
            " [ 61  42  49 ...  26 103  75]\n",
            " [ 41  67  50 ...  98  49  61]\n",
            " [ 85  62  82 ...  74  74  89]]\n",
            "(64, 64)\n",
            "[[ 89  55  34 ...  71  63  64]\n",
            " [ 81  25 122 ...  25  80  74]\n",
            " [ 41   9  45 ... 242  64  56]\n",
            " ...\n",
            " [ 60  46  82 ...  49  66  70]\n",
            " [ 55  32  85 ...  47  30  53]\n",
            " [ 81  79  79 ...  66  83  78]]\n",
            "(64, 64)\n",
            "[[ 65  43  31 ...  57  61  76]\n",
            " [ 72  21  95 ...  36  74  70]\n",
            " [ 34  20  74 ...  72  24  52]\n",
            " ...\n",
            " [100  44  71 ...  64  68  79]\n",
            " [ 60  51  57 ...  52  42  58]\n",
            " [ 77  56  77 ...  71  83  92]]\n",
            "(64, 64)\n",
            "[[ 72  50  50 ...  69  73  71]\n",
            " [ 45  37 102 ...  35  80  69]\n",
            " [ 55  58  10 ...  62  28  54]\n",
            " ...\n",
            " [106  34  74 ...  64  85  69]\n",
            " [ 39  68  49 ...  67  40  70]\n",
            " [ 78  75 100 ...  50  83  96]]\n",
            "(64, 64)\n",
            "[[ 74  50   4 ...  57  35  64]\n",
            " [ 62 247  93 ...  50  84  81]\n",
            " [ 35  75  46 ...  91  42  61]\n",
            " ...\n",
            " [ 68  25  58 ...  42  74  67]\n",
            " [ 55  61  52 ...  30  30  47]\n",
            " [ 90  56  70 ...  69  77  86]]\n",
            "(64, 64)\n",
            "[[ 79  37  13 ...  40  56  71]\n",
            " [ 74  32 145 ...  29  69  64]\n",
            " [ 65  72 247 ...  32  39  48]\n",
            " ...\n",
            " [ 83  39  47 ...  52 100  47]\n",
            " [ 58  76  52 ...  63  30  60]\n",
            " [ 89  51  78 ...  69  97  70]]\n",
            "(64, 64)\n",
            "[[ 73  38  55 ...  19  67  70]\n",
            " [ 82  21 103 ...  12  79  61]\n",
            " [ 37  51  14 ...  44  37  69]\n",
            " ...\n",
            " [ 84  55  46 ...  44  58  68]\n",
            " [ 48  66  66 ...  68  36  71]\n",
            " [ 75  60  98 ...  71  77  89]]\n",
            "(64, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Trainning with Moving MNIST dataset"
      ],
      "metadata": {
        "id": "pvsZ3mzo9BxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmpXMxrMC50q",
        "outputId": "9ea54cba-9345-4a77-c17c-89d039a7df56"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects:  33% (1/3)\u001b[K\rremote: Counting objects:  66% (2/3)\u001b[K\rremote: Counting objects: 100% (3/3)\u001b[K\rremote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects:  33% (1/3)   \rUnpacking objects:  66% (2/3)   \rUnpacking objects: 100% (3/3)   \rUnpacking objects: 100% (3/3), done.\n",
            "From https://github.com/trieuduongle/SimVP-Simpler-yet-Better-Video-Prediction\n",
            "   2980080..6908366  3d-patch-gan -> origin/3d-patch-gan\n",
            "Updating 2980080..6908366\n",
            "Fast-forward\n",
            " gan.py | 3 \u001b[32m+\u001b[m\u001b[31m--\u001b[m\n",
            " 1 file changed, 1 insertion(+), 2 deletions(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KqQEKFi0jG9",
        "outputId": "6d252d30-d06a-402d-d37a-d32d86022083"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hickle==5.0.2\n",
            "  Downloading hickle-5.0.2-py3-none-any.whl (107 kB)\n",
            "\u001b[K     |████████████████████████████████| 107 kB 13.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm==4.64.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (4.64.1)\n",
            "Collecting scikit-image==0.19.3\n",
            "  Downloading scikit_image-0.19.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.0 MB 70.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy!=1.20,>=1.8 in /usr/local/lib/python3.8/dist-packages (from hickle==5.0.2->-r requirements.txt (line 1)) (1.21.6)\n",
            "Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.8/dist-packages (from hickle==5.0.2->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3->-r requirements.txt (line 3)) (2.8.8)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3->-r requirements.txt (line 3)) (1.7.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3->-r requirements.txt (line 3)) (21.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3->-r requirements.txt (line 3)) (2022.10.10)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3->-r requirements.txt (line 3)) (2.9.0)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3->-r requirements.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3->-r requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->scikit-image==0.19.3->-r requirements.txt (line 3)) (3.0.9)\n",
            "Installing collected packages: scikit-image, hickle\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.3\n",
            "    Uninstalling scikit-image-0.18.3:\n",
            "      Successfully uninstalled scikit-image-0.18.3\n",
            "Successfully installed hickle-5.0.2 scikit-image-0.19.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout 3d-patch-gan"
      ],
      "metadata": {
        "id": "3XJt_93CJGHW",
        "outputId": "67dd45c7-9840-4b31-ae6e-ad09aceccf18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already on '3d-patch-gan'\n",
            "Your branch is up to date with 'origin/3d-patch-gan'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py \\\n",
        "  --res_dir './results/mnist/20221212-lan-hai-temporal-patch-gan-resume-epoch-1' \\\n",
        "  --data_root '/content/drive/My Drive/Duong/datasets/' \\\n",
        "  --dataname 'mmnist' \\\n",
        "  --num_workers 8 \\\n",
        "  --batch_size 32 \\\n",
        "  --val_batch_size 32 \\\n",
        "  --epochs 201 \\\n",
        "  --save_epoch_freq 5\\\n",
        "  --in_shape 10 1 64 64 \\\n",
        "  --pre_seq_length 10 \\\n",
        "  --aft_seq_length 10 \\\n",
        "  --image_channels 1"
      ],
      "metadata": {
        "id": "EJ-upBDx71pO",
        "outputId": "36ba3845-dde4-4610-d64d-ff0ebf8c65d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use GPU: 0\n",
            "including adv loss\n",
            "\n",
            "device: \tcuda\t\n",
            "res_dir: \t./results/mnist/20221212-lan-hai-temporal-patch-gan-resume-epoch-1\t\n",
            "ex_name: \tDebug\t\n",
            "use_gpu: \tTrue\t\n",
            "gpu: \t0\t\n",
            "seed: \t1\t\n",
            "batch_size: \t32\t\n",
            "val_batch_size: \t32\t\n",
            "data_root: \t/content/drive/My Drive/Duong/datasets/\t\n",
            "dataname: \tmmnist\t\n",
            "num_workers: \t8\t\n",
            "in_shape: \t[10, 1, 64, 64]\t\n",
            "image_channels: \t1\t\n",
            "hid_S: \t64\t\n",
            "hid_T: \t256\t\n",
            "N_S: \t4\t\n",
            "N_T: \t8\t\n",
            "groups: \t4\t\n",
            "pre_seq_length: \t10\t\n",
            "aft_seq_length: \t10\t\n",
            "epochs: \t201\t\n",
            "log_step: \t1\t\n",
            "save_epoch_freq: \t5\t\n",
            "lr: \t0.01\t\n",
            "resume_path: \t\t\n",
            "lr_D: \t0.0001\t\n",
            "gan_type: \tvanilla\t\n",
            "lambda_adv: \t0.005\t\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>  start <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "train loss: 0.0353 - NonGAN loss: 0.0318 - GAN loss: 0.0035: 100% 313/313 [17:10<00:00,  3.29s/it]\n",
            "vali loss: 0.0309:  10% 32/313 [00:13<02:00,  2.33it/s]\n",
            "vali mse:129.0843, mae:316.1860, ssim:0.4988, psnr:31.9352\n",
            "Epoch: 1 | Train Loss: 0.0424 - NonGAN loss: 0.0391 - GAN loss: 0.0033 Vali Loss: 0.0315 | Take 1051.1902 seconds\n",
            "\n",
            "Validation loss decreased (inf --> 0.031515).  Saving model ...\n",
            "train loss: 0.0348 - NonGAN loss: 0.0313 - GAN loss: 0.0035: 100% 313/313 [17:07<00:00,  3.28s/it]\n",
            "vali loss: 0.0287:  10% 32/313 [00:13<02:02,  2.29it/s]\n",
            "vali mse:119.5493, mae:282.3218, ssim:0.5915, psnr:33.0292\n",
            "Epoch: 2 | Train Loss: 0.0331 - NonGAN loss: 0.0296 - GAN loss: 0.0035 Vali Loss: 0.0292 | Take 1047.4156 seconds\n",
            "\n",
            "Validation loss decreased (0.031515 --> 0.029187).  Saving model ...\n",
            "train loss: 0.0296 - NonGAN loss: 0.0261 - GAN loss: 0.0035: 100% 313/313 [17:05<00:00,  3.28s/it]\n",
            "vali loss: 0.0273:  10% 32/313 [00:13<01:55,  2.43it/s]Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "vali loss: 0.0273:  10% 32/313 [00:14<02:04,  2.27it/s]\n",
            "vali mse:114.2182, mae:271.0782, ssim:0.6454, psnr:33.6970\n",
            "Epoch: 3 | Train Loss: 0.0318 - NonGAN loss: 0.0283 - GAN loss: 0.0035 Vali Loss: 0.0279 | Take 1045.4053 seconds\n",
            "\n",
            "Validation loss decreased (0.029187 --> 0.027885).  Saving model ...\n",
            "train loss: 0.0318 - NonGAN loss: 0.0283 - GAN loss: 0.0035: 100% 313/313 [17:03<00:00,  3.27s/it]\n",
            "vali loss: 0.0269:  10% 32/313 [00:14<02:03,  2.27it/s]\n",
            "vali mse:111.7574, mae:254.4832, ssim:0.6588, psnr:34.0384\n",
            "Epoch: 4 | Train Loss: 0.0306 - NonGAN loss: 0.0271 - GAN loss: 0.0035 Vali Loss: 0.0273 | Take 1043.9415 seconds\n",
            "\n",
            "Validation loss decreased (0.027885 --> 0.027285).  Saving model ...\n",
            "train loss: 0.0293 - NonGAN loss: 0.0258 - GAN loss: 0.0035: 100% 313/313 [17:06<00:00,  3.28s/it]\n",
            "vali loss: 0.0255:  10% 32/313 [00:14<02:03,  2.28it/s]\n",
            "vali mse:106.8948, mae:248.5093, ssim:0.6463, psnr:33.9609\n",
            "Epoch: 5 | Train Loss: 0.0297 - NonGAN loss: 0.0262 - GAN loss: 0.0035 Vali Loss: 0.0261 | Take 1046.1398 seconds\n",
            "\n",
            "Validation loss decreased (0.027285 --> 0.026098).  Saving model ...\n",
            "train loss: 0.0286 - NonGAN loss: 0.0251 - GAN loss: 0.0035: 100% 313/313 [17:05<00:00,  3.28s/it]\n",
            "vali loss: 0.0247:  10% 32/313 [00:14<02:03,  2.28it/s]\n",
            "vali mse:103.7528, mae:243.9124, ssim:0.6928, psnr:34.3940\n",
            "Epoch: 6 | Train Loss: 0.0289 - NonGAN loss: 0.0254 - GAN loss: 0.0035 Vali Loss: 0.0253 | Take 1045.5307 seconds\n",
            "\n",
            "Validation loss decreased (0.026098 --> 0.025330).  Saving model ...\n",
            "train loss: 0.0294 - NonGAN loss: 0.0259 - GAN loss: 0.0035: 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "vali loss: 0.0235:  10% 32/313 [00:14<02:03,  2.28it/s]\n",
            "vali mse:100.2075, mae:243.3363, ssim:0.6558, psnr:34.0676\n",
            "Epoch: 7 | Train Loss: 0.0281 - NonGAN loss: 0.0247 - GAN loss: 0.0035 Vali Loss: 0.0245 | Take 1042.7432 seconds\n",
            "\n",
            "Validation loss decreased (0.025330 --> 0.024465).  Saving model ...\n",
            "train loss: 0.0266 - NonGAN loss: 0.0232 - GAN loss: 0.0035: 100% 313/313 [17:04<00:00,  3.27s/it]\n",
            "vali loss: 0.0228:  10% 32/313 [00:14<02:03,  2.27it/s]\n",
            "vali mse:96.0722, mae:230.6859, ssim:0.7082, psnr:34.5756\n",
            "Epoch: 8 | Train Loss: 0.0272 - NonGAN loss: 0.0237 - GAN loss: 0.0035 Vali Loss: 0.0235 | Take 1044.8356 seconds\n",
            "\n",
            "Validation loss decreased (0.024465 --> 0.023455).  Saving model ...\n",
            "train loss: 0.0263 - NonGAN loss: 0.0229 - GAN loss: 0.0035: 100% 313/313 [17:03<00:00,  3.27s/it]\n",
            "vali loss: 0.0228:  10% 32/313 [00:14<02:03,  2.27it/s]\n",
            "vali mse:95.5149, mae:226.7143, ssim:0.6966, psnr:34.5277\n",
            "Epoch: 9 | Train Loss: 0.0264 - NonGAN loss: 0.0230 - GAN loss: 0.0035 Vali Loss: 0.0233 | Take 1044.0782 seconds\n",
            "\n",
            "Validation loss decreased (0.023455 --> 0.023319).  Saving model ...\n",
            "train loss: 0.0247 - NonGAN loss: 0.0213 - GAN loss: 0.0035: 100% 313/313 [17:05<00:00,  3.28s/it]\n",
            "vali loss: 0.0213:  10% 32/313 [00:14<02:04,  2.26it/s]\n",
            "vali mse:89.8880, mae:213.9799, ssim:0.7221, psnr:34.8574\n",
            "Epoch: 10 | Train Loss: 0.0258 - NonGAN loss: 0.0223 - GAN loss: 0.0035 Vali Loss: 0.0219 | Take 1045.9871 seconds\n",
            "\n",
            "Validation loss decreased (0.023319 --> 0.021946).  Saving model ...\n",
            "train loss: 0.0261 - NonGAN loss: 0.0226 - GAN loss: 0.0035: 100% 313/313 [17:05<00:00,  3.28s/it]\n",
            "vali loss: 0.0216:  10% 32/313 [00:14<02:03,  2.28it/s]\n",
            "vali mse:88.5738, mae:217.0775, ssim:0.7452, psnr:34.9569\n",
            "Epoch: 11 | Train Loss: 0.0252 - NonGAN loss: 0.0217 - GAN loss: 0.0035 Vali Loss: 0.0216 | Take 1046.0573 seconds\n",
            "\n",
            "Validation loss decreased (0.021946 --> 0.021625).  Saving model ...\n",
            "train loss: 0.0239 - NonGAN loss: 0.0205 - GAN loss: 0.0035: 100% 313/313 [17:04<00:00,  3.27s/it]\n",
            "vali loss: 0.0206:  10% 32/313 [00:13<02:02,  2.29it/s]\n",
            "vali mse:86.0583, mae:202.3411, ssim:0.7394, psnr:35.1299\n",
            "Epoch: 12 | Train Loss: 0.0246 - NonGAN loss: 0.0212 - GAN loss: 0.0035 Vali Loss: 0.0210 | Take 1044.6050 seconds\n",
            "\n",
            "Validation loss decreased (0.021625 --> 0.021011).  Saving model ...\n",
            "train loss: 0.0265 - NonGAN loss: 0.0231 - GAN loss: 0.0035: 100% 313/313 [17:06<00:00,  3.28s/it]\n",
            "vali loss: 0.0202:  10% 32/313 [00:14<02:03,  2.27it/s]\n",
            "vali mse:84.9861, mae:209.7262, ssim:0.7700, psnr:35.3207\n",
            "Epoch: 13 | Train Loss: 0.0242 - NonGAN loss: 0.0207 - GAN loss: 0.0035 Vali Loss: 0.0207 | Take 1047.1999 seconds\n",
            "\n",
            "Validation loss decreased (0.021011 --> 0.020749).  Saving model ...\n",
            "train loss: 0.0233 - NonGAN loss: 0.0199 - GAN loss: 0.0035: 100% 313/313 [17:04<00:00,  3.27s/it]\n",
            "vali loss: 0.0197:  10% 32/313 [00:14<02:04,  2.26it/s]\n",
            "vali mse:83.2185, mae:204.0763, ssim:0.7468, psnr:35.0623\n",
            "Epoch: 14 | Train Loss: 0.0238 - NonGAN loss: 0.0204 - GAN loss: 0.0035 Vali Loss: 0.0203 | Take 1044.9224 seconds\n",
            "\n",
            "Validation loss decreased (0.020749 --> 0.020317).  Saving model ...\n",
            "train loss: 0.0224 - NonGAN loss: 0.0190 - GAN loss: 0.0035: 100% 313/313 [17:05<00:00,  3.28s/it]\n",
            "vali loss: 0.0197:  10% 32/313 [00:14<02:04,  2.25it/s]\n",
            "vali mse:82.5204, mae:198.9529, ssim:0.7746, psnr:35.4054\n",
            "Epoch: 15 | Train Loss: 0.0234 - NonGAN loss: 0.0199 - GAN loss: 0.0035 Vali Loss: 0.0201 | Take 1045.8096 seconds\n",
            "\n",
            "Validation loss decreased (0.020317 --> 0.020147).  Saving model ...\n",
            "train loss: 0.0230 - NonGAN loss: 0.0196 - GAN loss: 0.0035: 100% 313/313 [17:05<00:00,  3.28s/it]\n",
            "vali loss: 0.0192:  10% 32/313 [00:14<02:03,  2.28it/s]\n",
            "vali mse:79.9282, mae:197.7829, ssim:0.7809, psnr:35.3860\n",
            "Epoch: 16 | Train Loss: 0.0231 - NonGAN loss: 0.0196 - GAN loss: 0.0035 Vali Loss: 0.0195 | Take 1045.8742 seconds\n",
            "\n",
            "Validation loss decreased (0.020147 --> 0.019514).  Saving model ...\n",
            "train loss: 0.0252 - NonGAN loss: 0.0217 - GAN loss: 0.0035: 100% 313/313 [17:05<00:00,  3.28s/it]\n",
            "vali loss: 0.0191:  10% 32/313 [00:14<02:04,  2.26it/s]\n",
            "vali mse:79.1982, mae:194.4990, ssim:0.7895, psnr:35.6398\n",
            "Epoch: 17 | Train Loss: 0.0228 - NonGAN loss: 0.0194 - GAN loss: 0.0035 Vali Loss: 0.0193 | Take 1046.3070 seconds\n",
            "\n",
            "Validation loss decreased (0.019514 --> 0.019336).  Saving model ...\n",
            "train loss: 0.0217 - NonGAN loss: 0.0182 - GAN loss: 0.0035: 100% 313/313 [17:04<00:00,  3.27s/it]\n",
            "vali loss: 0.0185:  10% 32/313 [00:14<02:03,  2.27it/s]\n",
            "vali mse:78.9998, mae:187.6176, ssim:0.7854, psnr:35.5809\n",
            "Epoch: 18 | Train Loss: 0.0226 - NonGAN loss: 0.0191 - GAN loss: 0.0035 Vali Loss: 0.0193 | Take 1044.5925 seconds\n",
            "\n",
            "Validation loss decreased (0.019336 --> 0.019287).  Saving model ...\n",
            "train loss: 0.0202 - NonGAN loss: 0.0167 - GAN loss: 0.0035: 100% 313/313 [17:04<00:00,  3.27s/it]\n",
            "vali loss: 0.0182:  10% 32/313 [00:14<02:04,  2.26it/s]\n",
            "vali mse:77.0059, mae:188.1823, ssim:0.7786, psnr:35.5715\n",
            "Epoch: 19 | Train Loss: 0.0222 - NonGAN loss: 0.0187 - GAN loss: 0.0035 Vali Loss: 0.0188 | Take 1046.4295 seconds\n",
            "\n",
            "Validation loss decreased (0.019287 --> 0.018801).  Saving model ...\n",
            "train loss: 0.0211 - NonGAN loss: 0.0177 - GAN loss: 0.0035: 100% 313/313 [17:05<00:00,  3.28s/it]\n",
            "vali loss: 0.0175:  10% 32/313 [00:14<02:03,  2.28it/s]\n",
            "vali mse:75.4649, mae:188.5243, ssim:0.7592, psnr:35.6095\n",
            "Epoch: 20 | Train Loss: 0.0221 - NonGAN loss: 0.0187 - GAN loss: 0.0035 Vali Loss: 0.0184 | Take 1045.9624 seconds\n",
            "\n",
            "Validation loss decreased (0.018801 --> 0.018424).  Saving model ...\n",
            "train loss: 0.0235 - NonGAN loss: 0.0200 - GAN loss: 0.0035: 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "vali loss: 0.0178:  10% 32/313 [00:14<02:05,  2.25it/s]\n",
            "vali mse:74.9600, mae:184.2629, ssim:0.8137, psnr:36.0432\n",
            "Epoch: 21 | Train Loss: 0.0217 - NonGAN loss: 0.0183 - GAN loss: 0.0035 Vali Loss: 0.0183 | Take 1043.3075 seconds\n",
            "\n",
            "Validation loss decreased (0.018424 --> 0.018301).  Saving model ...\n",
            "train loss: 0.0202 - NonGAN loss: 0.0167 - GAN loss: 0.0035: 100% 313/313 [17:05<00:00,  3.28s/it]\n",
            "vali loss: 0.0174:  10% 32/313 [00:13<01:55,  2.43it/s]Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "vali loss: 0.0174:  10% 32/313 [00:14<02:05,  2.24it/s]\n",
            "vali mse:73.5509, mae:178.7181, ssim:0.7988, psnr:35.7442\n",
            "Epoch: 22 | Train Loss: 0.0216 - NonGAN loss: 0.0181 - GAN loss: 0.0035 Vali Loss: 0.0180 | Take 1046.0369 seconds\n",
            "\n",
            "Validation loss decreased (0.018301 --> 0.017957).  Saving model ...\n",
            "train loss: 0.0220 - NonGAN loss: 0.0186 - GAN loss: 0.0035:  75% 236/313 [12:55<04:13,  3.29s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 14, in <module>\n",
            "    exp.train(args)\n",
            "  File \"/content/drive/MyDrive/Duong/SimVP/code/exp.py\", line 154, in train\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\", line 487, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\", line 197, in backward\n",
            "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from API.dataloader_moving_mnist import load_data\n",
        "\n",
        "train_loader, vali_loader, test_loader, data_mean, data_std =  load_data(9,10, '/content/drive/My Drive/Duong/datasets/', 1)\n",
        "\n",
        "for batch_x, batch_y in train_loader:\n",
        "  print(batch_x.size())\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYx9hxIfRoK9",
        "outputId": "0c18895b-9b15-4f59-926c-4c1dfba06b81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([9, 10, 1, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py \\\n",
        "  --res_dir './results/mnist/20221213-lan-mot-model-dua-pytorch-gan' \\\n",
        "  --data_root '/content/drive/My Drive/Duong/datasets/' \\\n",
        "  --dataname 'mmnist' \\\n",
        "  --num_workers 8 \\\n",
        "  --batch_size 32 \\\n",
        "  --val_batch_size 32 \\\n",
        "  --epochs 201 \\\n",
        "  --save_epoch_freq 5\\\n",
        "  --in_shape 10 1 64 64 \\\n",
        "  --pre_seq_length 10 \\\n",
        "  --aft_seq_length 10 \\\n",
        "  --image_channels 1"
      ],
      "metadata": {
        "id": "MR7PeFTgFzDR",
        "outputId": "8c25c088-54e5-4203-c306-bcb38d080e46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use GPU: 0\n",
            "\n",
            "device: \tcuda\t\n",
            "res_dir: \t./results/mnist/20221213-lan-mot-model-dua-pytorch-gan\t\n",
            "ex_name: \tDebug\t\n",
            "use_gpu: \tTrue\t\n",
            "gpu: \t0\t\n",
            "seed: \t1\t\n",
            "batch_size: \t32\t\n",
            "val_batch_size: \t32\t\n",
            "data_root: \t/content/drive/My Drive/Duong/datasets/\t\n",
            "dataname: \tmmnist\t\n",
            "num_workers: \t8\t\n",
            "in_shape: \t[10, 1, 64, 64]\t\n",
            "image_channels: \t1\t\n",
            "hid_S: \t64\t\n",
            "hid_T: \t256\t\n",
            "N_S: \t4\t\n",
            "N_T: \t8\t\n",
            "groups: \t4\t\n",
            "pre_seq_length: \t10\t\n",
            "aft_seq_length: \t10\t\n",
            "epochs: \t201\t\n",
            "log_step: \t1\t\n",
            "save_epoch_freq: \t5\t\n",
            "lr: \t0.01\t\n",
            "resume_path: \t\t\n",
            "lr_D: \t0.0001\t\n",
            "gan_type: \tvanilla\t\n",
            "lambda_adv: \t0.005\t\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>  start <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "train loss: 0.0331 - NonGAN loss: 0.0318 - Raw GAN loss: 0.250117600 - Discriminator loss: 0.250004083: 100% 313/313 [16:43<00:00,  3.21s/it]\n",
            "vali loss: 0.0309:  10% 32/313 [00:13<01:57,  2.40it/s]\n",
            "vali mse:128.8880, mae:314.9059, ssim:0.5170, psnr:32.1023\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 1 | Train Loss: 0.0403 - NonGAN loss: 0.0391 - GAN loss: 0.250121111 - Discriminator loss: 0.250003174 Vali Loss: 0.0315 | Take 1024.5131 seconds\n",
            "\n",
            "Validation loss decreased (inf --> 0.031467).  Saving model ...\n",
            "train loss: 0.0302 - NonGAN loss: 0.0289 - Raw GAN loss: 0.250118017 - Discriminator loss: 0.250001550: 100% 313/313 [16:43<00:00,  3.20s/it]\n",
            "vali loss: 0.0289:  10% 32/313 [00:13<01:59,  2.35it/s]\n",
            "vali mse:119.8548, mae:283.6753, ssim:0.5822, psnr:32.9925\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 2 | Train Loss: 0.0310 - NonGAN loss: 0.0297 - GAN loss: 0.250118706 - Discriminator loss: 0.250002763 Vali Loss: 0.0293 | Take 1024.2929 seconds\n",
            "\n",
            "Validation loss decreased (0.031467 --> 0.029262).  Saving model ...\n",
            "train loss: 0.0301 - NonGAN loss: 0.0288 - Raw GAN loss: 0.250114918 - Discriminator loss: 0.250001609: 100% 313/313 [16:41<00:00,  3.20s/it]\n",
            "vali loss: 0.0276:  10% 32/313 [00:13<02:00,  2.34it/s]\n",
            "vali mse:115.0819, mae:272.8388, ssim:0.5986, psnr:33.2573\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 3 | Train Loss: 0.0293 - NonGAN loss: 0.0281 - GAN loss: 0.250117295 - Discriminator loss: 0.250002189 Vali Loss: 0.0281 | Take 1022.3566 seconds\n",
            "\n",
            "Validation loss decreased (0.029262 --> 0.028096).  Saving model ...\n",
            "train loss: 0.0275 - NonGAN loss: 0.0263 - Raw GAN loss: 0.250116885 - Discriminator loss: 0.250001490: 100% 313/313 [16:43<00:00,  3.20s/it]\n",
            "vali loss: 0.0265:  10% 32/313 [00:13<01:59,  2.34it/s]\n",
            "vali mse:110.9800, mae:260.4633, ssim:0.6125, psnr:33.5656\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 4 | Train Loss: 0.0284 - NonGAN loss: 0.0272 - GAN loss: 0.250115850 - Discriminator loss: 0.250001720 Vali Loss: 0.0271 | Take 1023.8683 seconds\n",
            "\n",
            "Validation loss decreased (0.028096 --> 0.027095).  Saving model ...\n",
            "train loss: 0.0268 - NonGAN loss: 0.0255 - Raw GAN loss: 0.250113964 - Discriminator loss: 0.250001550: 100% 313/313 [16:43<00:00,  3.20s/it]\n",
            "vali loss: 0.0254:  10% 32/313 [00:13<01:59,  2.35it/s]\n",
            "vali mse:106.8668, mae:249.7101, ssim:0.6754, psnr:34.1577\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 5 | Train Loss: 0.0275 - NonGAN loss: 0.0262 - GAN loss: 0.250114198 - Discriminator loss: 0.250001284 Vali Loss: 0.0261 | Take 1024.0504 seconds\n",
            "\n",
            "Validation loss decreased (0.027095 --> 0.026091).  Saving model ...\n",
            "train loss: 0.0264 - NonGAN loss: 0.0252 - Raw GAN loss: 0.250111073 - Discriminator loss: 0.249999642: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0251:  10% 32/313 [00:13<01:59,  2.36it/s]\n",
            "vali mse:104.8620, mae:247.1304, ssim:0.6773, psnr:34.2078\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 6 | Train Loss: 0.0268 - NonGAN loss: 0.0255 - GAN loss: 0.250112630 - Discriminator loss: 0.250000908 Vali Loss: 0.0256 | Take 1023.1708 seconds\n",
            "\n",
            "Validation loss decreased (0.026091 --> 0.025601).  Saving model ...\n",
            "train loss: 0.0251 - NonGAN loss: 0.0239 - Raw GAN loss: 0.250110239 - Discriminator loss: 0.250000268: 100% 313/313 [16:43<00:00,  3.20s/it]\n",
            "vali loss: 0.0240:  10% 32/313 [00:13<01:59,  2.34it/s]\n",
            "vali mse:101.7099, mae:247.6287, ssim:0.6702, psnr:34.0819\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 7 | Train Loss: 0.0259 - NonGAN loss: 0.0246 - GAN loss: 0.250111159 - Discriminator loss: 0.250000480 Vali Loss: 0.0248 | Take 1023.7949 seconds\n",
            "\n",
            "Validation loss decreased (0.025601 --> 0.024832).  Saving model ...\n",
            "train loss: 0.0261 - NonGAN loss: 0.0249 - Raw GAN loss: 0.250109255 - Discriminator loss: 0.249999583: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0233:  10% 32/313 [00:13<02:01,  2.31it/s]\n",
            "vali mse:96.7915, mae:241.4340, ssim:0.6980, psnr:34.3862\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 8 | Train Loss: 0.0250 - NonGAN loss: 0.0238 - GAN loss: 0.250109661 - Discriminator loss: 0.250000197 Vali Loss: 0.0236 | Take 1023.4550 seconds\n",
            "\n",
            "Validation loss decreased (0.024832 --> 0.023631).  Saving model ...\n",
            "train loss: 0.0234 - NonGAN loss: 0.0221 - Raw GAN loss: 0.250106096 - Discriminator loss: 0.249999821: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0228:  10% 32/313 [00:13<02:00,  2.34it/s]\n",
            "vali mse:94.6360, mae:232.7882, ssim:0.6960, psnr:34.2926\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 9 | Train Loss: 0.0243 - NonGAN loss: 0.0230 - GAN loss: 0.250108127 - Discriminator loss: 0.249999928 Vali Loss: 0.0231 | Take 1023.7769 seconds\n",
            "\n",
            "Validation loss decreased (0.023631 --> 0.023105).  Saving model ...\n",
            "train loss: 0.0257 - NonGAN loss: 0.0244 - Raw GAN loss: 0.250104904 - Discriminator loss: 0.250000477: 100% 313/313 [16:43<00:00,  3.21s/it]\n",
            "vali loss: 0.0216:  10% 32/313 [00:13<01:59,  2.35it/s]\n",
            "vali mse:91.0309, mae:223.8947, ssim:0.7249, psnr:34.6504\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 10 | Train Loss: 0.0234 - NonGAN loss: 0.0222 - GAN loss: 0.250106712 - Discriminator loss: 0.249999655 Vali Loss: 0.0222 | Take 1023.6770 seconds\n",
            "\n",
            "Validation loss decreased (0.023105 --> 0.022225).  Saving model ...\n",
            "train loss: 0.0206 - NonGAN loss: 0.0193 - Raw GAN loss: 0.250105053 - Discriminator loss: 0.250000030: 100% 313/313 [16:43<00:00,  3.20s/it]\n",
            "vali loss: 0.0214:  10% 32/313 [00:13<01:59,  2.35it/s]\n",
            "vali mse:88.6591, mae:208.2479, ssim:0.7510, psnr:35.2053\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 11 | Train Loss: 0.0228 - NonGAN loss: 0.0216 - GAN loss: 0.250105180 - Discriminator loss: 0.249999436 Vali Loss: 0.0216 | Take 1023.9986 seconds\n",
            "\n",
            "Validation loss decreased (0.022225 --> 0.021646).  Saving model ...\n",
            "train loss: 0.0238 - NonGAN loss: 0.0225 - Raw GAN loss: 0.250101417 - Discriminator loss: 0.249999076: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0208:  10% 32/313 [00:13<01:58,  2.36it/s]\n",
            "vali mse:86.3296, mae:214.3259, ssim:0.7544, psnr:35.0099\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 12 | Train Loss: 0.0225 - NonGAN loss: 0.0212 - GAN loss: 0.250103646 - Discriminator loss: 0.249999195 Vali Loss: 0.0211 | Take 1023.5395 seconds\n",
            "\n",
            "Validation loss decreased (0.021646 --> 0.021077).  Saving model ...\n",
            "train loss: 0.0240 - NonGAN loss: 0.0228 - Raw GAN loss: 0.250100821 - Discriminator loss: 0.249999762: 100% 313/313 [16:43<00:00,  3.20s/it]\n",
            "vali loss: 0.0201:  10% 32/313 [00:13<02:01,  2.31it/s]\n",
            "vali mse:86.1143, mae:197.9144, ssim:0.7666, psnr:35.4284\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 13 | Train Loss: 0.0220 - NonGAN loss: 0.0207 - GAN loss: 0.250102316 - Discriminator loss: 0.249999043 Vali Loss: 0.0210 | Take 1027.5719 seconds\n",
            "\n",
            "Validation loss decreased (0.021077 --> 0.021024).  Saving model ...\n",
            "train loss: 0.0221 - NonGAN loss: 0.0209 - Raw GAN loss: 0.250098556 - Discriminator loss: 0.249998435: 100% 313/313 [16:43<00:00,  3.20s/it]\n",
            "vali loss: 0.0196:  10% 32/313 [00:13<01:59,  2.34it/s]\n",
            "vali mse:83.2661, mae:208.5506, ssim:0.7214, psnr:34.7430\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 14 | Train Loss: 0.0216 - NonGAN loss: 0.0203 - GAN loss: 0.250100920 - Discriminator loss: 0.249998848 Vali Loss: 0.0203 | Take 1024.0621 seconds\n",
            "\n",
            "Validation loss decreased (0.021024 --> 0.020329).  Saving model ...\n",
            "train loss: 0.0211 - NonGAN loss: 0.0199 - Raw GAN loss: 0.250100136 - Discriminator loss: 0.249998808: 100% 313/313 [16:43<00:00,  3.20s/it]\n",
            "vali loss: 0.0194:  10% 32/313 [00:13<01:59,  2.36it/s]\n",
            "vali mse:81.2714, mae:197.4784, ssim:0.7553, psnr:35.2663\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 15 | Train Loss: 0.0212 - NonGAN loss: 0.0200 - GAN loss: 0.250099426 - Discriminator loss: 0.249998705 Vali Loss: 0.0198 | Take 1023.8610 seconds\n",
            "\n",
            "Validation loss decreased (0.020329 --> 0.019842).  Saving model ...\n",
            "train loss: 0.0227 - NonGAN loss: 0.0215 - Raw GAN loss: 0.250096649 - Discriminator loss: 0.249999791: 100% 313/313 [16:43<00:00,  3.21s/it]\n",
            "vali loss: 0.0190:  10% 32/313 [00:13<01:59,  2.35it/s]\n",
            "vali mse:80.2358, mae:192.9972, ssim:0.7821, psnr:35.4532\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 16 | Train Loss: 0.0209 - NonGAN loss: 0.0197 - GAN loss: 0.250098044 - Discriminator loss: 0.249998527 Vali Loss: 0.0196 | Take 1024.4774 seconds\n",
            "\n",
            "Validation loss decreased (0.019842 --> 0.019589).  Saving model ...\n",
            "train loss: 0.0208 - NonGAN loss: 0.0195 - Raw GAN loss: 0.250095844 - Discriminator loss: 0.249997824: 100% 313/313 [16:44<00:00,  3.21s/it]\n",
            "vali loss: 0.0190:  10% 32/313 [00:13<02:00,  2.34it/s]\n",
            "vali mse:79.9587, mae:187.9091, ssim:0.7768, psnr:35.5765\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 17 | Train Loss: 0.0206 - NonGAN loss: 0.0194 - GAN loss: 0.250096642 - Discriminator loss: 0.249998325 Vali Loss: 0.0195 | Take 1025.1929 seconds\n",
            "\n",
            "Validation loss decreased (0.019589 --> 0.019521).  Saving model ...\n",
            "train loss: 0.0200 - NonGAN loss: 0.0188 - Raw GAN loss: 0.250096053 - Discriminator loss: 0.249997705: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0182:  10% 32/313 [00:13<01:59,  2.35it/s]\n",
            "vali mse:77.3166, mae:193.9320, ssim:0.7563, psnr:35.4800\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 18 | Train Loss: 0.0203 - NonGAN loss: 0.0191 - GAN loss: 0.250095275 - Discriminator loss: 0.249998199 Vali Loss: 0.0189 | Take 1023.6074 seconds\n",
            "\n",
            "Validation loss decreased (0.019521 --> 0.018876).  Saving model ...\n",
            "train loss: 0.0206 - NonGAN loss: 0.0193 - Raw GAN loss: 0.250094652 - Discriminator loss: 0.249997228: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0186:  10% 32/313 [00:13<01:59,  2.36it/s]\n",
            "vali mse:78.1127, mae:188.4859, ssim:0.7854, psnr:35.4902\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 19 | Train Loss: 0.0201 - NonGAN loss: 0.0189 - GAN loss: 0.250093945 - Discriminator loss: 0.249998053 Vali Loss: 0.0191 | Take 1023.3683 seconds\n",
            "\n",
            "train loss: 0.0195 - NonGAN loss: 0.0182 - Raw GAN loss: 0.250092357 - Discriminator loss: 0.249997556: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0178:  10% 32/313 [00:13<02:00,  2.33it/s]\n",
            "vali mse:75.5598, mae:180.3233, ssim:0.8086, psnr:35.9734\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 20 | Train Loss: 0.0198 - NonGAN loss: 0.0185 - GAN loss: 0.250092498 - Discriminator loss: 0.249997953 Vali Loss: 0.0184 | Take 1023.4553 seconds\n",
            "\n",
            "Validation loss decreased (0.018876 --> 0.018447).  Saving model ...\n",
            "train loss: 0.0184 - NonGAN loss: 0.0171 - Raw GAN loss: 0.250092238 - Discriminator loss: 0.249997303: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0174:  10% 32/313 [00:13<01:59,  2.36it/s]\n",
            "vali mse:74.5328, mae:185.1846, ssim:0.8017, psnr:35.7621\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 21 | Train Loss: 0.0195 - NonGAN loss: 0.0182 - GAN loss: 0.250091192 - Discriminator loss: 0.249997869 Vali Loss: 0.0182 | Take 1023.2126 seconds\n",
            "\n",
            "Validation loss decreased (0.018447 --> 0.018197).  Saving model ...\n",
            "train loss: 0.0196 - NonGAN loss: 0.0183 - Raw GAN loss: 0.250091642 - Discriminator loss: 0.249997929: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0175:  10% 32/313 [00:13<02:00,  2.33it/s]\n",
            "vali mse:73.8357, mae:182.5983, ssim:0.7949, psnr:35.6652\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 22 | Train Loss: 0.0194 - NonGAN loss: 0.0181 - GAN loss: 0.250089789 - Discriminator loss: 0.249997754 Vali Loss: 0.0180 | Take 1024.8904 seconds\n",
            "\n",
            "Validation loss decreased (0.018197 --> 0.018027).  Saving model ...\n",
            "train loss: 0.0184 - NonGAN loss: 0.0171 - Raw GAN loss: 0.250083506 - Discriminator loss: 0.249998450: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0171:  10% 32/313 [00:13<02:00,  2.33it/s]\n",
            "vali mse:72.7979, mae:195.7074, ssim:0.7207, psnr:35.0890\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 23 | Train Loss: 0.0191 - NonGAN loss: 0.0179 - GAN loss: 0.250088530 - Discriminator loss: 0.249997609 Vali Loss: 0.0178 | Take 1023.6179 seconds\n",
            "\n",
            "Validation loss decreased (0.018027 --> 0.017773).  Saving model ...\n",
            "train loss: 0.0186 - NonGAN loss: 0.0173 - Raw GAN loss: 0.250084162 - Discriminator loss: 0.249997184: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0169:  10% 32/313 [00:13<02:00,  2.34it/s]\n",
            "vali mse:72.3167, mae:178.0713, ssim:0.8185, psnr:36.0102\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 24 | Train Loss: 0.0189 - NonGAN loss: 0.0176 - GAN loss: 0.250087184 - Discriminator loss: 0.249997527 Vali Loss: 0.0177 | Take 1023.2239 seconds\n",
            "\n",
            "Validation loss decreased (0.017773 --> 0.017656).  Saving model ...\n",
            "train loss: 0.0186 - NonGAN loss: 0.0173 - Raw GAN loss: 0.250088036 - Discriminator loss: 0.249997437: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0160:  10% 32/313 [00:13<02:01,  2.32it/s]\n",
            "vali mse:70.4919, mae:183.9406, ssim:0.7695, psnr:35.5195\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 25 | Train Loss: 0.0187 - NonGAN loss: 0.0174 - GAN loss: 0.250085938 - Discriminator loss: 0.249997371 Vali Loss: 0.0172 | Take 1023.8056 seconds\n",
            "\n",
            "Validation loss decreased (0.017656 --> 0.017210).  Saving model ...\n",
            "train loss: 0.0175 - NonGAN loss: 0.0163 - Raw GAN loss: 0.250085682 - Discriminator loss: 0.249997646: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0166:  10% 32/313 [00:13<02:01,  2.32it/s]\n",
            "vali mse:71.8051, mae:177.1409, ssim:0.8014, psnr:35.7489\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 26 | Train Loss: 0.0185 - NonGAN loss: 0.0172 - GAN loss: 0.250084622 - Discriminator loss: 0.249997277 Vali Loss: 0.0175 | Take 1023.5309 seconds\n",
            "\n",
            "train loss: 0.0177 - NonGAN loss: 0.0164 - Raw GAN loss: 0.250084132 - Discriminator loss: 0.249997407: 100% 313/313 [16:42<00:00,  3.20s/it]\n",
            "vali loss: 0.0162:  10% 32/313 [00:13<02:01,  2.31it/s]\n",
            "vali mse:69.6223, mae:176.6281, ssim:0.8229, psnr:36.0959\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 27 | Train Loss: 0.0182 - NonGAN loss: 0.0170 - GAN loss: 0.250083492 - Discriminator loss: 0.249997210 Vali Loss: 0.0170 | Take 1023.8608 seconds\n",
            "\n",
            "Validation loss decreased (0.017210 --> 0.016998).  Saving model ...\n",
            "train loss: 0.0184 - NonGAN loss: 0.0172 - Raw GAN loss: 0.250081897 - Discriminator loss: 0.249997348:  29% 90/313 [04:49<11:54,  3.21s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py \\\n",
        "  --res_dir './results/mnist/20221215-lan-mot-model-dua-pytorch-gan-resume-epoch-26' \\\n",
        "  --data_root '/content/drive/My Drive/Duong/datasets/' \\\n",
        "  --resume_path './results/mnist/20221213-lan-mot-model-dua-pytorch-gan/Debug/checkpoints/26.pth' \\\n",
        "  --dataname 'mmnist' \\\n",
        "  --num_workers 8 \\\n",
        "  --batch_size 32 \\\n",
        "  --val_batch_size 32 \\\n",
        "  --epochs 201 \\\n",
        "  --save_epoch_freq 5\\\n",
        "  --in_shape 10 1 64 64 \\\n",
        "  --pre_seq_length 10 \\\n",
        "  --aft_seq_length 10 \\\n",
        "  --image_channels 1"
      ],
      "metadata": {
        "id": "xKvQFNyUnaDR",
        "outputId": "282cca12-2836-444d-b42f-f658315a7692",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use GPU: 0\n",
            "\n",
            "device: \tcuda\t\n",
            "res_dir: \t./results/mnist/20221215-lan-mot-model-dua-pytorch-gan-resume-epoch-26\t\n",
            "ex_name: \tDebug\t\n",
            "use_gpu: \tTrue\t\n",
            "gpu: \t0\t\n",
            "seed: \t1\t\n",
            "batch_size: \t32\t\n",
            "val_batch_size: \t32\t\n",
            "data_root: \t/content/drive/My Drive/Duong/datasets/\t\n",
            "dataname: \tmmnist\t\n",
            "num_workers: \t8\t\n",
            "in_shape: \t[10, 1, 64, 64]\t\n",
            "image_channels: \t1\t\n",
            "hid_S: \t64\t\n",
            "hid_T: \t256\t\n",
            "N_S: \t4\t\n",
            "N_T: \t8\t\n",
            "groups: \t4\t\n",
            "pre_seq_length: \t10\t\n",
            "aft_seq_length: \t10\t\n",
            "epochs: \t201\t\n",
            "log_step: \t1\t\n",
            "save_epoch_freq: \t5\t\n",
            "lr: \t0.01\t\n",
            "resume_path: \t./results/mnist/20221213-lan-mot-model-dua-pytorch-gan/Debug/checkpoints/26.pth\t\n",
            "lr_D: \t0.0001\t\n",
            "gan_type: \tvanilla\t\n",
            "lambda_adv: \t0.005\t\n",
            "resuming\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>  start <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "train loss: 0.0165 - NonGAN loss: 0.0153 - Raw GAN loss: 0.250081986 - Discriminator loss: 0.249997258: 100% 313/313 [17:11<00:00,  3.30s/it]\n",
            "vali loss: 0.0149:  10% 32/313 [00:13<01:59,  2.35it/s]\n",
            "vali mse:63.9472, mae:156.1166, ssim:0.8363, psnr:36.3589\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 1 | Train Loss: 0.0171 - NonGAN loss: 0.0159 - GAN loss: 0.250082869 - Discriminator loss: 0.249997414 Vali Loss: 0.0156 | Take 1053.7355 seconds\n",
            "\n",
            "Validation loss decreased (inf --> 0.015612).  Saving model ...\n",
            "train loss: 0.0167 - NonGAN loss: 0.0154 - Raw GAN loss: 0.250080645 - Discriminator loss: 0.249996811: 100% 313/313 [17:03<00:00,  3.27s/it]\n",
            "vali loss: 0.0147:  10% 32/313 [00:13<02:01,  2.31it/s]\n",
            "vali mse:62.9838, mae:154.6208, ssim:0.8429, psnr:36.4089\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 2 | Train Loss: 0.0167 - NonGAN loss: 0.0154 - GAN loss: 0.250081485 - Discriminator loss: 0.249997464 Vali Loss: 0.0154 | Take 1045.1425 seconds\n",
            "\n",
            "Validation loss decreased (0.015612 --> 0.015377).  Saving model ...\n",
            "train loss: 0.0190 - NonGAN loss: 0.0178 - Raw GAN loss: 0.250079364 - Discriminator loss: 0.249996617: 100% 313/313 [17:04<00:00,  3.27s/it]\n",
            "vali loss: 0.0146:  10% 32/313 [00:13<02:01,  2.32it/s]\n",
            "vali mse:62.7132, mae:156.4696, ssim:0.8427, psnr:36.3950\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 3 | Train Loss: 0.0165 - NonGAN loss: 0.0152 - GAN loss: 0.250080358 - Discriminator loss: 0.249997426 Vali Loss: 0.0153 | Take 1045.9185 seconds\n",
            "\n",
            "Validation loss decreased (0.015377 --> 0.015311).  Saving model ...\n",
            "train loss: 0.0169 - NonGAN loss: 0.0157 - Raw GAN loss: 0.250082821 - Discriminator loss: 0.249996647: 100% 313/313 [17:03<00:00,  3.27s/it]\n",
            "vali loss: 0.0143:  10% 32/313 [00:13<02:02,  2.30it/s]\n",
            "vali mse:62.2329, mae:155.1020, ssim:0.8370, psnr:36.4096\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 4 | Train Loss: 0.0164 - NonGAN loss: 0.0151 - GAN loss: 0.250079316 - Discriminator loss: 0.249997375 Vali Loss: 0.0152 | Take 1045.2961 seconds\n",
            "\n",
            "Validation loss decreased (0.015311 --> 0.015194).  Saving model ...\n",
            "train loss: 0.0155 - NonGAN loss: 0.0142 - Raw GAN loss: 0.250078678 - Discriminator loss: 0.249997243: 100% 313/313 [17:03<00:00,  3.27s/it]\n",
            "vali loss: 0.0145:  10% 32/313 [00:13<02:02,  2.29it/s]\n",
            "vali mse:61.9791, mae:152.8369, ssim:0.8431, psnr:36.4490\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 5 | Train Loss: 0.0162 - NonGAN loss: 0.0150 - GAN loss: 0.250078142 - Discriminator loss: 0.249997306 Vali Loss: 0.0151 | Take 1045.1707 seconds\n",
            "\n",
            "Validation loss decreased (0.015194 --> 0.015132).  Saving model ...\n",
            "train loss: 0.0162 - NonGAN loss: 0.0149 - Raw GAN loss: 0.250074357 - Discriminator loss: 0.249997005: 100% 313/313 [17:04<00:00,  3.27s/it]\n",
            "vali loss: 0.0142:  10% 32/313 [00:13<02:02,  2.29it/s]\n",
            "vali mse:61.4202, mae:150.6243, ssim:0.8460, psnr:36.5145\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 6 | Train Loss: 0.0162 - NonGAN loss: 0.0150 - GAN loss: 0.250077047 - Discriminator loss: 0.249997189 Vali Loss: 0.0150 | Take 1046.4225 seconds\n",
            "\n",
            "Validation loss decreased (0.015132 --> 0.014995).  Saving model ...\n",
            "train loss: 0.0162 - NonGAN loss: 0.0149 - Raw GAN loss: 0.250074983 - Discriminator loss: 0.249996573: 100% 313/313 [17:04<00:00,  3.27s/it]\n",
            "vali loss: 0.0148:  10% 32/313 [00:13<02:02,  2.30it/s]\n",
            "vali mse:61.9849, mae:162.2399, ssim:0.8496, psnr:36.5526\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 7 | Train Loss: 0.0162 - NonGAN loss: 0.0149 - GAN loss: 0.250075963 - Discriminator loss: 0.249997072 Vali Loss: 0.0151 | Take 1046.4131 seconds\n",
            "\n",
            "train loss: 0.0175 - NonGAN loss: 0.0162 - Raw GAN loss: 0.250073195 - Discriminator loss: 0.249997050: 100% 313/313 [17:04<00:00,  3.27s/it]\n",
            "vali loss: 0.0141:  10% 32/313 [00:14<02:04,  2.26it/s]\n",
            "vali mse:61.3650, mae:152.6109, ssim:0.8442, psnr:36.4079\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 8 | Train Loss: 0.0161 - NonGAN loss: 0.0149 - GAN loss: 0.250074963 - Discriminator loss: 0.249996970 Vali Loss: 0.0150 | Take 1046.1374 seconds\n",
            "\n",
            "Validation loss decreased (0.014995 --> 0.014982).  Saving model ...\n",
            "train loss: 0.0156 - NonGAN loss: 0.0143 - Raw GAN loss: 0.250072062 - Discriminator loss: 0.249996275: 100% 313/313 [17:03<00:00,  3.27s/it]\n",
            "vali loss: 0.0141:  10% 32/313 [00:13<02:02,  2.29it/s]\n",
            "vali mse:61.4259, mae:151.3868, ssim:0.8433, psnr:36.4619\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 9 | Train Loss: 0.0161 - NonGAN loss: 0.0149 - GAN loss: 0.250073844 - Discriminator loss: 0.249996848 Vali Loss: 0.0150 | Take 1045.1822 seconds\n",
            "\n",
            "train loss: 0.0181 - NonGAN loss: 0.0169 - Raw GAN loss: 0.250072211 - Discriminator loss: 0.249996364: 100% 313/313 [17:03<00:00,  3.27s/it]\n",
            "vali loss: 0.0147:  10% 32/313 [00:14<02:03,  2.28it/s]\n",
            "vali mse:61.6452, mae:167.2183, ssim:0.7903, psnr:35.9401\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 10 | Train Loss: 0.0161 - NonGAN loss: 0.0149 - GAN loss: 0.250072931 - Discriminator loss: 0.249996725 Vali Loss: 0.0151 | Take 1044.5868 seconds\n",
            "\n",
            "train loss: 0.0144 - NonGAN loss: 0.0131 - Raw GAN loss: 0.250069827 - Discriminator loss: 0.249998182: 100% 313/313 [17:03<00:00,  3.27s/it]\n",
            "vali loss: 0.0140:  10% 32/313 [00:14<02:03,  2.28it/s]\n",
            "vali mse:60.9536, mae:151.6729, ssim:0.8364, psnr:36.3978\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 11 | Train Loss: 0.0160 - NonGAN loss: 0.0148 - GAN loss: 0.250071784 - Discriminator loss: 0.249996680 Vali Loss: 0.0149 | Take 1044.9387 seconds\n",
            "\n",
            "Validation loss decreased (0.014982 --> 0.014881).  Saving model ...\n",
            "train loss: 0.0164 - NonGAN loss: 0.0152 - Raw GAN loss: 0.250064462 - Discriminator loss: 0.249997541: 100% 313/313 [17:04<00:00,  3.27s/it]\n",
            "vali loss: 0.0142:  10% 32/313 [00:13<02:02,  2.29it/s]\n",
            "vali mse:61.3254, mae:162.7796, ssim:0.8519, psnr:36.5824\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 12 | Train Loss: 0.0161 - NonGAN loss: 0.0149 - GAN loss: 0.250070675 - Discriminator loss: 0.249996509 Vali Loss: 0.0150 | Take 1047.9637 seconds\n",
            "\n",
            "train loss: 0.0175 - NonGAN loss: 0.0163 - Raw GAN loss: 0.250069916 - Discriminator loss: 0.249996722: 100% 313/313 [17:04<00:00,  3.27s/it]\n",
            "vali loss: 0.0150:  10% 32/313 [00:14<02:04,  2.25it/s]\n",
            "vali mse:62.4152, mae:151.9892, ssim:0.8436, psnr:36.4654\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 13 | Train Loss: 0.0162 - NonGAN loss: 0.0149 - GAN loss: 0.250069763 - Discriminator loss: 0.249996425 Vali Loss: 0.0152 | Take 1046.7351 seconds\n",
            "\n",
            "train loss: 0.0170 - NonGAN loss: 0.0157 - Raw GAN loss: 0.250065535 - Discriminator loss: 0.249996364: 100% 313/313 [17:03<00:00,  3.27s/it]\n",
            "vali loss: 0.0149:  10% 32/313 [00:14<02:03,  2.28it/s]\n",
            "vali mse:61.8276, mae:153.4853, ssim:0.8479, psnr:36.4947\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 14 | Train Loss: 0.0162 - NonGAN loss: 0.0149 - GAN loss: 0.250068689 - Discriminator loss: 0.249996330 Vali Loss: 0.0151 | Take 1045.3190 seconds\n",
            "\n",
            "train loss: 0.0164 - NonGAN loss: 0.0152 - Raw GAN loss: 0.250071496 - Discriminator loss: 0.249995619: 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "vali loss: 0.0142:  10% 32/313 [00:14<02:02,  2.29it/s]\n",
            "vali mse:60.7612, mae:152.6585, ssim:0.8438, psnr:36.3626\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 15 | Train Loss: 0.0162 - NonGAN loss: 0.0149 - GAN loss: 0.250067607 - Discriminator loss: 0.249996229 Vali Loss: 0.0148 | Take 1044.4924 seconds\n",
            "\n",
            "Validation loss decreased (0.014881 --> 0.014835).  Saving model ...\n",
            "train loss: 0.0171 - NonGAN loss: 0.0158 - Raw GAN loss: 0.250064492 - Discriminator loss: 0.249996692: 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "vali loss: 0.0140:  10% 32/313 [00:13<02:02,  2.29it/s]\n",
            "vali mse:61.5035, mae:152.0229, ssim:0.8438, psnr:36.3834\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 16 | Train Loss: 0.0162 - NonGAN loss: 0.0149 - GAN loss: 0.250066535 - Discriminator loss: 0.249996095 Vali Loss: 0.0150 | Take 1045.8299 seconds\n",
            "\n",
            "train loss: 0.0160 - NonGAN loss: 0.0147 - Raw GAN loss: 0.250064462 - Discriminator loss: 0.249996126: 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "vali loss: 0.0149:  10% 32/313 [00:13<02:02,  2.30it/s]\n",
            "vali mse:62.5452, mae:148.5716, ssim:0.8506, psnr:36.7349\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 17 | Train Loss: 0.0161 - NonGAN loss: 0.0149 - GAN loss: 0.250065350 - Discriminator loss: 0.249995990 Vali Loss: 0.0153 | Take 1044.1711 seconds\n",
            "\n",
            "train loss: 0.0165 - NonGAN loss: 0.0153 - Raw GAN loss: 0.250066191 - Discriminator loss: 0.249995381: 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "vali loss: 0.0145:  10% 32/313 [00:14<02:03,  2.27it/s]\n",
            "vali mse:61.9613, mae:160.1034, ssim:0.8461, psnr:36.4510\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 18 | Train Loss: 0.0162 - NonGAN loss: 0.0150 - GAN loss: 0.250064400 - Discriminator loss: 0.249995819 Vali Loss: 0.0151 | Take 1044.1091 seconds\n",
            "\n",
            "train loss: 0.0179 - NonGAN loss: 0.0166 - Raw GAN loss: 0.250064999 - Discriminator loss: 0.249994844: 100% 313/313 [17:01<00:00,  3.26s/it]\n",
            "vali loss: 0.0148:  10% 32/313 [00:13<02:02,  2.30it/s]\n",
            "vali mse:62.7454, mae:161.0648, ssim:0.8246, psnr:36.0574\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 19 | Train Loss: 0.0162 - NonGAN loss: 0.0150 - GAN loss: 0.250063270 - Discriminator loss: 0.249995721 Vali Loss: 0.0153 | Take 1043.1085 seconds\n",
            "\n",
            "train loss: 0.0153 - NonGAN loss: 0.0140 - Raw GAN loss: 0.250060767 - Discriminator loss: 0.249995857: 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "vali loss: 0.0147:  10% 32/313 [00:14<02:02,  2.29it/s]\n",
            "vali mse:62.0326, mae:154.9255, ssim:0.8355, psnr:36.4798\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 20 | Train Loss: 0.0163 - NonGAN loss: 0.0150 - GAN loss: 0.250062189 - Discriminator loss: 0.249995620 Vali Loss: 0.0151 | Take 1044.4355 seconds\n",
            "\n",
            "train loss: 0.0155 - NonGAN loss: 0.0142 - Raw GAN loss: 0.250060737 - Discriminator loss: 0.249996066: 100% 313/313 [17:03<00:00,  3.27s/it]\n",
            "vali loss: 0.0144:  10% 32/313 [00:13<02:02,  2.30it/s]\n",
            "vali mse:61.9641, mae:158.3195, ssim:0.8236, psnr:36.0809\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 21 | Train Loss: 0.0162 - NonGAN loss: 0.0149 - GAN loss: 0.250061156 - Discriminator loss: 0.249995542 Vali Loss: 0.0151 | Take 1044.6382 seconds\n",
            "\n",
            "train loss: 0.0160 - NonGAN loss: 0.0148 - Raw GAN loss: 0.250064611 - Discriminator loss: 0.249994785: 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "vali loss: 0.0145:  10% 32/313 [00:13<02:02,  2.30it/s]\n",
            "vali mse:61.6868, mae:152.5751, ssim:0.8400, psnr:36.5146\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 22 | Train Loss: 0.0162 - NonGAN loss: 0.0150 - GAN loss: 0.250059957 - Discriminator loss: 0.249995453 Vali Loss: 0.0151 | Take 1044.1267 seconds\n",
            "\n",
            "train loss: 0.0150 - NonGAN loss: 0.0137 - Raw GAN loss: 0.250054240 - Discriminator loss: 0.249995783: 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "vali loss: 0.0146:  10% 32/313 [00:13<02:01,  2.30it/s]\n",
            "vali mse:62.0018, mae:160.0477, ssim:0.8230, psnr:36.2284\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 23 | Train Loss: 0.0162 - NonGAN loss: 0.0150 - GAN loss: 0.250058972 - Discriminator loss: 0.249995303 Vali Loss: 0.0151 | Take 1043.9228 seconds\n",
            "\n",
            "train loss: 0.0157 - NonGAN loss: 0.0145 - Raw GAN loss: 0.250052899 - Discriminator loss: 0.249995574: 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "vali loss: 0.0151:  10% 32/313 [00:14<02:06,  2.22it/s]\n",
            "vali mse:62.7270, mae:154.9473, ssim:0.8477, psnr:36.4630\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 24 | Train Loss: 0.0161 - NonGAN loss: 0.0149 - GAN loss: 0.250057730 - Discriminator loss: 0.249995271 Vali Loss: 0.0153 | Take 1044.3199 seconds\n",
            "\n",
            "train loss: 0.0154 - NonGAN loss: 0.0142 - Raw GAN loss: 0.250057787 - Discriminator loss: 0.249995440: 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "vali loss: 0.0143:  10% 32/313 [00:13<02:02,  2.29it/s]\n",
            "vali mse:62.1739, mae:155.3127, ssim:0.8401, psnr:36.2864\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 25 | Train Loss: 0.0161 - NonGAN loss: 0.0149 - GAN loss: 0.250056708 - Discriminator loss: 0.249995110 Vali Loss: 0.0152 | Take 1043.7856 seconds\n",
            "\n",
            "train loss: 0.0157 - NonGAN loss: 0.0145 - Raw GAN loss: 0.250057369 - Discriminator loss: 0.249995410: 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "vali loss: 0.0144:  10% 32/313 [00:13<02:02,  2.29it/s]\n",
            "vali mse:61.9568, mae:154.4433, ssim:0.8386, psnr:36.3073\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 26 | Train Loss: 0.0161 - NonGAN loss: 0.0149 - GAN loss: 0.250055627 - Discriminator loss: 0.249995007 Vali Loss: 0.0151 | Take 1043.7001 seconds\n",
            "\n",
            "train loss: 0.0165 - NonGAN loss: 0.0152 - Raw GAN loss: 0.250056446 - Discriminator loss: 0.249995276: 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "vali loss: 0.0143:  10% 32/313 [00:14<02:03,  2.28it/s]\n",
            "vali mse:61.5666, mae:153.9239, ssim:0.8238, psnr:36.4431\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 27 | Train Loss: 0.0162 - NonGAN loss: 0.0149 - GAN loss: 0.250054842 - Discriminator loss: 0.249994885 Vali Loss: 0.0150 | Take 1043.9201 seconds\n",
            "\n",
            "train loss: 0.0163 - NonGAN loss: 0.0150 - Raw GAN loss: 0.250054210 - Discriminator loss: 0.249993593: 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "vali loss: 0.0142:  10% 32/313 [00:14<02:03,  2.28it/s]\n",
            "vali mse:62.0461, mae:154.7491, ssim:0.8479, psnr:36.5006\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 28 | Train Loss: 0.0162 - NonGAN loss: 0.0150 - GAN loss: 0.250053668 - Discriminator loss: 0.249994731 Vali Loss: 0.0151 | Take 1044.3011 seconds\n",
            "\n",
            "train loss: 0.0165 - NonGAN loss: 0.0152 - Raw GAN loss: 0.250051588 - Discriminator loss: 0.249994352: 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "vali loss: 0.0140:  10% 32/313 [00:14<02:03,  2.28it/s]\n",
            "vali mse:61.2016, mae:151.4346, ssim:0.8468, psnr:36.5025\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 29 | Train Loss: 0.0162 - NonGAN loss: 0.0149 - GAN loss: 0.250052628 - Discriminator loss: 0.249994595 Vali Loss: 0.0149 | Take 1044.0595 seconds\n",
            "\n",
            "train loss: 0.0160 - NonGAN loss: 0.0147 - Raw GAN loss: 0.250047117 - Discriminator loss: 0.249993443: 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "vali loss: 0.0152:  10% 32/313 [00:13<02:02,  2.29it/s]\n",
            "vali mse:63.1638, mae:168.6799, ssim:0.8446, psnr:36.3531\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 30 | Train Loss: 0.0161 - NonGAN loss: 0.0148 - GAN loss: 0.250051378 - Discriminator loss: 0.249994567 Vali Loss: 0.0154 | Take 1044.0071 seconds\n",
            "\n",
            "train loss: 0.0157 - NonGAN loss: 0.0145 - Raw GAN loss: 0.250054449 - Discriminator loss: 0.249994114: 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "vali loss: 0.0146:  10% 32/313 [00:13<02:02,  2.29it/s]\n",
            "vali mse:62.6619, mae:158.4276, ssim:0.8422, psnr:36.3177\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 31 | Train Loss: 0.0161 - NonGAN loss: 0.0149 - GAN loss: 0.250050070 - Discriminator loss: 0.249994436 Vali Loss: 0.0153 | Take 1043.9509 seconds\n",
            "\n",
            "train loss: 0.0149 - NonGAN loss: 0.0136 - Raw GAN loss: 0.250046939 - Discriminator loss: 0.249994010: 100% 313/313 [17:03<00:00,  3.27s/it]\n",
            "vali loss: 0.0142:  10% 32/313 [00:13<02:02,  2.29it/s]\n",
            "vali mse:60.8240, mae:160.9712, ssim:0.8578, psnr:36.7740\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 32 | Train Loss: 0.0160 - NonGAN loss: 0.0147 - GAN loss: 0.250048880 - Discriminator loss: 0.249994451 Vali Loss: 0.0148 | Take 1044.8186 seconds\n",
            "\n",
            "train loss: 0.0165 - NonGAN loss: 0.0153 - Raw GAN loss: 0.250052541 - Discriminator loss: 0.249992013: 100% 313/313 [17:03<00:00,  3.27s/it]\n",
            "vali loss: 0.0141:  10% 32/313 [00:13<02:02,  2.29it/s]\n",
            "vali mse:60.3805, mae:162.4827, ssim:0.8081, psnr:36.0011\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 33 | Train Loss: 0.0159 - NonGAN loss: 0.0147 - GAN loss: 0.250048043 - Discriminator loss: 0.249994329 Vali Loss: 0.0147 | Take 1044.9991 seconds\n",
            "\n",
            "Validation loss decreased (0.014835 --> 0.014741).  Saving model ...\n",
            "train loss: 0.0173 - NonGAN loss: 0.0161 - Raw GAN loss: 0.250048250 - Discriminator loss: 0.249993742: 100% 313/313 [17:03<00:00,  3.27s/it]\n",
            "vali loss: 0.0143:  10% 32/313 [00:13<02:01,  2.30it/s]\n",
            "vali mse:60.6980, mae:150.6231, ssim:0.8528, psnr:36.6091\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 34 | Train Loss: 0.0160 - NonGAN loss: 0.0147 - GAN loss: 0.250046768 - Discriminator loss: 0.249994196 Vali Loss: 0.0148 | Take 1044.7143 seconds\n",
            "\n",
            "train loss: 0.0167 - NonGAN loss: 0.0154 - Raw GAN loss: 0.250043213 - Discriminator loss: 0.249995381: 100% 313/313 [17:04<00:00,  3.27s/it]\n",
            "vali loss: 0.0141:  10% 32/313 [00:14<02:03,  2.28it/s]\n",
            "vali mse:60.9795, mae:161.9998, ssim:0.8515, psnr:36.5081\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 35 | Train Loss: 0.0158 - NonGAN loss: 0.0146 - GAN loss: 0.250045560 - Discriminator loss: 0.249994155 Vali Loss: 0.0149 | Take 1045.9399 seconds\n",
            "\n",
            "train loss: 0.0163 - NonGAN loss: 0.0151 - Raw GAN loss: 0.250044644 - Discriminator loss: 0.249993563: 100% 313/313 [17:03<00:00,  3.27s/it]\n",
            "vali loss: 0.0142:  10% 32/313 [00:13<02:02,  2.29it/s]\n",
            "vali mse:60.1940, mae:152.9683, ssim:0.8503, psnr:36.4820\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 36 | Train Loss: 0.0158 - NonGAN loss: 0.0146 - GAN loss: 0.250044447 - Discriminator loss: 0.249994052 Vali Loss: 0.0147 | Take 1045.2075 seconds\n",
            "\n",
            "Validation loss decreased (0.014741 --> 0.014696).  Saving model ...\n",
            "train loss: 0.0157 - NonGAN loss: 0.0145 - Raw GAN loss: 0.250038952 - Discriminator loss: 0.249994129: 100% 313/313 [17:04<00:00,  3.27s/it]\n",
            "vali loss: 0.0138:  10% 32/313 [00:13<02:02,  2.30it/s]\n",
            "vali mse:59.5757, mae:145.0463, ssim:0.8544, psnr:36.6381\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 37 | Train Loss: 0.0157 - NonGAN loss: 0.0144 - GAN loss: 0.250043476 - Discriminator loss: 0.249994084 Vali Loss: 0.0145 | Take 1045.8729 seconds\n",
            "\n",
            "Validation loss decreased (0.014696 --> 0.014545).  Saving model ...\n",
            "train loss: 0.0154 - NonGAN loss: 0.0141 - Raw GAN loss: 0.250042737 - Discriminator loss: 0.249994189: 100% 313/313 [17:01<00:00,  3.26s/it]\n",
            "vali loss: 0.0136:  10% 32/313 [00:13<02:01,  2.31it/s]\n",
            "vali mse:59.3266, mae:147.3099, ssim:0.8559, psnr:36.6782\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 38 | Train Loss: 0.0157 - NonGAN loss: 0.0145 - GAN loss: 0.250042269 - Discriminator loss: 0.249993888 Vali Loss: 0.0145 | Take 1042.9902 seconds\n",
            "\n",
            "Validation loss decreased (0.014545 --> 0.014484).  Saving model ...\n",
            "train loss: 0.0149 - NonGAN loss: 0.0136 - Raw GAN loss: 0.250040263 - Discriminator loss: 0.249995410: 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "vali loss: 0.0146:  10% 32/313 [00:13<02:02,  2.29it/s]\n",
            "vali mse:60.4190, mae:146.9216, ssim:0.8558, psnr:36.6706\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 39 | Train Loss: 0.0156 - NonGAN loss: 0.0144 - GAN loss: 0.250041105 - Discriminator loss: 0.249993852 Vali Loss: 0.0148 | Take 1043.9633 seconds\n",
            "\n",
            "train loss: 0.0155 - NonGAN loss: 0.0142 - Raw GAN loss: 0.250036925 - Discriminator loss: 0.249993995: 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "vali loss: 0.0137:  10% 32/313 [00:13<02:02,  2.29it/s]\n",
            "vali mse:59.4237, mae:145.4132, ssim:0.8509, psnr:36.6408\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 40 | Train Loss: 0.0156 - NonGAN loss: 0.0143 - GAN loss: 0.250039978 - Discriminator loss: 0.249993775 Vali Loss: 0.0145 | Take 1044.0346 seconds\n",
            "\n",
            "train loss: 0.0151 - NonGAN loss: 0.0138 - Raw GAN loss: 0.250032753 - Discriminator loss: 0.249994248: 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "vali loss: 0.0136:  10% 32/313 [00:13<02:02,  2.29it/s]\n",
            "vali mse:58.4937, mae:147.4922, ssim:0.8399, psnr:36.6279\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 41 | Train Loss: 0.0156 - NonGAN loss: 0.0143 - GAN loss: 0.250038912 - Discriminator loss: 0.249993664 Vali Loss: 0.0143 | Take 1044.1808 seconds\n",
            "\n",
            "Validation loss decreased (0.014484 --> 0.014281).  Saving model ...\n",
            "train loss: 0.0178 - NonGAN loss: 0.0165 - Raw GAN loss: 0.250040680 - Discriminator loss: 0.249991640: 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "vali loss: 0.0136:  10% 32/313 [00:14<02:02,  2.28it/s]\n",
            "vali mse:58.8957, mae:158.3145, ssim:0.8085, psnr:36.1642\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 42 | Train Loss: 0.0154 - NonGAN loss: 0.0142 - GAN loss: 0.250037820 - Discriminator loss: 0.249993657 Vali Loss: 0.0144 | Take 1045.1796 seconds\n",
            "\n",
            "train loss: 0.0132 - NonGAN loss: 0.0120 - Raw GAN loss: 0.250037402 - Discriminator loss: 0.249992937: 100% 313/313 [17:01<00:00,  3.26s/it]\n",
            "vali loss: 0.0142:  10% 32/313 [00:14<02:04,  2.26it/s]\n",
            "vali mse:57.5748, mae:141.6122, ssim:0.8612, psnr:36.8161\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 43 | Train Loss: 0.0154 - NonGAN loss: 0.0141 - GAN loss: 0.250036272 - Discriminator loss: 0.249993593 Vali Loss: 0.0141 | Take 1044.4408 seconds\n",
            "\n",
            "Validation loss decreased (0.014281 --> 0.014057).  Saving model ...\n",
            "train loss: 0.0166 - NonGAN loss: 0.0153 - Raw GAN loss: 0.250034571 - Discriminator loss: 0.249994323: 100% 313/313 [17:01<00:00,  3.27s/it]\n",
            "vali loss: 0.0140:  10% 32/313 [00:14<02:03,  2.28it/s]\n",
            "vali mse:58.5747, mae:142.1090, ssim:0.8596, psnr:36.7892\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 44 | Train Loss: 0.0154 - NonGAN loss: 0.0141 - GAN loss: 0.250035278 - Discriminator loss: 0.249993501 Vali Loss: 0.0143 | Take 1043.1361 seconds\n",
            "\n",
            "train loss: 0.0171 - NonGAN loss: 0.0158 - Raw GAN loss: 0.250034392 - Discriminator loss: 0.249992520: 100% 313/313 [17:01<00:00,  3.26s/it]\n",
            "vali loss: 0.0138:  10% 32/313 [00:13<02:02,  2.30it/s]\n",
            "vali mse:57.8925, mae:157.8307, ssim:0.8160, psnr:36.0823\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 45 | Train Loss: 0.0153 - NonGAN loss: 0.0140 - GAN loss: 0.250034432 - Discriminator loss: 0.249993438 Vali Loss: 0.0141 | Take 1043.4392 seconds\n",
            "\n",
            "train loss: 0.0123 - NonGAN loss: 0.0110 - Raw GAN loss: 0.250034481 - Discriminator loss: 0.249993831: 100% 313/313 [17:01<00:00,  3.26s/it]\n",
            "vali loss: 0.0129:  10% 32/313 [00:14<02:03,  2.28it/s]\n",
            "vali mse:56.9804, mae:140.3676, ssim:0.8570, psnr:36.7946\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 46 | Train Loss: 0.0152 - NonGAN loss: 0.0139 - GAN loss: 0.250033088 - Discriminator loss: 0.249993398 Vali Loss: 0.0139 | Take 1042.6807 seconds\n",
            "\n",
            "Validation loss decreased (0.014057 --> 0.013912).  Saving model ...\n",
            "train loss: 0.0157 - NonGAN loss: 0.0144 - Raw GAN loss: 0.250034124 - Discriminator loss: 0.249991298: 100% 313/313 [17:01<00:00,  3.26s/it]\n",
            "vali loss: 0.0130:  10% 32/313 [00:13<02:01,  2.31it/s]\n",
            "vali mse:57.5014, mae:152.7119, ssim:0.8584, psnr:36.6389\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 47 | Train Loss: 0.0151 - NonGAN loss: 0.0138 - GAN loss: 0.250031916 - Discriminator loss: 0.249993391 Vali Loss: 0.0140 | Take 1043.3242 seconds\n",
            "\n",
            "train loss: 0.0136 - NonGAN loss: 0.0124 - Raw GAN loss: 0.250028968 - Discriminator loss: 0.249996334: 100% 313/313 [17:00<00:00,  3.26s/it]\n",
            "vali loss: 0.0130:  10% 32/313 [00:14<02:03,  2.28it/s]\n",
            "vali mse:56.5644, mae:148.0632, ssim:0.8704, psnr:37.0528\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 48 | Train Loss: 0.0150 - NonGAN loss: 0.0138 - GAN loss: 0.250030695 - Discriminator loss: 0.249993333 Vali Loss: 0.0138 | Take 1042.2402 seconds\n",
            "\n",
            "Validation loss decreased (0.013912 --> 0.013810).  Saving model ...\n",
            "train loss: 0.0153 - NonGAN loss: 0.0141 - Raw GAN loss: 0.250029683 - Discriminator loss: 0.249992400: 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "vali loss: 0.0134:  10% 32/313 [00:13<02:02,  2.29it/s]\n",
            "vali mse:56.9653, mae:148.9623, ssim:0.8434, psnr:36.2416\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 49 | Train Loss: 0.0150 - NonGAN loss: 0.0138 - GAN loss: 0.250029619 - Discriminator loss: 0.249993195 Vali Loss: 0.0139 | Take 1043.6769 seconds\n",
            "\n",
            "train loss: 0.0146 - NonGAN loss: 0.0134 - Raw GAN loss: 0.250026226 - Discriminator loss: 0.249994606: 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "vali loss: 0.0142:  10% 32/313 [00:14<02:03,  2.28it/s]\n",
            "vali mse:56.5539, mae:138.4427, ssim:0.8610, psnr:36.8632\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 50 | Train Loss: 0.0149 - NonGAN loss: 0.0136 - GAN loss: 0.250028540 - Discriminator loss: 0.249993214 Vali Loss: 0.0138 | Take 1043.6739 seconds\n",
            "\n",
            "Validation loss decreased (0.013810 --> 0.013807).  Saving model ...\n",
            "train loss: 0.0147 - NonGAN loss: 0.0135 - Raw GAN loss: 0.250026107 - Discriminator loss: 0.249992967: 100% 313/313 [17:03<00:00,  3.27s/it]\n",
            "vali loss: 0.0131:  10% 32/313 [00:13<02:01,  2.31it/s]\n",
            "vali mse:55.6869, mae:146.5477, ssim:0.8666, psnr:36.7491\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 51 | Train Loss: 0.0148 - NonGAN loss: 0.0136 - GAN loss: 0.250027525 - Discriminator loss: 0.249993135 Vali Loss: 0.0136 | Take 1044.3467 seconds\n",
            "\n",
            "Validation loss decreased (0.013807 --> 0.013596).  Saving model ...\n",
            "train loss: 0.0156 - NonGAN loss: 0.0144 - Raw GAN loss: 0.250024647 - Discriminator loss: 0.249994576: 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "vali loss: 0.0128:  10% 32/313 [00:14<02:03,  2.27it/s]\n",
            "vali mse:55.3966, mae:147.5276, ssim:0.8660, psnr:36.7381\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 52 | Train Loss: 0.0148 - NonGAN loss: 0.0136 - GAN loss: 0.250026011 - Discriminator loss: 0.249993074 Vali Loss: 0.0135 | Take 1044.1800 seconds\n",
            "\n",
            "Validation loss decreased (0.013596 --> 0.013525).  Saving model ...\n",
            "train loss: 0.0127 - NonGAN loss: 0.0114 - Raw GAN loss: 0.250029296 - Discriminator loss: 0.249993548: 100% 313/313 [17:02<00:00,  3.27s/it]\n",
            "vali loss: 0.0128:  10% 32/313 [00:13<02:02,  2.29it/s]\n",
            "vali mse:55.4146, mae:147.7085, ssim:0.8709, psnr:36.9224\n",
            "(32, 10, 1, 64, 64)\n",
            "Epoch: 53 | Train Loss: 0.0147 - NonGAN loss: 0.0135 - GAN loss: 0.250025323 - Discriminator loss: 0.249993027 Vali Loss: 0.0135 | Take 1043.8522 seconds\n",
            "\n",
            "train loss: 0.0145 - NonGAN loss: 0.0133 - Raw GAN loss: 0.250015467 - Discriminator loss: 0.249995306:  44% 138/313 [07:31<09:30,  3.26s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.load('./results/mnist/20221213-lan-mot-model-dua-pytorch-gan/Debug/checkpoints/26.pth').keys()"
      ],
      "metadata": {
        "id": "MUuowdTzsHMs",
        "outputId": "bb2f2f1c-9ac3-499e-d4b0-2a129d78abbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['GENERATOR_STATE_DICT', 'GENERATOR_OPTIMIZER_STATE_DICT', 'DISCRIMINATOR_STATE_DICT', 'DISCRIMINATOR_OPTIMIZER_STATE_DICT'])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull && python interpolate.py \\\n",
        "  --data_root '/content/drive/My Drive/Duong/datasets/' \\\n",
        "  --resume_path './results/mnist/20221212-lan-hai-temporal-patch-gan-resume-epoch-1/Debug/checkpoints/3.pth' \\\n",
        "  --res_dir './results/mnist/20221212-lan-hai-temporal-patch-gan-resume-epoch-1'"
      ],
      "metadata": {
        "id": "pO2tW7f1LCum",
        "outputId": "fbf78b80-748f-4af7-c5bf-f2e295e73318",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n",
            "Use GPU: 0\n",
            "Traceback (most recent call last):\n",
            "  File \"interpolate.py\", line 18, in <module>\n",
            "    main()\n",
            "  File \"interpolate.py\", line 14, in main\n",
            "    exp = Exp(args)\n",
            "  File \"/content/drive/MyDrive/Duong/SimVP/code/exp.py\", line 24, in __init__\n",
            "    self._preparation()\n",
            "  File \"/content/drive/MyDrive/Duong/SimVP/code/exp.py\", line 62, in _preparation\n",
            "    self._build_model()\n",
            "  File \"/content/drive/MyDrive/Duong/SimVP/code/exp.py\", line 77, in _build_model\n",
            "    raise (ValueError('Resume path does not exist'))\n",
            "ValueError: Resume path does not exist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traning with KTH dataset"
      ],
      "metadata": {
        "id": "73U9z7Fazp94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/My Drive/Duong/datasets/kth.zip' -d '/content/drive/My Drive/Duong/datasets/kth'"
      ],
      "metadata": {
        "id": "xmo39p-uyn2h",
        "outputId": "7e5fb337-a81b-4f93-bdbb-f38ff0405419",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/My Drive/Duong/datasets/kth.zip\n",
            "warning:  stripped absolute path spec from /\n",
            "mapname:  conversion of  failed\n",
            " extracting: /content/drive/My Drive/Duong/datasets/kth/dataloader_kth.py  \n",
            " extracting: /content/drive/My Drive/Duong/datasets/kth/test_data_gzip.hkl  \n",
            " extracting: /content/drive/My Drive/Duong/datasets/kth/train_data_gzip.hkl  \n",
            " extracting: /content/drive/My Drive/Duong/datasets/kth/test_indices_gzip.hkl  \n",
            " extracting: /content/drive/My Drive/Duong/datasets/kth/train_indices_gzip.hkl  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hickle"
      ],
      "metadata": {
        "id": "y5gsFHkQ2lRC",
        "outputId": "7aed2756-6e3f-4541-8c3d-059f340357ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hickle\n",
            "  Downloading hickle-5.0.2-py3-none-any.whl (107 kB)\n",
            "\u001b[K     |████████████████████████████████| 107 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy!=1.20,>=1.8 in /usr/local/lib/python3.8/dist-packages (from hickle) (1.21.6)\n",
            "Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.8/dist-packages (from hickle) (3.1.0)\n",
            "Installing collected packages: hickle\n",
            "Successfully installed hickle-5.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py \\\n",
        "  --res_dir './results/20221203' \\\n",
        "  --data_root '/content/drive/My Drive/Duong/datasets/kth/' \\\n",
        "  --dataname 'kth' \\\n",
        "  --num_workers 1 \\\n",
        "  --batch_size 8 \\\n",
        "  --in_shape 10 1 128 128"
      ],
      "metadata": {
        "id": "IdLLvosiztz6",
        "outputId": "016df212-be82-44c1-d51c-480c584ec023",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use GPU: 0\n",
            "exist\n",
            "tcmalloc: large alloc 16681664512 bytes == 0x6478000 @  0x7f8fcffde1e7 0x7f8f5ffd414e 0x7f8f6002c745 0x7f8f5ffd79c8 0x5d7f65 0x560200 0x55e571 0x4eae40 0x7f8f2ea70f05 0x5d813c 0x4ff485 0x46eb22 0x59daf9 0x5176d9 0x55fa11 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x5d77c6 0x561051\n",
            "tcmalloc: large alloc 16681664512 bytes == 0x3fc394000 @  0x7f8fcffde1e7 0x7f8f5ffd414e 0x7f8f60030166 0x7f8f60022665 0x7f8f600d3640 0x5aa114 0x49ced5 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x5d77c6 0x561051 0x5d7c18 0x49ca7c 0x5d7c18 0x49ca7c 0x55e858 0x5d7cf1 0x5d9412 0x586306\n",
            "tcmalloc: large alloc 9808510976 bytes == 0x63f6000 @  0x7f8fcffde1e7 0x7f8f5ffd414e 0x7f8f6002c745 0x7f8f5ffd79c8 0x5d7f65 0x560200 0x55e571 0x4eae40 0x7f8f2ea70f05 0x5d813c 0x4ff485 0x46eb22 0x59daf9 0x5176d9 0x55fa11 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x5d77c6 0x561051\n",
            "tcmalloc: large alloc 9808510976 bytes == 0x7dfab6000 @  0x7f8fcffde1e7 0x7f8f5ffd414e 0x7f8f60030166 0x7f8f60022665 0x7f8f600d3640 0x5aa114 0x49ced5 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x5d77c6 0x561051 0x5d7c18 0x49ca7c 0x5d7c18 0x49ca7c 0x55e858 0x5d7cf1 0x5d9412 0x586306\n",
            "\n",
            "device: \tcuda\t\n",
            "res_dir: \t./results/20221203\t\n",
            "ex_name: \tDebug\t\n",
            "use_gpu: \tTrue\t\n",
            "gpu: \t0\t\n",
            "seed: \t1\t\n",
            "batch_size: \t8\t\n",
            "val_batch_size: \t16\t\n",
            "data_root: \t/content/drive/My Drive/Duong/datasets/kth/\t\n",
            "dataname: \tkth\t\n",
            "num_workers: \t1\t\n",
            "in_shape: \t[10, 1, 128, 128]\t\n",
            "hid_S: \t64\t\n",
            "hid_T: \t256\t\n",
            "N_S: \t4\t\n",
            "N_T: \t8\t\n",
            "groups: \t4\t\n",
            "epochs: \t51\t\n",
            "log_step: \t1\t\n",
            "save_epoch_freq: \t10\t\n",
            "lr: \t0.01\t\n",
            "exist\n",
            "tcmalloc: large alloc 16681664512 bytes == 0x7f8acbb20000 @  0x7f8fcffde1e7 0x7f8f5ffd414e 0x7f8f6002c745 0x7f8f5ffd79c8 0x5d7f65 0x560200 0x55e571 0x4eae40 0x7f8f2ea70f05 0x5d813c 0x4ff485 0x46eb22 0x59daf9 0x5176d9 0x55fa11 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x5d77c6 0x561051\n",
            "tcmalloc: large alloc 16681664512 bytes == 0x7f86e9640000 @  0x7f8fcffde1e7 0x7f8f5ffd414e 0x7f8f60030166 0x7f8f60022665 0x7f8f600d3640 0x5aa114 0x49ced5 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x5d77c6 0x561051 0x5d7c18 0x49ca7c 0x55e858 0x5d7cf1 0x5d9412 0x586306 0x5d808f 0x55f3fd\n",
            "tcmalloc: large alloc 9808510976 bytes == 0x539d4000 @  0x7f8fcffde1e7 0x7f8f5ffd414e 0x7f8f6002c745 0x7f8f5ffd79c8 0x5d7f65 0x560200 0x55e571 0x4eae40 0x7f8f2ea70f05 0x5d813c 0x4ff485 0x46eb22 0x59daf9 0x5176d9 0x55fa11 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x5d77c6 0x561051\n",
            "tcmalloc: large alloc 9808510976 bytes == 0x7f8acbb20000 @  0x7f8fcffde1e7 0x7f8f5ffd414e 0x7f8f60030166 0x7f8f60022665 0x7f8f600d3640 0x5aa114 0x49ced5 0x5d7c18 0x49ec69 0x5d7c18 0x49ec69 0x55e571 0x5d7cf1 0x49caa1 0x5d7c18 0x49ca7c 0x55e571 0x5d7cf1 0x49ec69 0x55e571 0x5d7cf1 0x5d77c6 0x561051 0x5d7c18 0x49ca7c 0x55e858 0x5d7cf1 0x5d9412 0x586306 0x5d808f 0x55f3fd\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>  start <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "  0% 0/650 [00:08<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 46, in <module>\n",
            "    exp.train(args)\n",
            "  File \"/content/drive/MyDrive/Duong/SimVP/code/exp.py\", line 104, in train\n",
            "    loss = self.criterion(pred_y, batch_y)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py\", line 530, in forward\n",
            "    return F.mse_loss(input, target, reduction=self.reduction)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 3279, in mse_loss\n",
            "    expanded_input, expanded_target = torch.broadcast_tensors(input, target)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/functional.py\", line 73, in broadcast_tensors\n",
            "    return _VF.broadcast_tensors(tensors)  # type: ignore[attr-defined]\n",
            "RuntimeError: The size of tensor a (10) must match the size of tensor b (20) at non-singleton dimension 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/My Drive/Duong/datasets/kth'"
      ],
      "metadata": {
        "id": "Ii2kRUcy3-0h",
        "outputId": "03bab3be-ad6c-4a25-ee7c-cc8c71ffed74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataloader_kth.py   test_indices_gzip.hkl  train_indices_gzip.hkl\n",
            "test_data_gzip.hkl  train_data_gzip.hkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Try to run model"
      ],
      "metadata": {
        "id": "_GZX1vhNsq0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "id": "JsQ_SKEUst1A",
        "outputId": "a1ae6996-5aac-4eac-eb4a-8afa1c33e790",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 51, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/51)\u001b[K\rremote: Counting objects:   3% (2/51)\u001b[K\rremote: Counting objects:   5% (3/51)\u001b[K\rremote: Counting objects:   7% (4/51)\u001b[K\rremote: Counting objects:   9% (5/51)\u001b[K\rremote: Counting objects:  11% (6/51)\u001b[K\rremote: Counting objects:  13% (7/51)\u001b[K\rremote: Counting objects:  15% (8/51)\u001b[K\rremote: Counting objects:  17% (9/51)\u001b[K\rremote: Counting objects:  19% (10/51)\u001b[K\rremote: Counting objects:  21% (11/51)\u001b[K\rremote: Counting objects:  23% (12/51)\u001b[K\rremote: Counting objects:  25% (13/51)\u001b[K\rremote: Counting objects:  27% (14/51)\u001b[K\rremote: Counting objects:  29% (15/51)\u001b[K\rremote: Counting objects:  31% (16/51)\u001b[K\rremote: Counting objects:  33% (17/51)\u001b[K\rremote: Counting objects:  35% (18/51)\u001b[K\rremote: Counting objects:  37% (19/51)\u001b[K\rremote: Counting objects:  39% (20/51)\u001b[K\rremote: Counting objects:  41% (21/51)\u001b[K\rremote: Counting objects:  43% (22/51)\u001b[K\rremote: Counting objects:  45% (23/51)\u001b[K\rremote: Counting objects:  47% (24/51)\u001b[K\rremote: Counting objects:  49% (25/51)\u001b[K\rremote: Counting objects:  50% (26/51)\u001b[K\rremote: Counting objects:  52% (27/51)\u001b[K\rremote: Counting objects:  54% (28/51)\u001b[K\rremote: Counting objects:  56% (29/51)\u001b[K\rremote: Counting objects:  58% (30/51)\u001b[K\rremote: Counting objects:  60% (31/51)\u001b[K\rremote: Counting objects:  62% (32/51)\u001b[K\rremote: Counting objects:  64% (33/51)\u001b[K\rremote: Counting objects:  66% (34/51)\u001b[K\rremote: Counting objects:  68% (35/51)\u001b[K\rremote: Counting objects:  70% (36/51)\u001b[K\rremote: Counting objects:  72% (37/51)\u001b[K\rremote: Counting objects:  74% (38/51)\u001b[K\rremote: Counting objects:  76% (39/51)\u001b[K\rremote: Counting objects:  78% (40/51)\u001b[K\rremote: Counting objects:  80% (41/51)\u001b[K\rremote: Counting objects:  82% (42/51)\u001b[K\rremote: Counting objects:  84% (43/51)\u001b[K\rremote: Counting objects:  86% (44/51)\u001b[K\rremote: Counting objects:  88% (45/51)\u001b[K\rremote: Counting objects:  90% (46/51)\u001b[K\rremote: Counting objects:  92% (47/51)\u001b[K\rremote: Counting objects:  94% (48/51)\u001b[K\rremote: Counting objects:  96% (49/51)\u001b[K\rremote: Counting objects:  98% (50/51)\u001b[K\rremote: Counting objects: 100% (51/51)\u001b[K\rremote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects:   3% (1/28)\u001b[K\rremote: Compressing objects:   7% (2/28)\u001b[K\rremote: Compressing objects:  10% (3/28)\u001b[K\rremote: Compressing objects:  14% (4/28)\u001b[K\rremote: Compressing objects:  17% (5/28)\u001b[K\rremote: Compressing objects:  21% (6/28)\u001b[K\rremote: Compressing objects:  25% (7/28)\u001b[K\rremote: Compressing objects:  28% (8/28)\u001b[K\rremote: Compressing objects:  32% (9/28)\u001b[K\rremote: Compressing objects:  35% (10/28)\u001b[K\rremote: Compressing objects:  39% (11/28)\u001b[K\rremote: Compressing objects:  42% (12/28)\u001b[K\rremote: Compressing objects:  46% (13/28)\u001b[K\rremote: Compressing objects:  50% (14/28)\u001b[K\rremote: Compressing objects:  53% (15/28)\u001b[K\rremote: Compressing objects:  57% (16/28)\u001b[K\rremote: Compressing objects:  60% (17/28)\u001b[K\rremote: Compressing objects:  64% (18/28)\u001b[K\rremote: Compressing objects:  67% (19/28)\u001b[K\rremote: Compressing objects:  71% (20/28)\u001b[K\rremote: Compressing objects:  75% (21/28)\u001b[K\rremote: Compressing objects:  78% (22/28)\u001b[K\rremote: Compressing objects:  82% (23/28)\u001b[K\rremote: Compressing objects:  85% (24/28)\u001b[K\rremote: Compressing objects:  89% (25/28)\u001b[K\rremote: Compressing objects:  92% (26/28)\u001b[K\rremote: Compressing objects:  96% (27/28)\u001b[K\rremote: Compressing objects: 100% (28/28)\u001b[K\rremote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 41 (delta 27), reused 22 (delta 12), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (41/41), done.\n",
            "From https://github.com/trieuduongle/SimVP-Simpler-yet-Better-Video-Prediction\n",
            "   f07a3d2..36c3530  colab      -> origin/colab\n",
            "Updating f07a3d2..36c3530\n",
            "Fast-forward\n",
            " API/dataloader.py              |   9 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " API/dataloader_kth.py          |   4 \u001b[32m+\u001b[m\n",
            " API/dataloader_moving_mnist.py |   4 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " SimVP.ipynb                    | 665 \u001b[32m+++++++++++++++++++++++++++++++++++++++\u001b[m\u001b[31m--\u001b[m\n",
            " create_parser.py               |  45 \u001b[32m+++\u001b[m\n",
            " exp.py                         |  10 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " fake_training.py               | 131 \u001b[32m++++++++\u001b[m\n",
            " interpolate.py                 |   9 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " main.py                        |   2 \u001b[32m+\u001b[m\n",
            " requirements.txt               |   4 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 10 files changed, 847 insertions(+), 36 deletions(-)\n",
            " create mode 100644 create_parser.py\n",
            " create mode 100644 fake_training.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py \\\n",
        "  --res_dir './results/fake_training/' \\\n",
        "  --data_root '/content/drive/My Drive/Duong/datasets/' \\\n",
        "  --dataname 'mmnist' \\\n",
        "  --num_workers 8 \\\n",
        "  --batch_size 16 \\\n",
        "  --save_epoch_freq 2\\\n",
        "  --in_shape 10 1 64 64"
      ],
      "metadata": {
        "id": "oDf17M5msvnM",
        "outputId": "8899df8b-92f6-49d9-e7cd-6d6a984278e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use GPU: 0\n",
            "\n",
            "device: \tcuda\t\n",
            "res_dir: \t./results/fake_training/\t\n",
            "ex_name: \tDebug\t\n",
            "use_gpu: \tTrue\t\n",
            "gpu: \t0\t\n",
            "seed: \t1\t\n",
            "batch_size: \t16\t\n",
            "val_batch_size: \t16\t\n",
            "data_root: \t/content/drive/My Drive/Duong/datasets/\t\n",
            "dataname: \tmmnist\t\n",
            "num_workers: \t8\t\n",
            "in_shape: \t[10, 1, 64, 64]\t\n",
            "hid_S: \t64\t\n",
            "hid_T: \t256\t\n",
            "N_S: \t4\t\n",
            "N_T: \t8\t\n",
            "groups: \t4\t\n",
            "epochs: \t51\t\n",
            "log_step: \t1\t\n",
            "save_epoch_freq: \t2\t\n",
            "lr: \t0.01\t\n",
            "resume_path: \t\t\n",
            ">>>>>>>>>>>>>>>>>>>>>>>>>>>>  start <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "  0% 0/625 [00:00<?, ?it/s]longger\n",
            "train loss: 0.1219:   0% 1/625 [00:05<1:00:43,  5.84s/it]longger\n",
            "train loss: 0.5743:   0% 2/625 [00:07<32:35,  3.14s/it]  longger\n",
            "train loss: 0.1668:   0% 3/625 [00:08<23:36,  2.28s/it]longger\n",
            "train loss: 0.0751:   1% 4/625 [00:09<19:24,  1.88s/it]longger\n",
            "train loss: 0.1162:   1% 5/625 [00:10<17:05,  1.65s/it]longger\n",
            "train loss: 0.1168:   1% 6/625 [00:12<15:41,  1.52s/it]longger\n",
            "train loss: 0.0851:   1% 7/625 [00:13<14:48,  1.44s/it]longger\n",
            "train loss: 0.0640:   1% 8/625 [00:14<14:14,  1.38s/it]longger\n",
            "train loss: 0.0572:   1% 9/625 [00:15<13:51,  1.35s/it]longger\n",
            "train loss: 0.0524:   2% 10/625 [00:17<13:36,  1.33s/it]longger\n",
            "train loss: 0.0566:   2% 10/625 [00:18<19:00,  1.86s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 47, in <module>\n",
            "    exp.train(args)\n",
            "  File \"/content/drive/MyDrive/Duong/SimVP/code/exp.py\", line 137, in train\n",
            "    self.optimizer.step()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 113, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 157, in step\n",
            "    adam(params_with_grad,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 213, in adam\n",
            "    func(params,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\", line 305, in _single_tensor_adam\n",
            "    denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}